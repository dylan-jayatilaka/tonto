!-------------------------------------------------------------------------------
!
! MAT{REAL}: Matrix operations ...
!
! Copyright (C) Dylan Jayatilaka, 1996
!
! This library is free software; you can redistribute it and/or
! modify it under the terms of the GNU Library General Public
! License as published by the Free Software Foundation; either
! version 2 of the License, or (at your option) any later version.
!
! This library is distributed in the hope that it will be useful,
! but WITHOUT ANY WARRANTY; without even the implied warranty of
! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
! Library General Public License for more details.
!
! You should have received a copy of the GNU Library General Public
! License along with this library; if not, write to the
! Free Software Foundation, Inc., 59 Temple Place - Suite 330,
! Boston, MA  02111-1307, USA.
!
! $Id: mat{real}.foo 4384 2014-05-22 10:34:55Z dylan_ $
!-------------------------------------------------------------------------------

module MAT{REAL}

! #ifdef INTEL_ifort
!    USE lapack95, only: dsyev
!    USE lapack95, only: dgesv
!    USE lapack95, only: dgetrf
!    USE lapack95, only: dgetri
! #endif

   implicit none

   interface uncompress_from_pyramid
      symmetric_unzip_triangle
   end

   ! For getting rotation matrix to match vectors
   saved_reference :: MAT{REAL}*, private   DEFAULT_NULL
   saved_actual    :: MAT{REAL}*, private   DEFAULT_NULL

contains

!  =================
!  Memory allocation
!  =================

   create(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Allocate a matrix with the given dimensions
   end

   create(lb1,ub1,lb2,ub2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Allocate a matrix with the given bounds
   end

   destroy ::: get_from(OBJECT), leaky, PURE
   ! Deallocate "self"
   end

! Old

   create(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given dimensions
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the specified "bounds" for each dimension
   end

   create(lb1,ub1,lb2,ub2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given dimensions
   end

   create(bounds1,bounds2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the specified bounds for each dimension
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given bounds for all dimensions
   end

   destroy ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Destroy the object
   end

!  ====
!  Copy
!  ====

   create_copy(matrix) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a replica copy of matrix
   end

!  ============================
!  Size-of and shape operations
!  ============================

   is_same_shape_as(a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" has the same shape as "self"
   end

   is_transposed_shape_of(a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" is the transposed shape of self
   end

   is_square result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns TRUE if the matrix is square
   end

!  =======================
!  Shrinking and expansion
!  =======================

   shrink(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Shrinks self to dimension dim1xdim2.  Contents are retained.
   end

   expand(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands self to dimension dim1xdim2.  Contents are retained.
   end

   shrink_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Shrinks columns of self to dimension dim2. Contents are retained.
   end

   expand_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands the columns self to dim2.  Contents are retained.
   end

   append_columns(cols) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Append the columns "cols" onto the end of self.
   end

   append_column(col) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Append the column "col" onto the end of self.
   end

   prune_column(col) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Prune the column "col".
   end


   expand_rows(dim1) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands the rows of self to dim1. Contents are retained.
   end

!  ====================
!  Comparison functions
!  ====================

   equals(b) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Check if the matrix is the same as "b".
   end

   same_as(b,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Check if the matrix is the same as "b", within "eps".
   end

!  ================
!  Range operations
!  ================

   all_in_range(range) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return TRUE if all values of self are within the specified "range".
   end

   in_range(range) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return element ij as TRUE if self(i,j) is within the specified "range".
   end

   element_range result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the range (smallest and largest value) of self.
   end

   number_in_range(range,symmetric) result (res)::: get_from(MAT{INTRINSIC}), pure
   ! Return the number of element self(i,j) within the specified "range".
   ! If "symmetric" is present and TRUE, only the elements in self
   ! where the row is greater than the col index are reported.
   end

   get_indices_in_range(range,row,col,val,symmetric) ::: get_from(MAT{INTRINSIC}), pure
   ! Get the "row" and "col" indices, and values "val", of the
   ! elements of "self" which are within the specified "range".
   end

!  =================
!  Inquiry functions
!  =================

   is_diagonal(eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" is a diagonal matrix to within
   ! tolerance "eps" (if present).
   end

   has_unit_diagonal(eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" has 1's as diagonal elements to within
   ! tolerance "eps" (if present).
   end

   has_minus_unit_diagonal result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" has -1's as diagonal elements
   end

   is_unit_matrix(eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" is the unit matrix to within
   ! tolerance "eps" (if present).
   end

   is_inversion_matrix result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" is an inversion matrix
   ! i.e. minus the unit matrix
   end

   is_symmetric result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" is a symmetric matrix
   end

   is_antisymmetric result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" is an antisymmetric matrix
   end

   is_zero(eps) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return TRUE is "self" is the zero matrix, i.e. every element is zero.
   ! If present, "eps" is used to decide when a small number is zero.
   end

!  =================
!  Column operations
!  =================

   has_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" has a column "c", with "eps" tolerance.
   end

   index_for_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the index of the first column in "self" which matches "c",
   ! within tolerance "eps", or else return 0 for no match.
   end

   indices_for_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Return the indices of columns in "self" which match "c",
   ! within tolerance "eps", or else return 0 for no match.
   end



   compare_columns_with(m,col) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the columns of "self" with "m". The elements of array "col" are set
   ! TRUE if the corresponding column appears in "m"
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set TRUE if the corresponding
   ! column is unique.
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set to the indices of the unique
   ! columns.
   end

   no_of_unique_columns result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. Return the number of unique columns.
   end


   swap_columns(col1,col2) ::: get_from(MAT{INTRINSIC}), PURE
   ! Swap columns "col1" and "col2" of self
   end

   swap_columns(list) ::: get_from(MAT{INTRINSIC}), PURE
   ! Sequentially swap all columns in a column "list",
   ! self(:,i)      = self(:,list(i))
   ! self(:,col(i)) = self(:,i)
   end

   reverse_column_order ::: get_from(MAT{INTRINSIC}), PURE
   ! Reverse the order of the columns of self.
   end


   column_norms result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
   end

   get_column_norms(res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
   end

   get_column_dot_products(res) ::: get_from(MAT{INTRINSIC})
   ! Return the dot products of every column with itself.
   ! Good for testing distances without using a sqrt.
   end

   index_of_minimum_column_norm result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the column index of the column with the *minimum* norm.
   end

   max_abs_column_difference result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the maximum of the absolute difference between all the column vector
   ! pairs of the matrix.
   end


   mean_column_vector result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the mean of the column vectors.
   end

   sum_column_vectors result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Sum the column vectors (i.e. rows) in "self".
   end


   plus_column(col) ::: get_from(MAT{INTRINSIC}), pure
   ! Add column "col" to every column of "self".
   end

   minus_column(col) ::: get_from(MAT{INTRINSIC}), pure
   ! Subtract column "col" to every column of "self".
   end

   plus_scaled_column(col,fac) ::: get_from(MAT{INTRINSIC}), pure
   ! Add the "fac" scaled column "col" to every column of "self".
   end

!  ==============
!  Row operations
!  ==============

   unique_rows(row) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set TRUE if the corresponding
   ! row is unique.
   end

   unique_rows(row) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set to the indices of the unique
   ! rows.
   end

   no_of_unique_rows result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later row of "self" with earlier rows to see if they are
   ! unique. Return the number of unique rows.
   end

   swap_rows(row1,row2) ::: get_from(MAT{INTRINSIC}), PURE
   ! Swap columns "row1" and "row2" of self
   end

   swap_rows(list) ::: get_from(MAT{INTRINSIC}), PURE
   ! Sequentially swap all rows in a row "list",
   ! self(i,:)       = self(list(i),:)
   end

   row_norms result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the norms of every row
   end

   get_row_norms(res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the norms of every row
   end

   sum_row_vectors result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Sum the row vectors (i.e. columns) in "self".
   end

!  ==========================================
!  Matrix algebra and vector space operations
!  ==========================================

   determinant result (res) ::: get_from(MAT{INTRINSIC}), recursive, PURE
   ! Return the determinant
   end

   adjugate(i,j) result (res) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Return the adjugate of a matrix
   end


   sum_elements result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the sum of the elements in "self"
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}, RES?=>REAL), PURE
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{CPX}, RES?=>CPX), PURE
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
   end


   rotate(v) ::: get_from(MAT{INTRINSIC}), PURE
   ! Rotate vector "v" by self
   end

   jacobi_rotation(p,q) ::: pure
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q). NOTE: self must be symmetric
      self :: INOUT
      p,q :: INT, IN

      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL

      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)

      theta = (s_qq-s_pp)/(TWO*s_pq)

      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t

      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)

      do i = 1,.dim1

         s_ip = self(i,p)
         s_iq = self(i,q)

         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)

         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq

      end

      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO

   end

   jacobi_rotation(p,q,v) ::: pure
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q) and also update the rotation
   ! matrix "v". NOTE: self must be symmetric
      self :: INOUT
      p,q :: INT, IN
      v :: MAT{REAL}, INOUT

      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL

      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)

      theta = (s_qq-s_pp)/(TWO*s_pq)

      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t

      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)

      do i = 1,.dim1

         s_ip = self(i,p)
         s_iq = self(i,q)

         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)

         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq

      end

      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO

      do i = 1,.dim1

         s_ip = v(i,p)
         s_iq = v(i,q)

         v(i,p) = s_ip - s*(s_iq+tau*s_ip)
         v(i,q) = s_iq + s*(s_ip-tau*s_iq)

      end

   end

   to_3x3_rotation_matrix(axis,angle) ::: PURE
   ! Set "self" to the rotation matrix which rotates around vector "axis" in
   ! an anticlockwise direction (when looking against the "axis" vector) by
   ! amount "angle" (in radians).
      self :: OUT
      axis :: VEC{REAL}, IN
      angle :: REAL, IN

   ENSURE(.is_square,"non-square matrix")
   ENSURE(.dim1==3,"must be 3x3 matrix")
   ENSURE(axis.dim==3,"axis is not 3 dimensional")

      x,y,z,xp,yp :: VEC{REAL}(3)

      z = axis
      z.normalise

      x = z.cross([ONE,ZERO,ZERO])
      if (x.is_zero(TOL(9))) x = z.cross([ZERO,ONE,ZERO])
      x.normalise

      y  = z.cross(x)

      xp = cos(angle)*x+sin(angle)*y
      yp = cos(angle)*y-sin(angle)*x

      self =  z.outer_product_with(z) &
           + xp.outer_product_with(x) &
           + yp.outer_product_with(y)

   end


   to_unit_matrix ::: get_from(MAT{INTRINSIC}), pure
   ! Set "self" to the unit matrix
   end


   zero_small_values(eps) ::: get_from(MAT{INTRINSIC}), pure
   ! Zero elements of the matrix which are less than "eps" in magnitude
   end


   set_to(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Set self to "a"
   end

   set_to_transpose_of(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Self becomes the transpose of "a"
   end

   to_transpose ::: get_from(MAT{INTRINSIC}), PURE
   ! Self becomes its own transpose.
   end


   plus(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Add to self the matrix "a"
   end

   minus(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Subtract from self the matrix "a"
   end

   to_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set "self" to matrix "at" scaled by "fac"
   end

   plus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add to "self" matrix "a" scaled by "fac"
   end

   minus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Subtract from "self" matrix "a" scaled by "fac"
   end


   to_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL), PURE
   ! Set "self" to the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
   end

   plus_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL), PURE
   ! Add to "self" the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
   end

   to_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL, FAC?=>REAL), PURE
   ! Set "self" to the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! need to be transposed.
   end

   plus_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL, FAC?=>REAL), PURE
   ! Add to "self" the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! neeb to be transposed.
   end


   to_outer_product_of(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>REAL, FAC?=>REAL), PURE
   ! Set "self" to the outer product of "a" with itself, with an
   ! optional scale factor "fac".
   end

   plus_outer_product_of(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>REAL, FAC?=>REAL), PURE
   ! Add to "self" the outer product of "a" with itself, with an
   ! optional scale factor "fac".
   end


   to_product_with_diagonal(a,diag,transpose_a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, DIAG?=>VEC{REAL}), PURE
   ! Set "self" to the matrix product of "a" with diagonal matrix "diag" (stored
   ! as a vector).  If present, ""transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
   end

   to_product_with_diagonal(dg,a,transpose_a) ::: get_from(MAT{INTRINSIC}, DG?=>VEC{REAL}, A?=>MAT{REAL}), PURE
   ! Set "self" to the matrix product of diagonal matrix "dg" (stored as a
   ! vector) and "a".  If present, "transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
   end


   plus_difference_product_with(U,ev,eo,tol) ::: PURE
   ! Do self += (ev(a)-eo(i)) * U(a,i).
   ! If "tol" is present, small ev/eo and (ev-eo) get set to zero
      self :: INOUT
      U    :: MAT{REAL}, IN
      ev   :: VEC{REAL}, IN
      eo   :: VEC{REAL}, IN
      tol  :: REAL, optional, IN

   ENSURE(ev.dim==self.dim1,"wrong size, ev")
   ENSURE(eo.dim==self.dim2,"wrong size, eo")

      a,i :: INT
      ea,ei,ai :: REAL

      if (NOT present(tol)) then

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      else

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) ai = ZERO
            if (ea.is_zero(tol)) ai = ZERO
            if (ei.is_zero(tol)) ai = ZERO
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      end

   end

   plus_difference_divisor_with(U,ev,eo,tol) ::: PURE
   ! Do self += (ev(a)-eo(i))^-1 * U(a,i).
   ! If "tol" is present, small ev/eo and (ev-eo) get set to zero
      self :: INOUT
      U    :: MAT{REAL}, IN
      ev   :: VEC{REAL}, IN
      eo   :: VEC{REAL}, IN
      tol  :: REAL, optional, IN

   ENSURE(ev.dim==self.dim1,"wrong size, ev")
   ENSURE(eo.dim==self.dim2,"wrong size, eo")

      a,i :: INT
      ea,ei,ai :: REAL

      if (NOT present(tol)) then

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) then; ai = ZERO
            else;                      ai = ONE/ai
            end
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      else

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) then; ai = ZERO
            else;                      ai = ONE/ai
            end
            if (ea.is_zero(tol))       ai = ZERO
            if (ei.is_zero(tol))       ai = ZERO
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      end

   end

!  ================
!  Trace operations
!  ================

   trace result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the trace of self
   end

   trace_product_with(a,transpose_a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, RES?=>REAL, CAST=>), PURE
   ! Return the trace of the product of "self" with matrix "a",
   ! and if "transpose_a" is present and TRUE, then transpose "a".
   end

   dot(a) result (res) ::: PURE
   ! Synonym for trace_product_with(a) ... Return the trace of the product of
   ! "self" with matrix "a". This is really intended for use with symmetric
   ! matrices only.
      self :: IN
      a :: MAT{REAL}, IN
      res :: REAL
 ! ENSURE(.is_symmetric,"self is not symmetric")
 ! ENSURE(a.is_symmetric,"self is not symmetric")

      res = .trace_product_with(a,transpose_a=TRUE)

   end

   trace_product_with(a,b,c) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the trace of the product of "self" with matrices "a", "b" and "c".
   end

   trace_product_with(a,b,c,d,e) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the trace of the product of "self" with matrices "a", "b" ... "e".
   end

   contract_with(v) result (res) ::: pure
   ! Contract with a 1-vector.
      self :: IN
      v :: VEC{REAL}, IN
      res :: REAL

 ! ENSURE(.is_square,"self is not square")
 ! ENSURE(.dim1==v.dim,"wrong size, v")

      dim,i1,i2 :: INT

      dim = .dim1

      res = ZERO

      do i2 = 1,dim
      do i1 = 1,dim
         res = res + self(i1,i2)*v(i1)*v(i2)
      end
      end

   end

!  ========================
!  Change of basis routines
!  ========================

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Change the basis of "self" using vectors "V"; self = V^dagger self V
   end

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrix "V" (stored as a vector).
   ! self = V self V
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrices "L" and "R" (stored as
   ! vectors).  self = L self R
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new".  new = V^dagger self V
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW?=>MAT{CPX}, V?=>MAT{CPX}, TRANSPOSE_A=>DAGGER_A), PURE
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new" i.e. new = V^dagger self V. This version uses only intrinsic
   ! procedures to avoid circular dependencies.
   end

   change_basis_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
   end

   change_basis_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrices "L" and "R" (stored as
   ! vectors) and place the result in "new".  new = L self R
   end

   back_transform_using(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Back transform "self" using vectors "V", and place the result in "self".
   ! self = V self V^dagger
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! new = V self V^dagger
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW?=>MAT{CPX}, V?=>MAT{CPX}, TRANSPOSE_A=>DAGGER_A), PURE
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! i.e. new = V self V^dagger. This version uses only intrinsic calls to avoid
   ! circular dependencies.
   end

   back_transform_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Back transform "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L self R^dagger
   end

   similarity_transform(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL})
   ! Do a similarity transform of "self" using vectors "V": self = V self V^-1
   end

!  ==============
!  ADP comparison
!  ==============

   S12_with_ADP(U2,U1err,U2err,S12err) result (res)
   ! Return the determinant a 3x3 matrix
      self :: IN
      U2 :: MAT{REAL}(3,3), IN
      U1err,U2err :: VEC{REAL}(6), optional, IN
      S12err :: REAL, optional, OUT
      res :: REAL

   ENSURE(present(U1err) EQV present(U2err),"both errors must be present")

      U1,U12 :: MAT{REAL}(3,3)
      a1,a2,a12 :: MAT{REAL}@
      d1,d2,d12,R12,fac :: REAL
      i,j,k :: INT

      ! Get inverses
      U1  = self
      U12 = U1 + U2

      ! Determinants
      d1  = sqrt(U1.determinant)
      d2  = sqrt(U2.determinant)
      d12 = ONE/U12.determinant

      ! Result
      fac = d1*d2*d12
      R12 = sqrt(EIGHT*fac)
      res = 100d0*(ONE - R12)

      ! Get the error in S12
      if (NOT (present(U1err) AND present(U2err) AND present(S12err))) return

      k = 0
      S12err = ZERO
      do i = 1,3
      do j = 1,j

         k = k + 1

         a1  =  U1.adjugate(i,j)
         a2  =  U2.adjugate(i,j)
         a12 = U12.adjugate(i,j)

         S12err = S12err +  a1.determinant*U1err(k)
         S12err = S12err +  a2.determinant*U2err(k)
         S12err = S12err - a12.determinant*(U1err(k)+U2err(k))*d12*TWO

      end
      end

      S12err = (TWO*100d0*fac/R12)*S12err

   end

!  ===============================
!  Tensor change of basis routines
!  ===============================

   to_tensor_change_basis_of(V,reorder)
   ! If "V" is a matrix used to change basis for a symmetric
   ! matrix:
   !   e.g. new = V^dagger old V
   ! Then set "self" to the matrix representing the above
   ! transformation in terms of the lower triangle of
   ! "old" treated as a vector. If "reorder" is present
   ! and TRUE then the usual lower triangular order is
   ! changed to 11,22,33,12,13,23 used in crystallography
   ! NOTE: see also GAUSSIAN:d_xyz_rep_matrix_for(R)
      V :: MAT{REAL}
      reorder :: BIN, optional

   ENSURE(.is_square,"self is non-square matrix")
   ENSURE(V.is_square,"V is non-square matrix")
   ENSURE(.dim1==V.dim1.triangle_number,"Incompatible matrices")

      new :: VEC{INT}(6) = [1,4,2,5,6,3]
      n,ab,a,b,cd,c,d, nab,ncd :: INT
      swap :: BIN

      swap = FALSE
      if (present(reorder)) swap = reorder

      n = V.dim1

      if (NOT swap) then

         ! This does: M'_ab = sum_cd V_ca M_cd V_db
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     self(ab,cd) =               V(c,a)*V(d,b)
                     if (c==d) cycle
                     self(ab,cd) = self(ab,cd) + V(d,a)*V(c,b)
                  end
               end
            end
         end

      else

         ! This does: M'_ab = sum_cd V_ca M_cd V_db
         DIE_IF(n/=3,"V must be 3x3")
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               nab = new(ab)
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     ncd = new(cd)
                     self(nab,ncd) =                 V(c,a)*V(d,b)
                     if (c==d) cycle
                     self(nab,ncd) = self(nab,ncd) + V(d,a)*V(c,b)
                  end
               end
            end
         end

      end

   end

   to_tensor_back_transform_of(V,reorder)
   ! If "V" is a matrix used to change basis for a symmetric
   ! matrix:
   !   e.g. new = V old V^dagger
   ! Then set "self" to the matrix representing the above
   ! transformation in terms of the lower triangle of
   ! "old" treated as a vector. If "reorder" is present
   ! and TRUE then the usual lower triangular order is
   ! changed to 11,22,33,12,13,23 used in crystallography
      V :: MAT{REAL}
      reorder :: BIN, optional

   ENSURE(.is_square,"self is non-square matrix")
   ENSURE(V.is_square,"V is non-square matrix")
   ENSURE(.dim1==V.dim1.triangle_number,"Incompatible matrices")

      new :: VEC{INT}(6) = [1,4,2,5,6,3]
      n,ab,a,b,cd,c,d, nab,ncd :: INT
      swap :: BIN

      swap = FALSE
      if (present(reorder)) swap = reorder

      n = V.dim1

      if (NOT swap) then
         ! This does: M'_ab = sum_cd V_ac M_cd V_bd
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     self(ab,cd) =               V(a,c)*V(b,d)
                     if (c==d) cycle
                     self(ab,cd) = self(ab,cd) + V(a,d)*V(b,c)
                  end
               end
            end
         end
      else
         ! This does: M'_ab = sum_cd V_ac M_cd V_bd
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               nab = new(ab)
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     ncd = new(cd)
                     self(nab,ncd) =                 V(a,c)*V(b,d)
                     if (c==d) cycle
                     self(nab,ncd) = self(nab,ncd) + V(a,d)*V(b,c)
                  end
               end
            end
         end
      end

   end

!  ==========================
!  Operations on the diagonal
!  ==========================

   set_from_diagonal(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}), PURE
   ! Converts the diagonal vector "d" to matrix "self".
   end

   set_diagonal_to(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}), PURE
   ! Set the diagonal of "self" to vector "d"
   end

   set_diagonal_to(val) ::: get_from(MAT{INTRINSIC}, VAL?=>REAL), PURE
   ! Set the diagonal of "self" to "val"
   end

   put_diagonal_to(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}, CAST?=>), PURE
   ! Get the diagonal elements of "self" in vector "d"
   end

   increment_diagonal_by(val) ::: get_from(MAT{INTRINSIC}, VAL?=>REAL), PURE
   ! Add "val" to the diagonal of "self"
   end

   scale_diagonal_by(fac) ::: get_from(MAT{INTRINSIC}, FAC?=>REAL), PURE
   ! Weight the diagonal elements of "self" by "fac"
   end

   zero_diagonal ::: get_from(MAT{INTRINSIC}), PURE
   ! Zero the diagonal elements of "self"
   end

   zero_off_diagonal ::: get_from(MAT{INTRINSIC}), PURE
   ! Zero the off diagonal elements of "self"
   end

   max_diagonal_element result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Get the maximum element on the diagonal of the matrix
   end

   max_abs_diagonal_element result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Get the maximum absolute value of the diagonal elements of the self matrix
   end

!  ========================
!  Symmetrising and folding
!  ========================

   symmetrize ::: get_from(MAT{INTRINSIC}), PURE
   ! Set self to half of itself plus half its transpose, i.e.
   ! self = 1/2 (self + self^T)
   end

   antisymmetrize ::: get_from(MAT{INTRINSIC}), PURE
   ! Set self to half of itself minus half its transpose, i.e.
   ! self = 1/2 (self - self^T)
   end

   symmetric_fold ::: get_from(MAT{INTRINSIC}), PURE
   ! Add the upper triangle of "self" into the lower triangle
   end

   antisymmetric_fold ::: get_from(MAT{INTRINSIC}), PURE
   ! Subtract the upper triangle of "self" into the lower triangle
   end

   symmetric_reflect ::: get_from(MAT{INTRINSIC}), PURE
   ! Make the upper triangle of "self" the same as the lower triangle
   end

   antisymmetric_reflect ::: get_from(MAT{INTRINSIC})
   ! Make the upper triangle of "self" the negative of the lower triangle and
   ! make the diagonal zero.
   end

   symmetric_fold_to_triangle(tr) ::: get_from(MAT{INTRINSIC}), PURE
   ! Add the upper triangle of "self" into the lower triangle and return
   ! the lower triangle "tr" as a vector across rows.
   end

!  ======================================
!  Compression and uncompression routines
!  ======================================

   zip_matrix_to(v) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts matrix "self" to the vector "v", where vectors are
   ! stored in column order
   end

   unzip_vector(v) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the vector "v" into a matrix "self".
   end

   zip_lower_triangle_to(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the lower triangle of "self" to the vector "tr"
   ! using row order.
   end

   symmetric_unzip_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into the symmetric matrix "self".
   end

   antisymmetric_unzip_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into the antisymmetric matrix "self".
   end

   unzip_lower_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into a lower triangular matrix "self".
   end

   unzip_upper_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into a upper triangular matrix "self".
   end

   tri_size result (ltr) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns the size of the lower triangle needed to store self.
   end

   flatten(vec) ::: pure
   ! flatten  a matrix into a vector
   ! meant for singlet bra at present
      self :: IN
      vec :: VEC{REAL}, OUT

      o,p :: INT
      counter :: INT

      counter = 0
      do o = 1,.dim1
         counter = counter + 1
         vec(counter) = self(o,o)
      end

      do o = 1,.dim1
      do p = 1,o-1
          counter = counter + 1
          vec(counter) = self(o,p)
          DIE_IF(self(o,p)/=self(p,o),"not singlet")
      end
      end

   end

   unflatten(vec_mat) ::: pure
   ! unflatten a matrix into a vector of matrices
   ! meant for singlet contraction_wfs at present
     self :: IN
     vec_mat :: VEC{MAT_{REAL}}, OUT

     n,o,p,dim1,dim :: INT
     counter :: INT
     val :: REAL

     dim =  .dim1
     dim1 = int(sqrt(2*.dim2+QUARTER)-HALF)
     DIE_IF(vec_mat.dim/=dim,"vec_mat.dim/=self.dim1")
     DIE_IF(vec_mat(1).element.dim2/=dim1,"vec_mat(1).element.dim2/=dim1")

     do n = 1,dim

        counter = 0
        do o = 1, dim1
           counter=counter+1
           vec_mat(n).element(o,o)=self(n,counter)
        end

        do o = 1, dim1
        do p = 1,o-1
           counter = counter + 1
           val = self(n,counter)/sqrt(TWO)
           vec_mat(n).element(o,p) = val
           vec_mat(n).element(p,o) = val
        end
        end

     end

   end

   unflatten_triplets(vec_mat) ::: pure
   ! unflatten a matrix into a vector of matrices
   ! meant for triplet contraction_wfs at present
     self :: INOUT
     vec_mat :: VEC{MAT_{REAL}}, INOUT

     n,o,p,dim1,dim :: INT
     counter :: INT
     val :: REAL

     dim = .dim1
     dim1 = int(sqrt(2*.dim2+QUARTER)+HALF)
     DIE_IF(vec_mat.dim/=dim,"vec_mat.dim/=self.dim1")
     DIE_IF(vec_mat(1).element.dim2/=dim1,"vec_mat(1).element.dim2/=dim1")

     self = self/sqrt(TWO)

     do n = 1,dim

        counter = 0

        do o = 1, dim1-1
        do p = o+1,dim1
           counter = counter + 1
           val = self(n,counter)
           vec_mat(n).element(o,p) = val
           vec_mat(n).element(p,o) =-val
        end
        end

     end

   end

!  =================
!  Orthogonalisation
!  =================

   normalise(S) ::: get_from(MAT{INTRINSIC}), PURE
   ! Normalise the column vectors in "self" using "S" as the metric.
   end

   is_linearly_dependent(S,tol,col) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE if the columns are linearly dependent with respect to "S".
   ! If present, "tol" is the tolerance used to establish linear dependency.
   ! If present, "col" is the column number where the dependence was first
   ! noticed when Schmidt orthogonalising is used, starting from column 1.
   end

   schmidt_orthonormalise(lambda)
   ! Schmidt orthonormalise the column vectors in "self".
   ! If the eigenvalue (lambda) of a vector is less than a cutoff, then that
   ! vector is chosen to be an orthonormal component.
   ! Eigenvalues must be sorted largest to smallest.
     self :: target
     lambda :: VEC{REAL}, IN
   ENSURE(size(lambda)>=.dim2,"not enough eigenvalues")
   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")
     new,old :: VEC{REAL}*
     fac,norm :: REAL
     dim1,dim2,n,k,x,y,j :: INT
     dim1 = .dim1
     dim2 = .dim2

     ! y is set to the first vanishing eigenvalue.
     y = dim2 + 1   

     do x = 1,dim2
       if (lambda(x)<TOL(10)) then
         y = x
         exit
       end
     end

     ! Schmidt orthogonalisation.
     do n = 1,y-1
        new => self(:,n)
        do k = 1,n-1
           old => self(:,k)
           fac = dot_product(old,new)
           new = new - fac*old
        end
        norm = dot_product(new,new)
        ENSURE(norm>TOL(10),"linear dependence, vector " // n.to_str)
        new = new * (ONE/sqrt(norm))
     end

     do n = y,dim2                ! Make up some orthogonal vectors for
       do j = 1,dim1              ! the vanishing eigenvalues.
         new => self(:,n)
         new = ZERO
         new(j) = ONE
         do k = 1,n-1
            old => self(:,k)
            fac = dot_product(old,new)
            new = new - fac*old
         end
         norm = dot_product(new,new)
         if (norm>TOL(10)) then   ! We have found an orthogonal vector
           new = new * (ONE/sqrt(norm))
           exit
         else                     ! Try another
           DIE_IF(j==dim1,"cannot find an orthogonal vector")
         end
       end
     end
   end

   classical_gram_schmidt_qr(Q,R) ::: PURE
   ! Given an mxn matrix decomposes the matrix into an
   ! orthogonal mxn matrix, Q, and an nxn upper
   ! triangular matrix R by the classical Gram-Schmidt
   ! algorithm.
      self :: IN
      Q,R :: MAT{REAL}, OUT

   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")

      ! q_ represent the unnormalised columns of Q
      ! u is used to aggreagate the multiplications
      q_,u :: VEC{REAL}*
      dim1,dim2,i,j :: INT

      dim1 = .dim1
      dim2 = .dim2
     
      ! q_ has the same size as the columns of the input 
      q_.create(dim1)
      u.create(dim1)
      
      u = ZERO
      do j = 1,dim2

         ! Because self(:,j) = Q(:,i)*R(i,j),
         ! the information can be stored in Q and R
         do i = 1,j-1
            R(i,j) = dot_product(Q(:,i),self(:,j))  
         end do

         ! Aggregates information of all other columns
         do i = 1,j-1
            u = u + R(i,j)*Q(:,i)
         end do

         ! Makes this column orthonormal to all other columns
         q_ = self(:,j) - u
         u  = ZERO
         R(j,j) = norm2(q_)
         Q(:,j) = q_/R(j,j)

      end do

      ! Clean
      u.destroy
      q_.destroy

   end

   modified_gram_schmidt_qr(Q,R) ::: PURE
   ! Given an mxn matrix decomposes the matrix into an orthogonal mxn
   ! matrix, Q, and an upper triangular matrix R by the modified
   ! Gram-Schmidt algorithm.
      self :: IN
      Q,R :: MAT{REAL}, OUT

   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")

      A :: MAT{REAL}*
      dim,j,k :: INT

      dim = .dim2
     
      A.create(.dim1,.dim2)
          
      A = self

      do k = 1,dim

         ! Normalises Q
         R(k,k) = norm2(A(:,k))
         Q(:,k) = A(:,k)/R(k,k)

         ! Removes this vector from every proceeding column
         do j = k+1,dim
            R(k,j) = dot_product(Q(:,k),A(:,j))
            A(:,j) = A(:,j) - R(k,j)*Q(:,k)
         end do

      end do

      ! Clean
      A.destroy

   end

   householder_qr(R,Q) ::: PURE
   ! Given an mxn matrix decomposes the matrix into an orthogonal mxm
   ! matrix, Q (if provided), and an upper triangular mxn matrix, R,
   ! using the householder algorithm. Q is calculated by backwards
   ! accumulation.
      self :: IN
      R :: MAT{REAL}, OUT
      Q :: MAT{REAL}, OUT, optional

   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")
   ENSURE(Q.dim1 == .dim1, "Wrong size Q")
   ENSURE(Q.dim2 == .dim1, "Wrong size Q")

      ! nu is the householder vector, v is a column input and b is a
      ! vector which stores all the beta values
      nu,v,b :: VEC{REAL}*

      ! A is the editable input matrix, which stores R and the
      ! householder vectors. I is the identity.
      A,I :: MAT{REAL}*
      beta :: REAL
      dim1,dim2,j :: INT

      dim1 = .dim1
      dim2 = .dim2
     
      A.create(.dim1,.dim2)
      I.create(.dim1,.dim1)
      b.create(.dim2)

      A = self

      ! Sets up the identity matrix
      I.to_unit_matrix

      do j = 1,dim2

         ! Creates vectors for passing through subroutines
         v.create(.dim1-j+1)
         nu.create(.dim1-j+1)
         v(:) = A(j:dim1,j)

         ! Calculates nu and beta using the householder function
         v.householder_vector(nu,beta)
         b(j) = beta

         ! A = R from the top to the diagonal, beneath the diagonal
         ! the non-nu(1) elements are stored
         A(j:dim1,j:dim2) = matmul((I(1:dim1-j+1,1:dim1-j+1)&
                           -b(j)*nu.outer_product_with(nu))&
                           ,A(j:dim1,j:dim2))

         if (j < dim1) then
            A(j+1:dim1,j) = nu(2:)
         end if

         ! Clean
         v.destroy
         nu.destroy

      end do

      ! Why not rename A -> R ? DJ
      do j = 1,dim2
         R(:j,j)=A(:j,j)
      end do

      ! Calculates Q if variable given, by aggregating the
      ! multiplication of the matrix to produce Q
      if (present(Q)) then

         nu.create(.dim1)
         Q = I
         nu = ONE
         do j = dim2,1,-1

            ! Vectors are stored in A, with nu(1) = ONE
            nu(j+1:dim1) = A(j+1:dim1,j)

            ! Creates P matrix
            Q(j:dim1,j:dim1)= matmul((I(1:dim1-j+1,1:dim1-j+1)&
                          &-b(j)*nu(j:dim1).outer_product_with(nu(j:dim1)))&
                          & ,Q(j:dim1,j:dim1))
         end do
         nu.destroy

      end if

      ! Clean
      b.destroy
      I.destroy
      A.destroy

   end

   block_householder_qr(R,Q) ::: PURE
   ! Given an mxn matrix decomposes the matrix into an
   ! orthogonal mxm matrix, Q, and an upper triangular mxn
   ! matrix, R, using the householder algorithm. Q is calculated
   ! through accumulation of W and Y.
      self :: IN
      R,Q :: MAT{REAL}, OUT

   ENSURE(.dim1>=.dim2,"more vectorst than dimension of vector space")
   ENSURE(Q.dim1 == .dim1, "Wrong size Q")
   ENSURE(Q.dim2 == .dim1, "Wrong size Q")

      nu,b,v,z :: VEC{REAL}*
      A,I,W,Y,M :: MAT{REAL}*
      beta :: REAL
      dim1,dim2,j :: INT

      dim1 = .dim1
      dim2 = .dim2
     
      A.create(dim1,dim2)
      W.create(dim1,dim2)
      Y.create(dim1,dim2)
      M.create(dim1,dim1)
      I.create(dim1,dim1)
      z.create(dim1)
      b.create(dim2)

      ! Determination of A is identical to Householder qr routine.
      A = self
      I.to_unit_matrix

      do j = 1,dim2
         v.create(.dim1-j+1)
         nu.create(.dim1-j+1)
         v(:) = A(j:dim1,j)
         v.householder_vector(nu,beta)
         b(j) = beta
         A(j:dim1,j) = v
         A(j:dim1,j:dim2) = matmul((I(1:dim1-j+1,1:dim1-j+1)&
                          &-b(j)*nu.outer_product_with(nu))&
                          & ,A(j:dim1,j:dim2))
         if (j < dim1) then
            A(j+1:dim1,j) = nu(2:)
         end if
         v.destroy
         nu.destroy
      end do

      do j = 1,dim2
         R(:j,j)=A(:j,j)
      end do

      nu.create(.dim1)
      nu = ZERO

      ! Y is simply the matrix of householder vectors with 0's before
      ! the vector if the dimension of the vector is less than the
      ! dimension of the Y matrix
      Y = ZERO
      Y(1,1) = ONE
      Y(2:dim1,1) = A(2:dim1,1)

      ! W is the Z produced for each column. The first column is
      ! simply -beta*Y(1)
      W(:,1) = -b(1)*Y(:,1)
      do j = 2,dim2
         nu(j-1) = ZERO
         nu(j) = ONE
         nu(j+1:dim1) = A(j+1:dim1,j)
         M = I + matmul(W(:,1:j-1),transpose(Y(:,1:j-1))) 
         z(:) = -b(j)*matmul(M,nu) 
         W(:,j) = z(:)
         Y(j,j) = ONE
         Y(j+1:dim1,j) = A(j+1:dim1,j)
       end do

       ! As per the proof from Golub and van Loan
       Q = I + matmul(W,transpose(Y))

       ! Clean
       b.destroy
       z.destroy
       I.destroy
       M.destroy
       Y.destroy
       W.destroy
       A.destroy

   end

   fast_givens_qr(R,Q) ::: PURE
   ! Given an mxn matrix decomposes the matrix into an
   ! orthogonal mxm matrix, Q (if provided), and an upper triangular mxn
   ! matrix, R, using the fast Givens algorithm.
      self :: IN
      R :: MAT{REAL}, OUT
      Q :: MAT{REAL}, OUT, optional

   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")

      di :: VEC{REAL}*
      F,M,A,D,G :: MAT{REAL}*
      dim1,dim2,i,j,k,t :: INT
      alpha,beta :: REAL

      dim1 = .dim1
      dim2 = .dim2
      
      di.create(dim1)
      A.create(dim1,dim2)
      D.create(dim1,dim1)
      M.create(dim1,dim1)
      F.create(dim1,dim1)
      G.create(2,2)

      A = self
      di = ONE
      D = ZERO
      M.to_unit_matrix
      F.to_unit_matrix

      ! If Q present, calculates the matrix M,
      ! so Q can be calculated
      if (present(Q)) then

         do j = 1,dim2
         do i = dim1,j+1,-1

            A(i-1:i,j).fast_givens_transformation(di(i-1:i),alpha,beta,t)

           ! F is the scaled to dimension mxm matrix
           ! version of the 2x2 Givens transform 
           ! matrix
            F = ZERO
            do k = 1,dim1
               F(k,k) = ONE
            end do

            if (t == 1) then

               ! F and G are determined by the type variable given
               ! from the fast givens transform         
               G = ONE
               F(i-1,i-1) = beta
               F(i,i) = alpha
               F(i,i-1) = ONE
               F(i-1,i) = ONE
               G(1,1) = beta
               G(2,2) = alpha

               ! Removes elements from the initial matrix.
               A(i-1:i,j:dim2) = matmul(transpose(G),A(i-1:i,j:dim2))

               ! M is aggregated so Q can be calculated later         
               M = matmul(M,F)

            else

               G = ONE
               F(i,i-1) = beta
               F(i-1,i) = alpha
               G(1,2) = alpha
               G(2,1) = beta
               A(i-1:i,j:dim2) = matmul(transpose(G),A(i-1:i,j:dim2))
               M = matmul(M,F)

            end if

         end do
         end do

         ! D is calculated so Q and R can be calculated 
         do i = 1,dim1
            D(i,i) = 1/sqrt(di(i))
         end do

         R.to_product_of(D,A)
         Q.to_product_of(M,D) 

      else

         ! As above, without the need to calculate Q
         do j = 1,dim2
         do i = dim1,j+1,-1

            A(i-1:i,j).fast_givens_transformation(di(i-1:i),alpha,beta,t)

            if (t == 1) then

               G = ONE
               G(1,1) = beta
               G(2,2) = alpha
               A(i-1:i,j:dim2) = matmul(transpose(G),A(i-1:i,j:dim2))

            else

               G = ONE
               G(1,2) = alpha
               G(2,1) = beta
               A(i-1:i,j:dim2) = matmul(transpose(G),A(i-1:i,j:dim2))

            end if

         end do
         end do

         do i = 1,dim1
            D(i,i) = 1/sqrt(di(i))
         end do

         R.to_product_of(D,A)

      end if

      di.destroy
      A.destroy
      D.destroy
      M.destroy
      F.destroy
      G.destroy

   end

   schmidt_orthonormalise(S,scales,n_dependent,ld_tol)
   ! Schmidt orthonormalise the vectors in "self" using "S" as the
   ! metric
   ! "scales" is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are orthonormalised. the others are counted (n_dependent)
   ! and rejected at the end of the list.
     self :: target
     S :: MAT{REAL}, IN
     scales :: VEC{REAL}, OUT
     n_dependent :: INT, OUT
     ld_tol :: REAL, optional

   ENSURE(NOT S.is_zero,"S is zero matrix")

     decreasing_vec :: MAT{REAL}*
     old,new :: VEC{REAL}*
     keep :: VEC{REAL}*
     fac :: REAL
     tol :: REAL
     norm :: REAL
     n,o,p,dim1,dim2 :: INT
     skip :: VEC{BIN}*
     n_dependent=0
     tol=LINEAR_DEPENDENCE_TOL
     if(present(ld_tol)) tol=ld_tol
     dim1= .dim1
     dim2= .dim2
     keep.create(dim2)
     skip.create(dim1)
     skip = FALSE
!eliminate function with small norms
     do n = 1,dim1
       new => self(n,:)
       norm = S.dot(new,new)
       if(norm < tol) then
         n_dependent=n_dependent+1
         skip(n)=TRUE
         scales(n)=norm
       end
     end
     DIE_IF(skip(1),"ground state is quasilinearly dependent")
     do n = 1,dim1
        if(skip(n)) cycle
        new => self(n,:)
        keep = new
        norm = S.dot(keep,keep)
!orthogonalisation
        do o = 1,n-1
           if(skip(o)) cycle
           old => self(o,:)
           fac = S.dot(old,new)
           new = new - fac*old
           norm = norm - fac*fac
        end
        scales(n) = norm
     !   if(norm>MAT_LINEAR_DEPENDENCE_TOL) then
        if(norm>tol) then
!normalisation of the orthogonalised vector
          norm = sqrt(norm)
          new = new/norm
        else
          n_dependent=n_dependent+1
          new=keep
          skip(n) = TRUE
        end
     end
     nullify(new)
     nullify(old)
     keep.destroy
!reject the quasilinearly dependent vectors at the end of the array
     o=0
     p=0
     decreasing_vec.create(dim1,dim2)
     do n=1,dim1
       if(NOT skip(n)) then
         p=p+1
         decreasing_vec(p,:)=self(n,:)
       else
         decreasing_vec(dim1-o,:)=self(n,:)
         o=o+1
       end
     end
     self=decreasing_vec
     decreasing_vec.destroy
     skip.destroy
   end

   schmidt_orthonormalise(S,indices,scales,n_dependent,ld_tol) ::: leaky
   ! Schmidt orthonormalise the vectors in "self" using "S" as the
   ! metric.
   ! "scales" is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are orthonormalised. the others are counted (n_dependent)
   ! rejected at the end of the list, their new order is in indices
   ! (which makes the routine leaky).
     self :: target
     indices :: VEC{INT}*
     S :: MAT{REAL}, IN
     scales :: VEC{REAL}, OUT
     n_dependent :: INT, OUT
     ld_tol :: REAL, optional

   ENSURE(NOT S.is_zero,"S is zero matrix")

     decreasing_vec :: MAT{REAL}*
     old,new :: VEC{REAL}*
     keep :: VEC{REAL}*
     fac :: REAL
     tol :: REAL
     norm :: REAL
     n,o,p,dim1,dim2 :: INT
     skip :: VEC{BIN}*
     n_dependent=0
     tol=LINEAR_DEPENDENCE_TOL
     if(present(ld_tol)) tol=ld_tol
     dim1= .dim1
     dim2= .dim2
     keep.create(dim2)
     skip.create(dim1)
     skip = FALSE
!eliminate function with small norms
     do n = 1,dim1
       new => self(n,:)
       norm = S.dot(new,new)
       if(norm < tol) then
         n_dependent=n_dependent+1
         skip(n)=TRUE
         scales(n)=norm
       end
     end
     DIE_IF(skip(1),"ground state is quasilinearly dependent")
     do n = 1,dim1
        if(skip(n)) cycle
        new => self(n,:)
        keep = new
        norm = S.dot(keep,keep)
!orthogonalisation
        do o = 1,n-1
           if(skip(o)) cycle
           old => self(o,:)
           fac = S.dot(old,new)
           new = new - fac*old
           norm = norm - fac*fac
        end
        scales(n) = norm
     !   if(norm>MAT_LINEAR_DEPENDENCE_TOL) then
        if(norm>tol) then
!normalisation of the orthogonalised vector
          norm = sqrt(norm)
          new = new/norm
        else
          n_dependent=n_dependent+1
          new=keep
          skip(n) = TRUE
        end
     end
     nullify(new)
     nullify(old)
     keep.destroy
!reject the quasilinearly dependent vectors at the end of the array
     o=0
     p=0
     decreasing_vec.create(dim1,dim2)
     indices.create(dim1)
     do n=1,dim1
       if(NOT skip(n)) then
         p=p+1
         decreasing_vec(p,:)=self(n,:)
         indices(n)=p
       else
         decreasing_vec(dim1-o,:)=self(n,:)
         indices(n)=dim1-o
         o=o+1
       end
     end
     self=decreasing_vec
     decreasing_vec.destroy
     skip.destroy
   end

   schmidt_orthonormalise(S,scales) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric. If "scales" is present, it is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are normalised.
   end

   schmidt_orthonormalise(scale) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" metric. If
   ! "scale" is present, it is set to the product of the normalisation
   ! factors used to normalise each column after the Schmidt
   ! procedure.
   end

   schmidt_orthonormalise(S,scale) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric. If "scale" is present, it is set to the product of the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure.
   end

   schmidt_orthonormalise(S,from,to) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the *column* vectors in "self" using "S" as the
   ! metric. Only the columns starting from index "from" are orthonormalised,
   ! and further, those columns are only orthonormalised to first columns, up to
   ! the column with index "to".
   end

   reverse_schmidt_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric.
   end

   reverse_schmidt_orthogonalise ::: get_from(MAT{INTRINSIC}, CAST=>)
   ! Schmidt orthonormalise the column vectors in "self" using unit metric.
   end

   symmetrically_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Symmetrically orthonormalise the column vectors in "self" using
   ! "S" as the metric, which must be real and positive definite.
   end

   make_diagonally_dominant(permutation) ::: get_from(MAT{INTRINSIC})
   ! Rearrange the order of the columns of self so that the largest magnitude
   ! elements in each column occur along the diagonal. If "permutation" is
   ! present, it is the array which achieves this ordering, i.e. at the end of
   ! the routine, what is done is: self = self(:,permutation).
   end

!  ========================
!  Idempotency purification
!  ========================

   McWeeny_purify(S) ::: PURE
   ! Apply the McWeeny purification to obtain an idempotent density
   ! matrix, using "S" as the metric.
      self :: INOUT
      S :: MAT{REAL}, IN

      W,PS,PSPS :: MAT{REAL}*
      diff :: REAL
      n :: INT

      n = .dim1

      W.create(n,n)
      PS.create(n,n)
      PSPS.create(n,n)

      W    = self
      PS   = self
      PSPS = self

      do

         ! McWeeny term
         PS.to_product_of(self,S)
         W.to_scaled_product_of(PS,self,fac=THREE)
         PSPS.to_product_of(PS,PS)
         W.plus_scaled_product_of(PSPS,self,fac=-TWO)

         ! Same?
         diff = maxval(abs(self - W))
         self = W
         if (diff<REAL_EPSILON) exit


      end

      PSPS.destroy
      PS.destroy
      W.destroy


   end

   Holas_5th_order_purify(S) ::: PURE
   ! Apply the Holas's 5th order purification to obtain an idempotent
   ! density matrix, using "S" as the metric. This was shown by
   ! J. Kim and Y. Jung (2011) CPL 511 p. 159-60.
      self :: INOUT
      S :: MAT{REAL}, IN

      W,PS,PS2,PS3 :: MAT{REAL}*
      diff :: REAL
      n :: INT

      n = .dim1
      W.create(n,n)
      PS.create(n,n)
      PS2.create(n,n)
      PS3.create(n,n)

      W   = self
      PS  = self
      PS2 = self
      PS3 = self

      do

         ! Holas term
         PS.to_product_of(self,S)
         PS2.to_product_of(PS,PS)
         W.to_scaled_product_of(PS2,self,fac=TEN)

         PS3.to_product_of(PS2,PS)
         W.plus_scaled_product_of(PS3,self,fac=-FIFTEEN)

         PS2.to_product_of(PS3,PS)
         W.plus_scaled_product_of(PS2,self,fac=SIX)

         ! Same?
         diff = maxval(abs(self - W))
         self = W
         if (diff<REAL_EPSILON) exit

      end

      PS3.destroy
      PS2.destroy
      PS.destroy
      W.destroy


   end

!  =====================
!  Eigenproblem routines
!  =====================

   diagonalize_by_jacobi(eigenvalues,eps,max_iterations)
   ! Diagonalises "self" using the Jacobi rotations method. Returns
   ! the "eigenvalues". Input the accuracy "eps" or the maximum number
   ! of iterations "max_iter", if desired.
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eps :: REAL, optional, OUT
      max_iterations :: INT, optional, IN

  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")

      i,j,iter,max_iter  :: INT
      accuracy,tol :: REAL
      done :: BIN
      W :: MAT{REAL}*

      accuracy = TOL(12)
      if (present(eps)) accuracy = eps

      max_iter = 30
      if (present(max_iterations)) max_iter = max_iterations

      W.create_copy(self)

      iter = 0

      do

        iter = iter + 1
        ENSURE(NOT iter>max_iter,"too many iterations")
        if (iter>max_iter) exit

        tol = accuracy
        if (iter<=3) tol = TOL(1)*(MAT{REAL}:sum_elements(abs(W)) - W.trace)

        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j)
        end
        end

        done = done AND iter>3

        if (done) exit

      end

      W.put_diagonal_to(eigenvalues)

      W.destroy

   end

   diagonalize_by_jacobi(eigenvalues,eigenvectors,eps,max_iterations) ::: PURE
   ! Diagonalises "self" using the Jacobi rotations method. Returns the
   ! "eigenvalues". Input the accuracy "eps" or the maximum number of iterations
   ! "max_iter", if desired.
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT
      eps :: REAL, optional, IN
      max_iterations :: INT, optional, IN

  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
  ENSURE(eigenvectors.is_square, "eigenvectors are not square")
  ENSURE(eigenvalues.dim1>=.dim1,"wrong size, eigenvectors")

      i,j,iter,max_iter  :: INT
      accuracy,tol :: REAL
      done :: BIN
      W :: MAT{REAL}*

      accuracy = TOL(8)
      if (present(eps)) accuracy = eps

      max_iter = 500
      if (present(max_iterations)) max_iter = max_iterations

      W.create_copy(self)

      eigenvectors.to_unit_matrix

      iter = 0

      do

        iter = iter + 1
        ENSURE(NOT iter>max_iter,"too many iterations")
        if (iter>max_iter) exit

        tol = accuracy
        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j,eigenvectors)
        end
        end

        done = done AND iter>3
        if (done) exit

      end

      W.put_diagonal_to(eigenvalues)

      W.destroy

   end

   solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors"
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT

      .solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors)

   end

   solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors) ::: private
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors". LAPACK version.
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
   ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")

      W :: VEC{REAL}*
      dim,fail,lwork :: INT

      dim = .dim1
      lwork = max(dim*dim,3*dim-1)
      W.create(lwork)
      eigenvectors = self
      fail = 0
      call dsyev("V","L",dim,eigenvectors,dim,eigenvalues,W,lwork,fail)
      W.destroy

   ENSURE(fail==0,"no solution, error found")

   end

   internal_vectors(eigenvectors2,iv_tol) ::: leaky
   ! Extract the internal vectors of a matrix i.e. vectors in the
   ! orthocomplement of the kernel of the matrix.
   !leaky because the number of outputed internal vectors is not known
   !beforehand
     eigenvectors2 :: MAT{REAL}*
     iv_tol :: REAL, optional
     ENSURE(.dim1==.dim2,"matrix not square")
     eigenvalues :: VEC{REAL}*
     eigenvectors :: MAT{REAL}*
     tol :: REAL
     i,h,dim :: INT

     tol = INTERNAL_GEMINAL_TOL
     if (present(iv_tol)) tol = iv_tol

     dim = .dim1
     eigenvalues.create(dim)
     eigenvectors.create(dim,dim)
     .solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
     h = count(mask= eigenvalues >tol)
     DIE_IF(count(mask= eigenvalues <  -TOL(10))/=0,"matrix not positive")
     DIE_IF(h==0,"no internal vector")

     eigenvectors2.create(h,dim)
     h=0
     do i=1,dim
       if (NOT eigenvalues(i).is_zero(tol)) then
         h=h+1
         eigenvectors2(h,:)=eigenvectors(:,i)
       end
     end

     eigenvalues.destroy
     eigenvectors.destroy

   end

!  ========================
!  Linear equation routines
!  ========================

   solve_linear_equation(rhs,solution,fail)
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yeilding vector "solution" as the answer
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      fail :: BIN, OUT, optional

      .solve_linear_equation_LAPACK(rhs,solution,fail)

   end

   solve_linear_equation_LAPACK(rhs,solution,fail) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yielding vector "solution" as the answer. LAPACK version.
      self :: INOUT
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      fail :: BIN, OUT, optional

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")

      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim,nrhs,err :: INT

      dim = rhs.dim
      nrhs = 1
      nullify(LU); LU.create(dim,dim)
      nullify(pivot); pivot.create(dim)

      LU = self
      solution = rhs

      call dgesv(dim,nrhs,LU,dim,pivot,solution,dim,err)

      if (present(fail)) then
         fail = FALSE
         if (err/=0) fail = TRUE
      else
         ENSURE(err==0,"no solution, error found")
      end

      pivot.destroy
      LU.destroy

   end

   solve_linear_equations(rhs,solution)
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
      rhs :: MAT{REAL}, IN
      solution :: MAT{REAL}, OUT

      .solve_linear_equations_LAPACK(rhs,solution)

   end

   solve_linear_equations_LAPACK(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
   ! LAPACK version
      self :: INOUT
      rhs :: MAT{REAL}, IN
      solution :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim1==.dim2,"rhs incompatible with coefficient matrix")
   ENSURE(nrhs>0,"no rhs vectors")

      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim1,nrhs,err :: INT

      dim1 = rhs.dim1
      nrhs = rhs.dim2

      LU.create(dim1,dim1)
      pivot.create(dim1)

      LU = self
      solution = rhs

      call dgesv(dim1,nrhs,LU,dim1,pivot,solution,dim1,err)

      pivot.destroy
      LU.destroy

   ENSURE(err==0,"no solution, error found")

   end

   solve_convex_linear_equation(rhs,solution,plist,keep0,keep1,fail)
   ! This routine solves the quadratic minimisation problem:
   !    f(X) = rhs . X  -  HALF * X^T . self . X  |  X>=0
   ! over all the elements in "plist", subject to the constraint that the
   ! "solution" X is positive for all elements in "plist". Any elements of the
   ! "solution" not in "plist" are not constrained to be positive nor do they
   ! participate in the evaluation of the quadratic function f -- they are
   ! usually lagrange multipliers. This routine involves solving reduced linear
   ! equations with "self" as the LHS and "rhs" as the RHS, over all partitions
   ! of the elements in "plist".  If "keep0" is present, then the indices in
   ! this sublist of "plist" must be kept when considering all partitions. If
   ! "keep1" is present, then the indices in this sublist of "plist" must be
   ! kept plus at most one extra index for each index in "keep1", and further,
   ! the positivity constraint is relaxed on these indices. It is an error if
   ! "keep0" and "keep1" are both present. If present, "fail" is set TRUE if no
   ! solutions are found, otherwise the routine terminates with an error.
   ! WARNING: if the dimension of the matrix is too large, this routine will
   ! take a long time.
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      plist :: VEC{INT}, IN
      keep0,keep1 :: VEC{INT}, IN, optional
      fail :: BIN, OUT, optional

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
   ENSURE(plist.dim<=.dim1,"plist to large")
   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
   ENSURE(NOT (present(keep0) AND present(keep1)),"specify only keep0 or keep1")

      pdim,rdim,kdim,k,n,n_combinations :: INT
      ulist,list :: VEC{INT}*
      combination :: MAT{INT}*
      sol,sol0,rhs0 :: VEC{REAL}*
      e,e0 :: REAL
      found_one,even :: BIN

!      if (.dim1==6) then
!      list.create(4)
!      sol.create(.dim1)
!      sol = ZERO
!      sol(1) = 0.3
!      sol(2) = 0.7
!      sol(4) = 0.4
!      sol(5) = 0.6
!      list = [1,2,4,5]
!            e0 = dot_product(rhs(list),sol(list)) &
!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!      print *, "===in MAT, average energy =",e0
!      sol.destroy
!      list.destroy
!      end
!!      if (.dim1==3) then
!!      list.create(2)
!!      sol.create(.dim1)
!!      sol = ZERO
!!      sol(1) = 0.3
!!      sol(2) = 0.7
!!      list = [1,2]
!!            e0 = dot_product(rhs(list),sol(list)) &
!!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!!      print *, "===in MAT, average energy =",e0
!!      sol.destroy
!!      list.destroy
!!      end
      even = FALSE
      if (present(keep0)) then
         ENSURE(keep0.has_all_elements_common_with(plist),"keep0 not in plist")
         kdim = keep0.dim
         even = kdim.is_even
      end
      if (present(keep1)) then
         ENSURE(keep1.has_all_elements_common_with(plist),"keep1 not in plist")
         kdim = keep1.dim
         even = kdim.is_even
      end
      pdim = plist.dim
      WARN_IF(pdim>=20,"LHS dimension may be too large")
      found_one = FALSE
      e = huge(ONE)
      sol.create(.dim1)
      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
      ulist.prune(plist)                          ! ulist = all - plist = unconstrained
    ! print *, "-----------start------------"
    ! print *, "even =",even
    ! print *, "plist:"
    ! print *, plist
    ! print *, "ulist:"
    ! print *, ulist
      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
    ! print *, "---> combinations of length k =", k
         if (present(keep1)) then
            if (k>2*kdim) cycle
         end
         n_combinations = int(pdim.choose(k))
         combination.create(k,n_combinations)
         plist.make_combinations_of_length(k,combination)
         rdim = k + .dim1 - pdim
         rhs0.create(rdim)
         sol0.create(rdim)
         list.create(rdim)                        ! list = comb(plist) + ulist
         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
    ! print *, "combination:"
    ! print *, combination(:,n)
            if (present(keep1)) then               ! if present, keep only these elements
               if (NOT keep1.has_all_elements_common_with(combination(:,n))) cycle
            end
            if (present(keep0)) then               ! if present, keep only these elements
    ! print *, "keep0:"
    ! print *, keep0
             ! if (NOT keep0.has_all_elements_common_with(combination(:,n))) cycle
               if (NOT keep0.has_elements_common_with(combination(:,n))) cycle
               if (even AND all(combination(:,n)> .dim1/2)) cycle
               if (even AND all(combination(:,n)<=.dim1/2)) cycle
            end
            list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
            list(k+1:) = ulist                    ! Always add the list of unconstrained elements
    ! print *, "list:"
    ! print *, list
    ! print *, "rhs:"
    ! print *, rhs
            rhs0 = rhs(list)
    ! print *, "rhs0:"
    ! print *, rhs0
    ! print *, "lhs0:"
    ! print *, self(list,list)
            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
            sol(list) = sol0
    ! print *, "sol0:"
    ! print *, sol0
    ! print *, "sol:"
    ! print *, sol
            if (NOT present(keep1) AND any(sol(list(1:k))<ZERO)) cycle  ! Unacceptable ..............
            e0 = dot_product(rhs(list),sol(list)) &
               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
    ! print *, "e0 = ",e0
            if (e0>=e) cycle                      ! Found a better solution before
            solution = ZERO                       ! Zero non-"list" solution elements
            solution(list) = sol(list)            ! Keep this solutions
    ! print *, "new solution found:"
    ! print *, solution
            e = e0                                ! Keep this E value
            found_one = TRUE
         end
         list.destroy
         sol0.destroy; rhs0.destroy
         combination.destroy
      end
      ulist.destroy
      sol.destroy
      if (present(fail)) then
         if (NOT found_one) then; fail = TRUE
         else;                    fail = FALSE
         end
      else
         DIE_IF(NOT found_one,"acceptable solution was not found")
      end
   end

!  ============
!  Least squares
!  ============

   solve_normal_equations(grad,shift,delta) ::: selfless, public, leaky
   ! Get the "shift" in some parameter vector by solving 
   ! the normal equations given a gradient vector "grad".
   ! "self" is used just workspace for the Hessian.
      grad  :: VEC{REAL}, IN
      shift :: VEC{REAL}, OUT
      delta :: REAL, optional, IN

      H :: MAT{REAL}*
      dim, i,j :: INT

      ! Hessian
      dim = grad.dim
      H.create(dim,dim)

      ! Make the normal matrix (outer product)
      do i = 1,dim
      do j = 1,dim
         H(i,j) = TWO * grad(i)*grad(j)
      end
      end

      ! Solve for the shifts .dX (leaky)
      H.solve_ill_linear_equations(grad,shift,1.0d-17,delta)

   end

   solve_ill_linear_equations(grad,solution,tol_near_0,delta) ::: leaky
   ! Solve a set of ill-conditioned linear equations. Eigenvalues of
   ! "self" less than "tol_near_0" are ignored.
      grad :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      tol_near_0 :: REAL, IN
      delta :: REAL, optional, IN

   ENSURE(.is_square,"not square")

      rhs :: VEC{REAL}*
      eval :: VEC{REAL}*
      eval_near_0 :: VEC{REAL}*
      evec_near_0 :: MAT{REAL}*
      ival :: VEC{REAL}*
      inv,evec :: MAT{REAL}*
    ! eval :: VEC{REAL}*
      n_near_0, d,i,j :: INT
      del :: REAL

      ! Delta value
      del = ONE
      if (present(delta)) del = delta

      ! Temporaries
      d = .dim1
      eval.create(d)
      ival.create(d)
      evec.create(d,d)
      inv.create(d,d)

      ! Solve the eigenvalue problem
      .solve_symmetric_eigenproblem(eval,evec)

      ! Count eigenvalues which are nearly zero (leaky)
      n_near_0 = count(eval<=ZERO OR abs(eval)<=tol_near_0)

      eval_near_0.create(n_near_0)
      evec_near_0.create(d,n_near_0)

      j = 0

      do i = 1,d

         if (eval(i)<=ZERO OR abs(eval(i))<=tol_near_0) then

            j = j + 1
            eval_near_0(j)   = eval(i)
            evec_near_0(:,j) = evec(:,i)
            ival(i)          = ZERO

         else

            ival(i) = ONE/eval(i)

         end

      end

      ! Make the inverse
      evec = transpose(evec)

      do i = 1,d
      do j = 1,d
         inv(i,j) = sum(evec(:,i)*ival(:)*evec(:,j))
      end
      end

      evec.destroy
    ! eval.destroy

      ! Get scaled RHS
      rhs.create_copy(grad)
      rhs = TWO*delta*grad

      ! Get the solution
      solution.to_product_of(inv,rhs)
      solution = -solution

      ! Clean
      rhs.destroy
      evec_near_0.destroy
      eval_near_0.destroy

      evec.destroy
      ival.destroy
      eval.destroy

   end

   solve_ill_linear_equations(rhs,solution,tol_near_0,n_near_0,eval_near_0,evec_near_0,eval,inverse,CM) ::: leaky
   ! Solve a set of ill-conditioned linear equations. Eigenvalues of
   ! "self" less than "tol_near_0" are ignored.
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      tol_near_0 :: REAL, IN
      n_near_0 :: INT, OUT
      eval_near_0 :: VEC{REAL}*
      evec_near_0 :: MAT{REAL}*
      eval :: VEC{REAL}*
      inverse,CM :: MAT{REAL}, OUT, optional

   ENSURE(.is_square,"not square")

      ival :: VEC{REAL}*
      inv,evec :: MAT{REAL}*
    ! eval :: VEC{REAL}*
      d,i,j :: INT

      ! Temporaries
      d = .dim1
      eval.create(d)
      ival.create(d)
      evec.create(d,d)
      inv.create(d,d)

      ! Solve the eigenvalue problem
      .solve_symmetric_eigenproblem(eval,evec)

      ! Count eigenvalues which are nearly zero (leaky)
      n_near_0 = count(eval<=ZERO OR abs(eval)<=tol_near_0)

      eval_near_0.destroy
      eval_near_0.create(n_near_0)
      evec_near_0.destroy
      evec_near_0.create(d,n_near_0)

      j = 0

      do i = 1,d

         if (eval(i)<=ZERO OR abs(eval(i))<=tol_near_0) then

            j = j + 1
            eval_near_0(j)   = eval(i)
            evec_near_0(:,j) = evec(:,i)
            ival(i)          = ZERO

         else

            ival(i) = ONE/eval(i)

         end

      end

      ! Make the inverse
      evec = transpose(evec)

      do i = 1,d
      do j = 1,d
         inv(i,j) = sum(evec(:,i)*ival(:)*evec(:,j))
      end
      end

      evec.destroy
    ! eval.destroy

      ! Get the solution
      solution.to_product_of(inv,rhs)

      ! Get uncertainties
      if (present(inverse)) then
         inverse = inv
      end

      ! Get correlation matrix
      if (present(CM)) then

         do i = 1,d
         do j = 1,d
            if      (inv(i,i).equals(ZERO,tol_near_0)) then
               CM(i,j) = ZERO
            else if (inv(j,j).equals(ZERO,tol_near_0)) then
               CM(i,j) = ZERO
            else
               CM(i,j) = inv(i,j)/sqrt(inv(i,i)*inv(j,j))
            end
         end
         end

      end

      inv.destroy

   end

!  ========
!  Cholesky
!  ========

   cholesky_decomposition(tr) ::: get_from(MAT{INTRINSIC})
   ! Decompose self into lower triangular matrices "L"
   !   self = L L^T or self = L L^\dagger
   ! where L is a lower triangular matrix stored as an array
   ! going across the rows i.e. (1,1), (2,1), (2,2), (3,1) ...
   end

   cholesky_decomposition(L) ::: get_from(MAT{INTRINSIC}), conjg=>1*
   ! Decompose self into lower triangular matrices "L"
   !   self = L L^T or self = L L^\dagger
   end

!  ==========================================================
!  Matrix functions: square roots, inverses, and exponentials
!  ==========================================================

   to_inverse_of(R)
   ! self = (R)^(-1); can have R=self
      self :: INOUT
      R :: MAT{REAL}, IN

      .to_inverse_of_LAPACK(R)

   end

   to_inverse_of_LAPACK(R) ::: private
   ! self = (R)^(-1); can have R=self. LAPACK version.
      self :: INOUT
      R :: MAT{REAL}, IN

   ENSURE(.is_square,"not square")
   ENSURE(.is_same_shape_as(R),"not same shape as R")

      W :: MAT{REAL}*
      ipiv :: VEC{INT}*
      d,d2,fail :: INT

      d  = size(R,1)
      d2 = d*d
      self = R
      ipiv.create(d)
      W.create(d,d)
      fail = 0

      call dgetrf(d,d,self,d,ipiv,fail)
      ENSURE(fail==0,"failed LU factorisation, fail = "//trim(fail.to_str))
      call dgetri(d,self,d,ipiv,W,d2,fail)
      ENSURE(fail==0,"failed back substitution, fail = "//trim(fail.to_str))

      ipiv.destroy
      W.destroy

   end

   to_pseudo_inverse_of(R,tol_0)
   ! self = (R)^(-1); can have R=self
      self :: INOUT
      R :: MAT{REAL}, IN
      tol_0 :: REAL, optional, IN

   ENSURE(.is_square,"self must be a square matrix")
   ENSURE(.is_same_shape_as(R),"self and R incomptabile")

      evec :: MAT{REAL}*
      eval :: VEC{REAL}*
      d,i,j,k :: INT
      tol,temp :: REAL

      ! Get tolerance for zero eigenvalue
      tol = REAL_EPSILON
      if (present(tol_0)) tol = tol_0

      ! Temporaries
      d = .dim1
      eval.create(d)
      evec.create(d,d)

      ! Solve the eigenvalue problem
      R.solve_symmetric_eigenproblem(eval,evec)

      ! Invert large eigenvalues
      j = 0
      do i = 1,d
         if (abs(eval(i))>tol) then; eval(i) = ONE/eval(i)
         else;                       eval(i) = ZERO
         end
      end

      ! Make the pseudo-inverse
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      ! Clean
      evec.destroy
      eval.destroy

   end

   to_inverse_of(R_eval,R_evec,tol,n_small)
   ! self = R^(-1), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on zero eigenvalues.  If "n_small" return the number of
   ! small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, target, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT

      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k,n :: INT
      val :: STR
      eps,temp :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Get inverse inverse eigenvalues
      d = R_eval.dim

      eval.create(d)

      n = 0
      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            val = temp.to_str("e15.8")
            DIE("non-positive eigenvalue, "// trim(val))
         else if (temp<=eps) then
            val = temp.to_str("e15.8")
            WARN("small eigenvalue, "// trim(val))
            n = n + 1
         end

         if (temp<=eps) then; eval(i) = ZERO
         else;                eval(i) = ONE/temp
         end

      end

      if (present(n_small)) n_small = n

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_sqrt_of(R,tol)
   ! Set self to the sqrt(R). Cannot have R=self. Negative eigenvalues
   ! are zeroed.
      self :: OUT
      R :: MAT{REAL}, IN
      tol :: REAL, optional, IN

 ! Looks like compiler problem for gfortran on 3/3/09
 ! ENSURE(.is_symmetric,"not symmetric")

      evec :: MAT{REAL}* DEFAULT_NULL
      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k :: INT
      eps,temp :: REAL

      eps = TOL(20)
      if (present(tol)) eps = tol

      d = R.dim1

      eval.create(d)
      evec.create(d,d)

      R.solve_symmetric_eigenproblem(eval,evec)

      do i = 1,d
         temp = abs(eval(i))
         if (temp <= eps) then
         !  WARN("non-positive eigenvalue, " // trim(temp.to_str("e15.8")))
            eval(i) = ZERO
         else
            eval(i) = sqrt(temp)
         end
      end

      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      evec.destroy
      eval.destroy

   end

   to_sqrt_of(R_eval,R_evec,tol)
   ! self = sqrt(R), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec".
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, target, IN
      tol :: REAL, optional, IN

      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k :: INT
      val :: STR
      eps,temp :: REAL

      eps = TOL(20)
      if (present(tol)) eps = tol

      d = R_eval.dim

      eval.create(d)

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            val = temp.to_str("e15.8")
            DIE("non-positive eigenvalue, "// trim(val))
         else if (temp<=eps) then
            val = temp.to_str("e15.8")
            WARN("small eigenvalue, "// trim(val))
            temp = abs(temp)
         end

         if (temp<=eps) then; eval(i) = ZERO
         else;                eval(i) = sqrt(temp)
         end

      end

      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_inverse_sqrt_of(R,tol,n_small,n_negative,shift)
   ! Set self = sqrt(R)^(-1). Cannot have R = self.
   ! If "tol" is present use that to decide on zero eigenvalues.
   ! If "n_small" return the number of small eigenvalues.
   ! If "shift" then use this value instead of small eigenvalues.
      self :: OUT
      R :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT
      shift :: REAL, optional, IN

 ! Looks like compiler problem for gfortran on 3/3/09
 ! ENSURE(.is_symmetric,"not symmetric")

      evec :: MAT{REAL}*
      eval :: VEC{REAL}*
      d,i,j,k,n_n,n_s :: INT
      eps,sh,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Shift for zeo eigenvalues
      sh = ZERO
      if (present(shift)) sh = shift

      ! Solve eigenproblem
      d = R.dim1

      eval.create(d)
      evec.create(d,d)

      R.solve_symmetric_eigenproblem(eval,evec)

      ! Inverse sqrt eigenvalues
      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = eval(i)

         if (temp<-eps) then
            ! Negative eigenvalues
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            ! Small eigenvalues
            eval(i) = sh   
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            ! Normal eigenvalues
            eval(i) = ONE/sqrt(temp)
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      evec.destroy
      eval.destroy

   end

   to_inverse_sqrt_of(R_eval,R_evec,tol,n_small,n_negative,shift) ::: PURE
   ! self = sqrt(R)^(-1), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on zero eigenvalues.  If "n_small" return the number of
   ! small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT
      shift :: REAL, optional, IN

      eval :: VEC{REAL}*
      d,i,j,k,n_n,n_s :: INT
      eps,sh,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Shift for zeo eigenvalues
      sh = ZERO
      if (present(shift)) sh = shift

      ! Get inverse sqrt eigenvalues
      d = R_eval.dim

      eval.create(d)

      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            ! Negative eigenvalues
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            ! Small eigenvalues
            eval(i) = sh   
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            ! Normal eigenvalues
            eval(i) = ONE/sqrt(temp)
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp 
      end
      end

      eval.destroy

   end


   to_eigenfilter_of(R_eval,R_evec,tol,n_small,n_negative) ::: PURE
   ! self = filter(self), where small eigenvalues less than "tol" are
   ! removed from its spectrum. Supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on small or negative eigenvalues.  If "n_small" return the
   ! number of small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT

      eval :: VEC{REAL}*
      d,i,j,k, n_n,n_s :: INT
      eps,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Get inverse sqrt eigenvalues
      d = R_eval.dim

      eval.create(d)

      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            eval(i) = ZERO
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            eval(i) = temp
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_power_series_inverse_of(S,tol,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the power series inverse square root of "S".
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
   end

   to_power_series_inv_sqrt_of(S,tol,prefactor,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the inverse square root of "S", a matrix which is required to
   ! have a unit diagonal. The method uses a binomial power series expansion.
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
   end

   to_power_product_inverse_of(S,tol,prefactor,max_it)
   ! Set self to the inverse of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed by the approximate square root until the result in the unit
   ! matrix, within tolerance "tol" (if present). Finally, to form the inverse,
   ! the inverse square root is squared.
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional
   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")
      n :: INT
      W :: MAT{REAL}*
      .to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
      n = S.dim1
      W.create(n,n); W = self
      .to_product_of(W,W)
      W.destroy
   end

   to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
   ! Set self to the inverse square root of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed into a new basis using the approximate square root, until the
   ! result is the unit matrix within tolerance "tol" (if present).
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional

   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")

      D,X :: MAT{REAL}*
      max_iter,n,k :: INT
      eps,prefac :: REAL

      eps = TOL(9)
      if (present(tol)) eps = tol
      max_iter = 100
      if (present(max_it)) max_iter = max_it
      prefac = ONE/FOUR
      if (present(prefactor)) prefac = prefactor

      n = S.dim1
      X.create(n,n)
      D.create(n,n)
      X = prefac*S

      self.to_unit_matrix

      k = 0
      do
         k = k + 1
         D = self
         self = (THREE/TWO)*D
         .plus_scaled_product_of(X,D,fac=-HALF)
         S.change_basis_to(X,self)
         X = prefac*X
         if (X.has_unit_diagonal(eps)) exit
         DIE_IF(k>max_iter,"power series too long")
      end
      self = sqrt(prefac)*self

      D.destroy
      X.destroy

   end


   to_exponential_of(X,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix "X" using a power series expansion, self = exp(X),
   end

   exponentiate_to(U,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix self using a power series expansion, U = exp(self),
   ! so that the maximum deviation from the exact answer is less than "tol"
   ! if present.
   end

   antisymmetric_exponential_to(U,eval,evec) ::: get_from(MAT{INTRINSIC}, EIGEN?=>solve_symmetric_eigenproblem)
   ! Make unitary matrix U = exp(self) where "self" must be antisymmetric.
   ! Uses the formula:  exp A = V (cos P) V^t + V (sin P)/P V^t A
   !                        P = sqrt diag(eig(A^t A))
   ! (c) dylan jayatilaka, university of western australia, 1993
   ! WARNING: Untested in TONTO and looks wrong.
   end

   to_matching_rotation(reference,actual,L,fail)
   ! Returns the rotation matrix which matches coordinates "reference"
   ! to "actual" in a least squares sense.  actual = U x reference.
   ! Return the mean fitting error "L" or else "fail"  for failure.
      reference :: MAT{REAL}, target, IN
      actual :: MAT{REAL}, IN
      L :: REAL
      fail :: BIN
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==actual.dim1,"self incompatible with actual")
   ENSURE(reference.dim2==actual.dim2,"reference incompatible with actual")

      U,X,Rd :: MAT{REAL}*
      X0,Xv :: VEC{REAL}*
      d,iteration :: INT
      big :: REAL

      ! Set dimension, number of points to fit
      d = .dim1

      ! Set minimum L value
      L = ZERO

      ! Start with U being unit matrix
      .to_unit_matrix

      ! Create antisymmetric matrix X, temporary rotation U
      X.create(d,d)
      X0.create(d*(d+1)/2)
      Xv.create(d*(d+1)/2)
      U.create(d,d)
      Rd.create(reference.dim1,reference.dim2)

      ! Repeatedly update U until converged
      iteration = 0
      fail = FALSE
      do

         iteration = iteration + 1

         ! Rotate actual positions
         Rd.to_product_of(self,actual,transpose_A=TRUE)

         ! Determine the gradient Xv at X=0
         saved_reference => reference
         saved_actual => Rd
         X0 = ZERO
         MAT{REAL}::match_vectors(X0,L,Xv)

         ! Exit if gradient converged or too many iterations
         big = maxval(abs(Xv))
         if (big<TOL(6)) exit
         fail = iteration==1000
         if (fail) exit


         ! Do a line minimisation along gradient Xv from X=0
         saved_reference => reference
         saved_actual => Rd
         VEC{REAL}:line_minimize_from_v2(MAT{REAL}::match_vectors,X0,Xv,L,TOL(6))

         ! Exponentiate X and update U
         X.antisymmetric_unzip_triangle(X0)
         U.to_exponential_of(X)
         X.to_product_of(self,U)
         self = X

      end

      ! Clean up
      Rd.destroy; U.destroy; Xv.destroy; X0.destroy; X.destroy

   end

   match_vectors(Xv,L,dL) ::: selfless, public
   ! Take Xv, exponentiate it, and determine "L", the overlap between
   ! "saved_actual" and "saved_reference". Also determine "dL" the
   ! derivative at Xv=0. NOTE: "dL" is wrong unless Xv=0.
      Xv :: VEC{REAL}, IN
      L :: REAL, OUT
      dL :: VEC{REAL}, optional, OUT
      X,U,Rd :: MAT{REAL}*
      d,n,p,q,pq,i :: INT
      val :: REAL

      ! Dimensions
      d = saved_actual.dim1
      n = saved_actual.dim2

      ! Temporaries
      X.create(d,d)
      U.create(d,d)
      Rd.create(d,n)

      ! Exponentiate Xv and get L
      X.antisymmetric_unzip_triangle(Xv)
      U.to_exponential_of(X)
      Rd.to_product_of(U,saved_actual,transpose_a=TRUE)
      Rd = Rd - saved_reference
      L = Rd.trace_product_with(Rd,transpose_a=TRUE)

      ! Gradient of L
      if (present(dL)) then
         Rd = Rd + saved_reference
         pq = 0
         do p = 1,d
            do q = 1,p
               pq = pq + 1
               val = ZERO
               do i = 1,n
                  val = val + Rd(p,i)*saved_reference(q,i) - Rd(q,i)*saved_reference(p,i)
               end
               dL(pq) = -TWO*val
            end
         end
      end

      ! Clean up
      Rd.destroy; U.destroy; X.destroy
   end

!  =============
!  String widths
!  =============

   str_lengths(dp,spaces) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns the minimal string lengths, with optional extra "spaces"
   end

   get_max_str_length(msl,max_dp,spaces) ::: get_from(MAT{INTRINSIC}), pure
   ! Return "msl" the maximum of the string lengths, keeping "max_dp"
   ! decimal places and including extra "spaces"
   end

!  =======================
!  Spin-orbital operations
!  =======================

!  Block returning routines

   alpha_alpha result (res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-alpha sector of the matrix
   end

   beta_alpha result (res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-alpha sector of the matrix
   end

   alpha_beta result (res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-beta sector of the matrix
   end

   beta_beta result (res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-beta sector of the matrix
   end

!  Set_to routines

   alpha_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Set the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Set the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Set the alpha-beta sector of the matrix to "X"
   end

   beta_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Set the beta-beta sector of the matrix to "X"
   end

   alpha_alpha_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set the alpha-beta sector of the matrix to "X"
   end

   beta_beta_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set the beta-beta sector of the matrix to "X"
   end

!  Put_to routines

   alpha_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>), PURE
   ! Put the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>), PURE
   ! Put the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>), PURE
   ! Put the alpha-beta sector of the matrix to "X"
   end

   beta_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>), PURE
   ! Put the beta-beta sector of the matrix to "X"
   end

!  plus routines

   alpha_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Add "X" to the alpha-alpha sector of the matrix
   end

   beta_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Add "X" to the beta-alpha sector of the matrix
   end

   alpha_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Add "X" to the alpha-beta sector of the matrix
   end

   beta_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Add "X" to the beta-beta sector of the matrix
   end

   alpha_alpha_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add "X" to the alpha-alpha sector of the matrix
   end

   beta_alpha_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add "X" to the beta-alpha sector of the matrix
   end

   alpha_beta_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add "X" to the alpha-beta sector of the matrix
   end

   beta_beta_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add "X" to the beta-beta sector of the matrix
   end

!  general block setting

   put_blocks_to(X,block_dim,block_list) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}), PURE
   ! Put from "self" the blocks listed in "block_list" into "X".
   ! Each block is square and has dimension "block_dim".
   end

   put_sub_blocks_to(X,block_dim,X_block_dim,block_list,X_block_offset) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Put from "self" into "X" the blocks listed in "block_list" BUT
   ! only the square sub blocks of size "X_block_dim" which start from
   ! "X_block_offset"+1 past a block boundary are copied into blocks
   ! of "X" i.e. a zero offset (default) assumes the first
   ! "X_block_dim" elements are copied from blocks of "self" into "X".
   end

!  =====================
!  Conversion to strings
!  =====================

   to_str(style,width,precision,left_justify) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Change self to a string with specified "style", "width" and
   ! "precision" as defined in the fortran standard
      self :: IN
      style :: STR, IN
      width,precision :: INT, IN
      left_justify :: BIN, IN, optional
      res :: MAT{STR}(.dim1,.dim2)
   end

!  ===============
!  Unit conversion
!  ===============

   convert_to(units)
   ! Convert the number "self" in atomic units or generic units to a
   ! new number in "units".
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = units.conversion_factor
      self   = self*factor
   end

   convert_from(units)
   ! Convert the number "self" from "units" system to a new number
   ! in atomic units or generic units.  Returns "err" whether it was successful.
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = ONE/(units.conversion_factor)
      self   = self*factor
   end

!  ==================================================
!  Gaussian function rotation representation matrices
!  =================================================

   gaussian_d_xyz_matrix result (dtr)
   ! Return the representation matrix for a d-type xyz product found in gaussian
   ! shells, induced by an xyz rotation matrix "self". The matrix representation
   ! induced is: d = d' * dtr, when the coordinates r of the gaussian shell
   ! functions are written in terms of new coordinates r' as: r = self^T * r'.
      dtr :: MAT{REAL}(6,6)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2 :: INT
      d1 :: VEC{INT}(6)  = (/1,2,3,1,1,2/)
      d2 :: VEC{INT}(6)  = (/1,2,3,2,3,3/)

      do i = 1,6 ! loop on old coordinates
         i1 = d1(i)
         i2 = d2(i)
         dtr(1,i)  = self(1,i1)*self(1,i2)
         dtr(2,i)  = self(2,i1)*self(2,i2)
         dtr(3,i)  = self(3,i1)*self(3,i2)
         dtr(4,i)  = self(1,i1)*self(2,i2) &
                   + self(2,i1)*self(1,i2)
         dtr(5,i)  = self(1,i1)*self(3,i2) &
                   + self(3,i1)*self(1,i2)
         dtr(6,i)  = self(2,i1)*self(3,i2) &
                   + self(3,i1)*self(2,i2)
      end

   end

   gaussian_f_xyz_matrix result (ftr)
   ! Return the representation matrix for an f xyz product found in gaussian
   ! shells from a p-type xyz matrix
      ftr :: MAT{REAL}(10,10)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2,i3 :: INT
      f1 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,1/)
      f2 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,2/)
      f3 :: VEC{INT}(10) = (/1,2,3,2,3,1,3,1,2,3/)

      do i = 1,10
         i1 = f1(i)
         i2 = f2(i)
         i3 = f3(i)
         ftr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)
         ftr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)
         ftr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)
         ftr(4,i)  = self(1,i1)*self(1,i2)*self(2,i3) &
                   + self(1,i1)*self(2,i2)*self(1,i3) &
                   + self(2,i1)*self(1,i2)*self(1,i3)
         ftr(5,i)  = self(1,i1)*self(1,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(1,i3)
         ftr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(1,i3)
         ftr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(3,i3)
         ftr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(1,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(1,i3)
         ftr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(2,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(2,i3)
         ftr(10,i) = self(1,i1)*self(2,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(3,i3) &
                   + self(2,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(2,i3) &
                   + self(3,i1)*self(2,i2)*self(1,i3)
      end

   end

   gaussian_g_xyz_matrix result (gtr)
   ! Return the representation matrix for a g xyz product found in gaussian
   ! shells from a p-type xyz matrix
      gtr :: MAT{REAL}(15,15)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2,i3,i4 :: INT
      g1 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g2 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g3 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,2,3,3,2,1,1/)
      g4 :: VEC{INT}(15) = (/1,2,3,2,3,1,3,1,2,2,3,3,3,3,2/)

      do i = 1,15
         i1 = g1(i)
         i2 = g2(i)
         i3 = g3(i)
         i4 = g4(i)
         gtr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)*self(2,i4)
         gtr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)*self(3,i4)
         gtr(4,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(5,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(1,i4)
         gtr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(3,i4)
         gtr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(1,i4)
         gtr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(2,i4)
         gtr(10,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(11,i) = self(1,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(1,i4)
         gtr(12,i) = self(2,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(2,i4)
         gtr(13,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(14,i) = self(2,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(2,i4)
         gtr(15,i) = self(3,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(3,i4)
      end

   end

! ======================
! Binning and histograms
! ======================

   to_histogram_from_data(data,X,Y,X_min,X_max,X_bin,Y_min,Y_max,Y_bin) ::: leaky
   ! Set "self" to a histogram matrix whose ij-th element contains the
   ! *sum* of the values in array "data" whose elements correspond to
   ! the ij-th bin in "X" and "Y", where a 2D bin is a range of
   ! values in "X" (and "Y) of side length "X_bin" (and "Y_bin")
   ! beginning at "X_min" (and "Y_min") and ending at "X_max" (and
   ! "Y_max"). The dimension of self is calculated here.
   ! NOTE: Don't use binned data to calculate properties unless you
   ! really need to coarse grain.
      self :: PTR
      data,X,Y :: VEC{REAL}, IN
      X_min,X_max,X_bin :: REAL, IN
      Y_min,Y_max,Y_bin :: REAL, IN

   ENSURE(data.dim==X.dim,"incompatible data and X descriptor")
   ENSURE(data.dim==Y.dim,"incompatible data and Y descriptor")
   ENSURE(X_max>X_min,"X_max is smaller than X_min!")
   ENSURE(Y_max>Y_min,"Y_max is smaller than Y_min!")
   ENSURE(X_bin<(X_max-X_min),"X_bin size is larger than [X_min,X_max]")
   ENSURE(Y_bin<(Y_max-Y_min),"X_bin size is larger than [X_min,X_max]")

      n_X,n_Y, i,j,k :: INT
      X_ran,Y_ran :: REAL

      ! The range of value ...
      X_ran = X_max - X_min
      Y_ran = Y_max - Y_min

      ! The number of bins ...
      n_X = ceiling(X_ran/X_bin)
      n_Y = ceiling(Y_ran/Y_bin)

      ! Create the histogram (leaky)
      self.create(n_X,n_Y)
      self = ZERO

      ! Now do the binning ...
      do k = 1,data.dim

         ! Get the bins
         i = ceiling(min(X(k)-X_min,X_ran)/X_bin)
         j = ceiling(min(Y(k)-Y_min,Y_ran)/Y_bin)

         ! Accumulate
         self(i,j) = self(i,j) + data(k)

      end

   end

!  ==========
!  Misc stuff
!  ==========

   make_enclosing_sphere(pos,radius)
   ! Determine the position and radius of a sphere that encloses all points in
   ! the grid.
      self :: IN
      radius :: REAL, OUT
      pos :: VEC{REAL}(3), OUT
   ENSURE(.dim2==3,"Second dimension of matrix is not 3.")
      diff :: VEC{REAL}(3)
      dist :: REAL
      n,n_pts :: INT
      n_pts = .dim2
      ! Get the center of the sphere.  Should use a better algorithm than just the
      ! average.
      pos = ZERO
      do n = 1,n_pts
       pos = pos + self(n,:)
      end
      pos = pos / n_pts
      ! The radius is the distance to the furthest point.
      radius = 0
      do n = 1,n_pts
       diff = self(n,:) - pos
       dist = dot_product(diff,diff)
       if (dist > radius) radius = dist
      end
      radius = sqrt(radius)
   end

   make_corresponding_orbitals(left,right,theta,p)
   ! This algorithm from Camp and King, J. Chem Phys. Vol 75(1), pp 268-274.
   ! p is the dimenstion of the first block of the partitioned matrices.
   ! Works best if "left" and "right" matrices are nonzero.
      self :: target
      left,right :: MAT{REAL}, target
      theta :: VEC{REAL}, OUT
      p :: INT, IN

   ENSURE(.is_square,"non-square matrix")
   ENSURE(.is_same_shape_as(right),"right is incompatible")
   ENSURE(.is_same_shape_as(left),"left is incompatible")
   ENSURE(size(theta)==min(.dim1,.dim1-p),"theta has wrong size")

      Vp,Vq,Wp,Wq,M,MWq,Hq,Up,Uq :: MAT{REAL}*
      lambda :: VEC{REAL}*
      minpq,q,n :: INT

      n = .dim1
      q = n - p
      minpq = min(p,q)

      ! I've only tested this for q>p.  Suspect p>q does not work.
      Vp => left(:p,:p)
      Vq => left(p+1:,p+1:)
      Wp => right(:p,:p)
      Wq => right(p+1:,p+1:)
      M  => self(:p,p+1:)
      Up => self(:p,:p)
      Uq => self(p+1:,p+1:)
      right(:p,p+1:)=ZERO
      right(p+1:,:p)=ZERO
      left(:p,p+1:)=ZERO
      left(p+1:,:p)=ZERO
      .zero_small_values(TOL(10))

      lambda.create(q)                       ! get eigenvalues and Wq.
      Hq.create(q,q)
      Hq.to_product_of(M,M,transpose_a=TRUE)
      Hq.solve_symmetric_eigenproblem(lambda,Wq)
      Hq.destroy

      lambda.reverse_order                   ! get rotation angles, largest first.
      theta = lambda(:minpq)
      lambda.destroy
      theta.zero_small_values(TOL(10))

   ENSURE(minval(theta)>=ZERO,"eigenvalues less than zero!")
   ENSURE(maxval(theta)<=ONE,"eigenvalues more than one!")
      theta = min(theta,ONE)
      theta = max(theta,ZERO)

      Wq.zero_small_values(TOL(10))          ! get Vp
      Wq.reverse_column_order
      MWq.create(p,q)
      MWq.to_product_of(M,Wq)
      Vp = MWq(:p,:p)
      MWq.destroy
      Vp.schmidt_orthonormalise(theta)

      Vq.to_product_of(Uq,Wq)                   ! get Vq
      Vq.reverse_schmidt_orthogonalise

      Wp.to_product_of(Up,Vp,transpose_a=TRUE)  ! get Wp
      Wp.reverse_schmidt_orthogonalise

      theta = sqrt(theta)
      theta = asin(theta)

   end

   to_multipole_W_translation_mx(R,l_max)
   ! Make the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, due to mistake (?) in Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Set self to zero, mainly for upper triangle
      self = ZERO
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   add_multipole_W_translation_mx(R,l_max)
   ! Add the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, when comparing to Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   to_multipole_T_interaction_mx(R,l_max,j_max)
   ! Make the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   add_multipole_T_interaction_mx(R,l_max,j_max)
   ! Add the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   to_R_mu_multipole_mx(points,l_max)
   ! Make the R_mu multipole matrix, self(i,j), which is the scaled regular
   ! mu-type solid harmonic evaluated at point P_i = "points(:,i)" for moment
   ! (L,M), where index j is L*L + M + L + 1, and where L is less than "l_max".
   ! This matrix is used to multiply the interaction matrix to evaluate the
   ! potential at the given points P_i from multipoles at Q,
   !     potential(i) = self * T(Q-P_i) * multipoles(Q).
   ! Reference: the book by Helgaker, Simons and Olsen, p. 407.
      points :: MAT{REAL}, IN
      l_max :: INT
   ENSURE(points.dim2==3,"wrong 2nd dimension, points arrays")
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==points.dim1,"wrong 1st dimension, self")
   ENSURE(.dim2==(l_max+1)*(l_max+1),"wrong 2nd dimension, self")
      Rm :: VEC{VEC_{VEC_{REAL}}}*
      L,M,lm :: INT
      VEC{REAL}:make_R_mu_harmonics(Rm,points,l_max)
      lm = 0
      do L = 0,l_max
         do M = -L,L ! note the canonoical order here
            lm = lm + 1
            self(:,lm) = Rm(L)[M][:]
         end
      end
      do L = l_max,0,-1
         do M = L,-L,-1
            deallocate(Rm(L)[M].element)
         end
         deallocate(Rm(L).element)
      end
      deallocate(Rm)
   end

   expand_quadrupole(compressed) result(res) ::: pure, selfless
   ! ?
      compressed :: VEC{REAL}(6), IN
      res :: MAT{REAL}(3,3)
      i :: INT
      ! xx,yy,zz
      do i =1,3
         res(i,i) = compressed(i)
      end do
      ! xy
      res(1,2) = compressed(4)
      res(2,1) = compressed(4)
      ! xz
      res(1,3) = compressed(5)
      res(3,1) = compressed(5)
      ! yz
      res(2,3) = compressed(6)
      res(3,2) = compressed(6)
   end

   compress_quadrupole(quadrupole) result(res) ::: pure, selfless
   ! ?
      quadrupole :: MAT{REAL}(3,3), IN
      res :: VEC{REAL}(6)
      i :: INT
      ! xx,yy,zz
      do i =1,3
         res(i) = quadrupole(i,i)
      end do
      ! xy
      res(4) = quadrupole(1,2)
      ! xz
      res(5) = quadrupole(1,3)
      ! yz
      res(6) = quadrupole(2,3)
   end

end
