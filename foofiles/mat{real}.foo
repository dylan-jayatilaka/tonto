!-------------------------------------------------------------------------------
!
! MAT{REAL}: Matrix operations ...
!
! Copyright (C) Dylan Jayatilaka, 1996
!
! This library is free software; you can redistribute it and/or
! modify it under the terms of the GNU Library General Public
! License as published by the Free Software Foundation; either
! version 2 of the License, or (at your option) any later version.
!
! This library is distributed in the hope that it will be useful,
! but WITHOUT ANY WARRANTY; without even the implied warranty of
! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
! Library General Public License for more details.
!
! You should have received a copy of the GNU Library General Public
! License along with this library; if not, write to the
! Free Software Foundation, Inc., 59 Temple Place - Suite 330,
! Boston, MA  02111-1307, USA.
!
! $Id: mat{real}.foo 4384 2014-05-22 10:34:55Z dylan_ $
!-------------------------------------------------------------------------------

module MAT{REAL}

! #ifdef INTEL_ifort
!    USE lapack95, only: dsyev
!    USE lapack95, only: dgesv
!    USE lapack95, only: dgetrf
!    USE lapack95, only: dgetri
! #endif

   implicit none

   interface uncompress_from_pyramid
      symmetric_unzip_triangle
   end

   ! For getting rotation matrix to match vectors
   saved_reference :: MAT{REAL}*, private   DEFAULT_NULL
   saved_actual    :: MAT{REAL}*, private   DEFAULT_NULL

contains

!  =================
!  Memory allocation
!  =================

   create(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given dimensions
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the specified "bounds" for each dimension
   end

   create(lb1,ub1,lb2,ub2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given dimensions
   end

   create(bounds1,bounds2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the specified bounds for each dimension
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a matrix with the given bounds for all dimensions
   end

   create_copy(matrix) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Create a replica copy of matrix
   end

   destroy ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Destroy the object
   end

   created result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo, pure
   ! Returns true if self has been created
   end

   destroyed result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo, pure
   ! Returns true if self has *not* been created
   end

!  ============================
!  Size-of and shape operations
!  ============================

   size result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo, pure
   ! Return the size of the array
   end

   dim1 result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo, pure
   ! Return the size of the 1st dimension
   end

   dim2 result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo, pure
   ! Return the size of the 2nd dimension
   end

   is_same_shape_as(a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" has the same shape as "self"
   end

   is_transposed_shape_of(a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" is the transposed shape of self
   end

   is_square result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns TRUE if the matrix is square
   end

!  =======================
!  Shrinking and expansion
!  =======================

   shrink(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Shrinks self to dimension dim1xdim2.  Contents are retained.
   end

   expand(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands self to dimension dim1xdim2.  Contents are retained.
   end

   shrink_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Shrinks columns of self to dimension dim2. Contents are retained.
   end

   expand_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands the columns self to dim2.  Contents are retained.
   end

   append_columns(cols) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Append the columns "cols" onto the end of self.
   end

   append_column(col) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Append the column "col" onto the end of self.
   end

   prune_column(col) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Prune the column "col".
   end


   expand_rows(dim1) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Expands the rows of self to dim1. Contents are retained.
   end

!  ====================
!  Comparison functions
!  ====================

   equals(b) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Check if the matrix is the same as "b".
   end

   same_as(b,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Check if the matrix is the same as "b", within "eps".
   end

!  ================
!  Range operations
!  ================

   all_in_range(range) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return TRUE if all values of self are within the specified "range".
   end

   in_range(range) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return element ij as TRUE if self(i,j) is within the specified "range".
   end

   range result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the range (smallest and largest value) of self.
   end

   number_in_range(range) result (res)::: get_from(MAT{INTRINSIC}), pure
   ! Return the number of element self(i,j) within the specified "range".
   end

   get_indices_in_range(range,row,col,val) ::: get_from(MAT{INTRINSIC}), pure
   ! Get the "row" and "col" indices, and values "val", of the
   ! elements of "self" which are within the specified "range".
   end

!  =================
!  Inquiry functions
!  =================

   is_diagonal(eps) result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is a diagonal matrix to within
   ! tolerance "eps" (if present).
   end

   has_unit_diagonal(eps) result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" has 1's as diagonal elements to within
   ! tolerance "eps" (if present).
   end

   has_minus_unit_diagonal result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" has -1's as diagonal elements
   end

   is_unit_matrix(eps) result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is the unit matrix to within
   ! tolerance "eps" (if present).
   end

   is_inversion_matrix result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is an inversion matrix
   ! i.e. minus the unit matrix
   end

   is_symmetric result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is a symmetric matrix
   end

   is_antisymmetric result (res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is an antisymmetric matrix
   end

   is_zero(eps) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE is "self" is the zero matrix, i.e. every element is zero.
   ! If present, "eps" is used to decide when a small number is zero.
   end

!  =================
!  Column operations
!  =================

   has_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Returns TRUE if the matrix "self" has a column "c", with "eps" tolerance.
   end

   index_for_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the index of the first column in "self" which matches "c",
   ! within tolerance "eps", or else return 0 for no match.
   end

   indices_for_column(c,eps) result (res) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Return the indices of columns in "self" which match "c",
   ! within tolerance "eps", or else return 0 for no match.
   end



   compare_columns_with(m,col) ::: get_from(MAT{INTRINSIC})
   ! Compare the columns of "self" with "m". The elements of array "col" are set
   ! TRUE if the corresponding column appears in "m"
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC})
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set TRUE if the corresponding
   ! column is unique.
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC}), leaky
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set to the indices of the unique
   ! columns.
   end

   no_of_unique_columns result (res) ::: get_from(MAT{INTRINSIC})
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. Return the number of unique columns.
   end


   swap_columns(col1,col2) ::: get_from(MAT{INTRINSIC})
   ! Swap columns "col1" and "col2" of self
   end

   swap_columns(list) ::: get_from(MAT{INTRINSIC})
   ! Sequentially swap all columns in a column "list",
   ! self(:,i)      = self(:,list(i))
   ! self(:,col(i)) = self(:,i)
   end

   reverse_column_order ::: get_from(MAT{INTRINSIC}), PURE
   ! Reverse the order of the columns of self.
   end


   column_norms result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
   end

   get_column_norms(res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
   end

   get_column_dot_products(res) ::: get_from(MAT{INTRINSIC})
   ! Return the dot products of every column with itself.
   ! Good for testing distances without using a sqrt.
   end

   index_of_minimum_column_norm result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the column index of the column with the *minimum* norm.
   end

   max_abs_column_difference result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the maximum of the absolute difference between all the column vector
   ! pairs of the matrix.
   end


   mean_column_vector result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the mean of the column vectors.
   end

   sum_column_vectors result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Sum the column vectors (i.e. rows) in "self".
   end


   plus_column(col) ::: get_from(MAT{INTRINSIC}), pure
   ! Add column "col" to every column of "self".
   end

   minus_column(col) ::: get_from(MAT{INTRINSIC}), pure
   ! Subtract column "col" to every column of "self".
   end

   plus_scaled_column(col,fac) ::: get_from(MAT{INTRINSIC}), pure
   ! Add the "fac" scaled column "col" to every column of "self".
   end

!  ==============
!  Row operations
!  ==============

   unique_rows(row) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set TRUE if the corresponding
   ! row is unique.
   end

   unique_rows(row) ::: get_from(MAT{INTRINSIC}), leaky, PURE
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set to the indices of the unique
   ! rows.
   end

   no_of_unique_rows result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Compare the later row of "self" with earlier rows to see if they are
   ! unique. Return the number of unique rows.
   end

   swap_rows(row1,row2) ::: get_from(MAT{INTRINSIC}), PURE
   ! Swap columns "row1" and "row2" of self
   end

   swap_rows(list) ::: get_from(MAT{INTRINSIC}), PURE
   ! Sequentially swap all rows in a row "list",
   ! self(i,:)       = self(list(i),:)
   end

   row_norms result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the norms of every row
   end

   sum_row_vectors result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Sum the row vectors (i.e. columns) in "self".
   end

!  ==========================================
!  Matrix algebra and vector space operations
!  ==========================================

   determinant result (res) ::: get_from(MAT{INTRINSIC}), recursive
   ! Return the determinant
   end

   adjugate(i,j) result (res) ::: get_from(MAT{INTRINSIC}), leaky
   ! Return the adjugate of a matrix
   end


   sum_elements result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the sum of the elements in "self"
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}, RES?=>REAL), PURE
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{CPX}, RES?=>CPX), PURE
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
   end


   rotate(v) ::: get_from(MAT{INTRINSIC}), PURE
   ! Rotate vector "v" by self
   end

   jacobi_rotation(p,q) ::: pure
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q). NOTE: self must be symmetric
      self :: INOUT
      p,q :: INT, IN

      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL

      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)

      theta = (s_qq-s_pp)/(TWO*s_pq)

      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t

      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)

      do i = 1,.dim1

         s_ip = self(i,p)
         s_iq = self(i,q)

         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)

         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq

      end

      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO

   end

   jacobi_rotation(p,q,v) ::: pure
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q) and also update the rotation
   ! matrix "v". NOTE: self must be symmetric
      self :: INOUT
      p,q :: INT, IN
      v :: MAT{REAL}, INOUT

      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL

      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)

      theta = (s_qq-s_pp)/(TWO*s_pq)

      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t

      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)

      do i = 1,.dim1

         s_ip = self(i,p)
         s_iq = self(i,q)

         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)

         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq

      end

      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO

      do i = 1,.dim1

         s_ip = v(i,p)
         s_iq = v(i,q)

         v(i,p) = s_ip - s*(s_iq+tau*s_ip)
         v(i,q) = s_iq + s*(s_ip-tau*s_iq)

      end

   end

   to_3x3_rotation_matrix(axis,angle) ::: PURE
   ! Set "self" to the rotation matrix which rotates around vector "axis" in
   ! an anticlockwise direction (when looking against the "axis" vector) by
   ! amount "angle" (in radians).
      self :: OUT
      axis :: VEC{REAL}, IN
      angle :: REAL, IN

   ENSURE(.is_square,"non-square matrix")
   ENSURE(.dim1==3,"must be 3x3 matrix")
   ENSURE(axis.dim==3,"axis is not 3 dimensional")

      x,y,z,xp,yp :: VEC{REAL}(3)

      z = axis
      z.normalise

      x = z.cross([ONE,ZERO,ZERO])
      if (x.is_zero(TOL(9))) x = z.cross([ZERO,ONE,ZERO])
      x.normalise

      y  = z.cross(x)

      xp = cos(angle)*x+sin(angle)*y
      yp = cos(angle)*y-sin(angle)*x

      self =  z.outer_product_with(z) &
           + xp.outer_product_with(x) &
           + yp.outer_product_with(y)

   end


   to_unit_matrix ::: get_from(MAT{INTRINSIC}), pure
   ! Set "self" to the unit matrix
   end


   zero_small_values(eps) ::: get_from(MAT{INTRINSIC}), pure
   ! Zero elements of the matrix which are less than "eps" in magnitude
   end


   set_to(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Set self to "a"
   end

   set_to_transpose_of(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Self becomes the transpose of "a"
   end

   to_transpose ::: get_from(MAT{INTRINSIC}), PURE
   ! Self becomes its own transpose.
   end


   plus(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Add to self the matrix "a"
   end

   minus(a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}), PURE
   ! Subtract from self the matrix "a"
   end

   to_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Set "self" to matrix "at" scaled by "fac"
   end

   plus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Add to "self" matrix "a" scaled by "fac"
   end

   minus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, FAC?=>REAL), PURE
   ! Subtract from "self" matrix "a" scaled by "fac"
   end


   to_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL), PURE
   ! Set "self" to the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
   end

   plus_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL), PURE
   ! Add to "self" the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
   end

   to_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL, FAC?=>REAL), PURE
   ! Set "self" to the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! need to be transposed.
   end

   plus_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB?=>REAL, FAC?=>REAL), PURE
   ! Add to "self" the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! neeb to be transposed.
   end


   to_outer_product_of(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>REAL, FAC?=>REAL), PURE
   ! Set "self" to the outer product of "a" with itself, with an
   ! optional scale factor "fac".
   end

   plus_outer_product_of(a,fac) ::: get_from(MAT{INTRINSIC}, A?=>REAL, FAC?=>REAL), PURE
   ! Add to "self" the outer product of "a" with itself, with an
   ! optional scale factor "fac".
   end


   to_product_with_diagonal(a,diag,transpose_a) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, DIAG?=>VEC{REAL}), PURE
   ! Set "self" to the matrix product of "a" with diagonal matrix "diag" (stored
   ! as a vector).  If present, ""transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
   end

   to_product_with_diagonal(dg,a,transpose_a) ::: get_from(MAT{INTRINSIC}, DG?=>VEC{REAL}, A?=>MAT{REAL}), PURE
   ! Set "self" to the matrix product of diagonal matrix "dg" (stored as a
   ! vector) and "a".  If present, "transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
   end


   plus_difference_product_with(U,ev,eo,tol) ::: PURE
   ! Do self += (ev(a)-eo(i)) * U(a,i).
   ! If "tol" is present, small ev/eo and (ev-eo) get set to zero
      self :: INOUT
      U    :: MAT{REAL}, IN
      ev   :: VEC{REAL}, IN
      eo   :: VEC{REAL}, IN
      tol  :: REAL, optional, IN

   ENSURE(ev.dim==self.dim1,"wrong size, ev")
   ENSURE(eo.dim==self.dim2,"wrong size, eo")

      a,i :: INT
      ea,ei,ai :: REAL

      if (NOT present(tol)) then

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      else

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) ai = ZERO
            if (ea.is_zero(tol)) ai = ZERO
            if (ei.is_zero(tol)) ai = ZERO
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      end

   end

   plus_difference_divisor_with(U,ev,eo,tol) ::: PURE
   ! Do self += (ev(a)-eo(i))^-1 * U(a,i).
   ! If "tol" is present, small ev/eo and (ev-eo) get set to zero
      self :: INOUT
      U    :: MAT{REAL}, IN
      ev   :: VEC{REAL}, IN
      eo   :: VEC{REAL}, IN
      tol  :: REAL, optional, IN

   ENSURE(ev.dim==self.dim1,"wrong size, ev")
   ENSURE(eo.dim==self.dim2,"wrong size, eo")

      a,i :: INT
      ea,ei,ai :: REAL

      if (NOT present(tol)) then

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) then; ai = ZERO
            else;                      ai = ONE/ai
            end
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      else

         do i = 1,.dim2
         do a = 1,.dim1
            ea = ev(a)
            ei = eo(i)
            ai = ea - ei
            if (ai.is_zero(tol)) then; ai = ZERO
            else;                      ai = ONE/ai
            end
            if (ea.is_zero(tol))       ai = ZERO
            if (ei.is_zero(tol))       ai = ZERO
            self(a,i) = self(a,i) + ai*U(a,i)
         end
         end

      end

   end

!  ================
!  Trace operations
!  ================

   trace result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Return the trace of self
   end

   trace_product_with(a,transpose_a) result (res) ::: get_from(MAT{INTRINSIC}, A?=>MAT{REAL}, RES?=>REAL, CAST=>), PURE
   ! Return the trace of the product of "self" with matrix "a",
   ! and if "transpose_a" is present and TRUE, then transpose "a".
   end

   dot(a) result (res) ::: PURE
   ! Synonym for trace_product_with(a) ... Return the trace of the product of
   ! "self" with matrix "a". This is really intended for use with symmetric
   ! matrices only.
      self :: IN
      a :: MAT{REAL}, IN
      res :: REAL
 ! ENSURE(.is_symmetric,"self is not symmetric")
 ! ENSURE(a.is_symmetric,"self is not symmetric")

      res = .trace_product_with(a,transpose_a=TRUE)

   end

   trace_product_with(a,b,c) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the trace of the product of "self" with matrices "a", "b" and "c".
   end

   trace_product_with(a,b,c,d,e) result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Return the trace of the product of "self" with matrices "a", "b" ... "e".
   end

   contract_with(v) result (res) ::: pure
   ! Contract with a 1-vector.
      self :: IN
      v :: VEC{REAL}, IN
      res :: REAL

 ! ENSURE(.is_square,"self is not square")
 ! ENSURE(.dim1==v.dim,"wrong size, v")

      dim,i1,i2 :: INT

      dim = .dim1

      res = ZERO

      do i2 = 1,dim
      do i1 = 1,dim
         res = res + self(i1,i2)*v(i1)*v(i2)
      end
      end

   end

!  ========================
!  Change of basis routines
!  ========================

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Change the basis of "self" using vectors "V"; self = V^dagger self V
   end

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrix "V" (stored as a vector).
   ! self = V self V
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrices "L" and "R" (stored as
   ! vectors).  self = L self R
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new".  new = V^dagger self V
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW?=>MAT{CPX}, V?=>MAT{CPX}, TRANSPOSE_A=>DAGGER_A), PURE
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new" i.e. new = V^dagger self V. This version uses only intrinsic
   ! procedures to avoid circular dependencies.
   end

   change_basis_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
   end

   change_basis_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>VEC{REAL}), PURE
   ! Change the basis of "self" using diagonal matrices "L" and "R" (stored as
   ! vectors) and place the result in "new".  new = L self R
   end

   back_transform_using(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Back transform "self" using vectors "V", and place the result in "self".
   ! self = V self V^dagger
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL}), PURE
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! new = V self V^dagger
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW?=>MAT{CPX}, V?=>MAT{CPX}, TRANSPOSE_A=>DAGGER_A), PURE
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! i.e. new = V self V^dagger. This version uses only intrinsic calls to avoid
   ! circular dependencies.
   end

   back_transform_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR?=>MAT{REAL}), PURE
   ! Back transform "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L self R^dagger
   end

   similarity_transform(V) ::: get_from(MAT{INTRINSIC}, V?=>MAT{REAL})
   ! Do a similarity transform of "self" using vectors "V": self = V self V^-1
   end

!  ==============
!  ADP comparison
!  ==============

   S12_with_ADP(U2,U1err,U2err,S12err) result (res)
   ! Return the determinant a 3x3 matrix
      U2 :: MAT{REAL}(3,3)
      U1err,U2err :: VEC{REAL}(6), IN, optional
      S12err :: REAL, OUT, optional
      res :: REAL

   ENSURE(present(U1err) EQV present(U2err),"both errors must be present")

      U1,U12 :: MAT{REAL}(3,3)
      a1,a2,a12 :: MAT{REAL}*
      d1,d2,d12,R12,fac :: REAL
      i,j,k :: INT

      ! Get inverses
      U1  = self
      U12 = U1 + U2

      ! Determinants
      d1  = sqrt(U1.determinant)
      d2  = sqrt(U2.determinant)
      d12 = ONE/U12.determinant

      ! Result
      fac = d1*d2*d12
      R12 = sqrt(EIGHT*fac)
      res = 100d0*(ONE - R12)

      ! Get the error in S12
      if (NOT (present(U1err) AND present(U2err) AND present(S12err))) return

      k = 0
      S12err = ZERO
      do i = 1,3
      do j = 1,j
         k = k + 1
          a1 =>  U1.adjugate(i,j)
          a2 =>  U2.adjugate(i,j)
         a12 => U12.adjugate(i,j)
         S12err = S12err +  a1.determinant*U1err(k)
         S12err = S12err +  a2.determinant*U2err(k)
         S12err = S12err - a12.determinant*(U1err(k)+U2err(k))*d12*TWO
         a12.destroy
          a2.destroy
          a1.destroy
      end
      end

      S12err = (TWO*100d0*fac/R12)*S12err

   end

!  ===============================
!  Tensor change of basis routines
!  ===============================

   to_tensor_change_basis_of(V,reorder)
   ! If "V" is a matrix used to change basis for a symmetric
   ! matrix:
   !   e.g. new = V^dagger old V
   ! Then set "self" to the matrix representing the above
   ! transformation in terms of the lower triangle of
   ! "old" treated as a vector. If "reorder" is present
   ! and TRUE then the usual lower triangular order is
   ! changed to 11,22,33,12,13,23 used in crystallography
   ! NOTE: see also GAUSSIAN:d_xyz_rep_matrix_for(R)
      V :: MAT{REAL}
      reorder :: BIN, optional

   ENSURE(.is_square,"self is non-square matrix")
   ENSURE(V.is_square,"V is non-square matrix")
   ENSURE(.dim1==V.dim1.triangle_number,"Incompatible matrices")

      new :: VEC{INT}(6) = [1,4,2,5,6,3]
      n,ab,a,b,cd,c,d, nab,ncd :: INT
      swap :: BIN

      swap = FALSE
      if (present(reorder)) swap = reorder

      n = V.dim1

      if (NOT swap) then

         ! This does: M'_ab = sum_cd V_ca M_cd V_db
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     self(ab,cd) =               V(c,a)*V(d,b)
                     if (c==d) cycle
                     self(ab,cd) = self(ab,cd) + V(d,a)*V(c,b)
                  end
               end
            end
         end

      else

         ! This does: M'_ab = sum_cd V_ca M_cd V_db
         DIE_IF(n/=3,"V must be 3x3")
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               nab = new(ab)
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     ncd = new(cd)
                     self(nab,ncd) =                 V(c,a)*V(d,b)
                     if (c==d) cycle
                     self(nab,ncd) = self(nab,ncd) + V(d,a)*V(c,b)
                  end
               end
            end
         end

      end

   end

   to_tensor_back_transform_of(V,reorder)
   ! If "V" is a matrix used to change basis for a symmetric
   ! matrix:
   !   e.g. new = V old V^dagger
   ! Then set "self" to the matrix representing the above
   ! transformation in terms of the lower triangle of
   ! "old" treated as a vector. If "reorder" is present
   ! and TRUE then the usual lower triangular order is
   ! changed to 11,22,33,12,13,23 used in crystallography
      V :: MAT{REAL}
      reorder :: BIN, optional

   ENSURE(.is_square,"self is non-square matrix")
   ENSURE(V.is_square,"V is non-square matrix")
   ENSURE(.dim1==V.dim1.triangle_number,"Incompatible matrices")

      new :: VEC{INT}(6) = [1,4,2,5,6,3]
      n,ab,a,b,cd,c,d, nab,ncd :: INT
      swap :: BIN

      swap = FALSE
      if (present(reorder)) swap = reorder

      n = V.dim1

      if (NOT swap) then
         ! This does: M'_ab = sum_cd V_ac M_cd V_bd
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     self(ab,cd) =               V(a,c)*V(b,d)
                     if (c==d) cycle
                     self(ab,cd) = self(ab,cd) + V(a,d)*V(b,c)
                  end
               end
            end
         end
      else
         ! This does: M'_ab = sum_cd V_ac M_cd V_bd
         ab = 0
         do a = 1,n
            do b = 1,a
               ab = ab + 1
               nab = new(ab)
               cd = 0
               do c = 1,n
                  do d = 1,c
                     cd = cd + 1
                     ncd = new(cd)
                     self(nab,ncd) =                 V(a,c)*V(b,d)
                     if (c==d) cycle
                     self(nab,ncd) = self(nab,ncd) + V(a,d)*V(b,c)
                  end
               end
            end
         end
      end

   end

!  ==========================
!  Operations on the diagonal
!  ==========================

   set_from_diagonal(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}), PURE
   ! Converts the diagonal vector "d" to matrix "self".
   end

   set_diagonal_to(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}), PURE
   ! Set the diagonal of "self" to vector "d"
   end

   set_diagonal_to(val) ::: get_from(MAT{INTRINSIC}, VAL?=>REAL), PURE
   ! Set the diagonal of "self" to "val"
   end

   put_diagonal_to(d) ::: get_from(MAT{INTRINSIC}, D?=>VEC{REAL}), PURE
   ! Get the diagonal elements of "self" in vector "d"
   end

   increment_diagonal_by(val) ::: get_from(MAT{INTRINSIC}, VAL?=>REAL), PURE
   ! Add "val" to the diagonal of "self"
   end

   scale_diagonal_by(fac) ::: get_from(MAT{INTRINSIC}, FAC?=>REAL), PURE
   ! Weight the diagonal elements of "self" by "fac"
   end

   zero_diagonal ::: get_from(MAT{INTRINSIC}), PURE
   ! Zero the diagonal elements of "self"
   end

   zero_off_diagonal ::: get_from(MAT{INTRINSIC}), PURE
   ! Zero the off diagonal elements of "self"
   end

   max_diagonal_element result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Get the maximum element on the diagonal of the matrix
   end

   max_abs_diagonal_element result (res) ::: get_from(MAT{INTRINSIC}), PURE
   ! Get the maximum absolute value of the diagonal elements of the self matrix
   end

!  ========================
!  Symmetrising and folding
!  ========================

   symmetrize ::: get_from(MAT{INTRINSIC}), PURE
   ! Set self to half of itself plus half its transpose, i.e.
   ! self = 1/2 (self + self^T)
   end

   antisymmetrize ::: get_from(MAT{INTRINSIC}), PURE
   ! Set self to half of itself minus half its transpose, i.e.
   ! self = 1/2 (self - self^T)
   end

   symmetric_fold ::: get_from(MAT{INTRINSIC}), PURE
   ! Add the upper triangle of "self" into the lower triangle
   end

   antisymmetric_fold ::: get_from(MAT{INTRINSIC}), PURE
   ! Subtract the upper triangle of "self" into the lower triangle
   end

   symmetric_reflect ::: get_from(MAT{INTRINSIC}), PURE
   ! Make the upper triangle of "self" the same as the lower triangle
   end

   antisymmetric_reflect ::: get_from(MAT{INTRINSIC})
   ! Make the upper triangle of "self" the negative of the lower triangle and
   ! make the diagonal zero.
   end

   symmetric_fold_to_triangle(tr) ::: get_from(MAT{INTRINSIC}), PURE
   ! Add the upper triangle of "self" into the lower triangle and return
   ! the lower triangle "tr" as a vector across rows.
   end

!  ======================================
!  Compression and uncompression routines
!  ======================================

   zip_lower_triangle_to(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the lower triangle of "self" to the vector "tr"
   ! using row order.
   end

   symmetric_unzip_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into the symmetric matrix "self".
   end

   antisymmetric_unzip_triangle(tr) ::: get_from(MAT{INTRINSIC}), pure
   ! Converts the triangle "tr" into the antisymmetric matrix "self".
   end

   tri_size result (ltr) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns the size of the lower triangle needed to store self.
   end

   flatten(vec) ::: pure
   ! flatten  a matrix into a vector
   ! meant for singlet bra at present
      self :: IN
      vec :: VEC{REAL}, OUT

      o,p :: INT
      counter :: INT

      counter = 0
      do o = 1,.dim1
         counter = counter + 1
         vec(counter) = self(o,o)
      end

      do o = 1,.dim1
      do p = 1,o-1
          counter = counter + 1
          vec(counter) = self(o,p)
          DIE_IF(self(o,p)/=self(p,o),"not singlet")
      end
      end

   end

   unflatten(vec_mat) ::: pure
   ! unflatten a matrix into a vector of matrices
   ! meant for singlet contraction_wfs at present
     self :: IN
     vec_mat :: VEC{MAT_{REAL}}, OUT

     n,o,p,dim1,dim :: INT
     counter :: INT
     val :: REAL

     dim =  .dim1
     dim1 = int(sqrt(2*.dim2+QUARTER)-HALF)
     DIE_IF(vec_mat.dim/=dim,"vec_mat.dim/=self.dim1")
     DIE_IF(vec_mat(1).element.dim2/=dim1,"vec_mat(1).element.dim2/=dim1")

     do n = 1,dim

        counter = 0
        do o = 1, dim1
           counter=counter+1
           vec_mat(n).element(o,o)=self(n,counter)
        end

        do o = 1, dim1
        do p = 1,o-1
           counter = counter + 1
           val = self(n,counter)/sqrt(TWO)
           vec_mat(n).element(o,p) = val
           vec_mat(n).element(p,o) = val
        end
        end

     end

   end

   unflatten_triplets(vec_mat) ::: pure
   ! unflatten a matrix into a vector of matrices
   ! meant for triplet contraction_wfs at present
     self :: INOUT
     vec_mat :: VEC{MAT_{REAL}}, INOUT

     n,o,p,dim1,dim :: INT
     counter :: INT
     val :: REAL

     dim = .dim1
     dim1 = int(sqrt(2*.dim2+QUARTER)+HALF)
     DIE_IF(vec_mat.dim/=dim,"vec_mat.dim/=self.dim1")
     DIE_IF(vec_mat(1).element.dim2/=dim1,"vec_mat(1).element.dim2/=dim1")

     self = self/sqrt(TWO)

     do n = 1,dim

        counter = 0

        do o = 1, dim1-1
        do p = o+1,dim1
           counter = counter + 1
           val = self(n,counter)
           vec_mat(n).element(o,p) = val
           vec_mat(n).element(p,o) =-val
        end
        end

     end

   end

!  =================
!  Orthogonalisation
!  =================

   schmidt_orthonormalise(lambda)
   ! Schmidt orthonormalise the column vectors in "self".
   ! If the eigenvalue (lambda) of a vector is less than a cutoff, then that
   ! vector is chosen to be an orthonormal component.
   ! Eigenvalues must be sorted largest to smallest.
     self :: target
     lambda :: VEC{REAL}, IN
   ENSURE(size(lambda)>=.dim2,"not enough eigenvalues")
   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")
     new,old :: VEC{REAL}*
     fac,norm :: REAL
     dim1,dim2,n,k,x,y,j :: INT
     dim1 = .dim1
     dim2 = .dim2

     y=dim2+1   ! y is set to the first vanishing eigenvalue.
     do x=1,dim2
       if (lambda(x)<TOL(10)) then
         y=x
         exit
       end
     end

     do n = 1,y-1  ! the usual Schmidt orthogonalisation.
        new => self(:,n)
        do k = 1,n-1
           old => self(:,k)
           fac = dot_product(old,new)
           new = new - fac*old
        end
        norm = dot_product(new,new)
        ENSURE(norm>TOL(10),"linear dependence, vector " // n.to_str)
        new = new * (ONE/sqrt(norm))
     end

     do n = y,dim2                       ! make up some orthogonal vectors for
       do j=1,dim1                       ! the vanishing eigenvalues.
         new => self(:,n)
         new = ZERO
         new(j) = ONE
         do k = 1,n-1
            old => self(:,k)
            fac = dot_product(old,new)
            new = new - fac*old
         end
         norm = dot_product(new,new)
         if (norm>TOL(10)) then  ! we have found an orthogonal vector
           new = new * (ONE/sqrt(norm))
           exit
         else                   ! try another
           DIE_IF(j==dim1,"cannot find an orthogonal vector")
         end
       end
     end
   end

   schmidt_orthonormalise(S,scales,n_dependent,ld_tol)
   ! Schmidt orthonormalise the vectors in "self" using "S" as the
   ! metric
   ! "scales" is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are orthonormalised. the others are counted (n_dependent)
   ! and rejected at the end of the list.
     self :: target
     S :: MAT{REAL}, IN
     scales :: VEC{REAL}, OUT
     n_dependent :: INT, OUT
     ld_tol :: REAL, optional

   ENSURE(NOT S.is_zero,"S is zero matrix")

     decreasing_vec :: MAT{REAL}*
     old,new :: VEC{REAL}*
     keep :: VEC{REAL}*
     fac :: REAL
     tol :: REAL
     norm :: REAL
     n,o,p,dim1,dim2 :: INT
     skip :: VEC{BIN}*
     n_dependent=0
     tol=LINEAR_DEPENDENCE_TOL
     if(present(ld_tol)) tol=ld_tol
     dim1= .dim1
     dim2= .dim2
     keep.create(dim2)
     skip.create(dim1)
     skip = FALSE
!eliminate function with small norms
     do n = 1,dim1
       new => self(n,:)
       norm = S.dot(new,new)
       if(norm < tol) then
         n_dependent=n_dependent+1
         skip(n)=TRUE
         scales(n)=norm
       end
     end
     DIE_IF(skip(1),"ground state is quasilinearly dependent")
     do n = 1,dim1
        if(skip(n)) cycle
        new => self(n,:)
        keep = new
        norm = S.dot(keep,keep)
!orthogonalisation
        do o = 1,n-1
           if(skip(o)) cycle
           old => self(o,:)
           fac = S.dot(old,new)
           new = new - fac*old
           norm = norm - fac*fac
        end
        scales(n) = norm
     !   if(norm>MAT_LINEAR_DEPENDENCE_TOL) then
        if(norm>tol) then
!normalisation of the orthogonalised vector
          norm = sqrt(norm)
          new = new/norm
        else
          n_dependent=n_dependent+1
          new=keep
          skip(n) = TRUE
        end
     end
     nullify(new)
     nullify(old)
     keep.destroy
!reject the quasilinearly dependent vectors at the end of the array
     o=0
     p=0
     decreasing_vec.create(dim1,dim2)
     do n=1,dim1
       if(NOT skip(n)) then
         p=p+1
         decreasing_vec(p,:)=self(n,:)
       else
         decreasing_vec(dim1-o,:)=self(n,:)
         o=o+1
       end
     end
     self=decreasing_vec
     decreasing_vec.destroy
     skip.destroy
   end

   schmidt_orthonormalise(S,indices,scales,n_dependent,ld_tol) ::: leaky
   ! Schmidt orthonormalise the vectors in "self" using "S" as the
   ! metric.
   ! "scales" is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are orthonormalised. the others are counted (n_dependent)
   ! rejected at the end of the list, their new order is in indices
   ! (which makes the routine leaky).
     self :: target
     indices :: VEC{INT}*
     S :: MAT{REAL}, IN
     scales :: VEC{REAL}, OUT
     n_dependent :: INT, OUT
     ld_tol :: REAL, optional

   ENSURE(NOT S.is_zero,"S is zero matrix")

     decreasing_vec :: MAT{REAL}*
     old,new :: VEC{REAL}*
     keep :: VEC{REAL}*
     fac :: REAL
     tol :: REAL
     norm :: REAL
     n,o,p,dim1,dim2 :: INT
     skip :: VEC{BIN}*
     n_dependent=0
     tol=LINEAR_DEPENDENCE_TOL
     if(present(ld_tol)) tol=ld_tol
     dim1= .dim1
     dim2= .dim2
     keep.create(dim2)
     skip.create(dim1)
     skip = FALSE
!eliminate function with small norms
     do n = 1,dim1
       new => self(n,:)
       norm = S.dot(new,new)
       if(norm < tol) then
         n_dependent=n_dependent+1
         skip(n)=TRUE
         scales(n)=norm
       end
     end
     DIE_IF(skip(1),"ground state is quasilinearly dependent")
     do n = 1,dim1
        if(skip(n)) cycle
        new => self(n,:)
        keep = new
        norm = S.dot(keep,keep)
!orthogonalisation
        do o = 1,n-1
           if(skip(o)) cycle
           old => self(o,:)
           fac = S.dot(old,new)
           new = new - fac*old
           norm = norm - fac*fac
        end
        scales(n) = norm
     !   if(norm>MAT_LINEAR_DEPENDENCE_TOL) then
        if(norm>tol) then
!normalisation of the orthogonalised vector
          norm = sqrt(norm)
          new = new/norm
        else
          n_dependent=n_dependent+1
          new=keep
          skip(n) = TRUE
        end
     end
     nullify(new)
     nullify(old)
     keep.destroy
!reject the quasilinearly dependent vectors at the end of the array
     o=0
     p=0
     decreasing_vec.create(dim1,dim2)
     indices.create(dim1)
     do n=1,dim1
       if(NOT skip(n)) then
         p=p+1
         decreasing_vec(p,:)=self(n,:)
         indices(n)=p
       else
         decreasing_vec(dim1-o,:)=self(n,:)
         indices(n)=dim1-o
         o=o+1
       end
     end
     self=decreasing_vec
     decreasing_vec.destroy
     skip.destroy
   end

   schmidt_orthonormalise(S,scales) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric. If "scales" is present, it is set to the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure. Only those vectors with norm more than the linear dependence
   ! tolerance are normalised.
   end

   is_linearly_dependent(S,tol,col) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE if the columns are linearly dependent with respect to "S".
   ! If present, "tol" is the tolerance used to establish linear dependency.
   ! If present, "col" is the column number where the dependence was first
   ! noticed when Schmidt orthogonalising is used, starting from column 1.
   end

   schmidt_orthonormalise(scale) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" metric. If
   ! "scale" is present, it is set to the product of the normalisation
   ! factors used to normalise each column after the Schmidt
   ! procedure.
   end

   schmidt_orthonormalise(S,scale) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric. If "scale" is present, it is set to the product of the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure.
   end

   schmidt_orthonormalise(S,from,to) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the *column* vectors in "self" using "S" as the
   ! metric. Only the columns starting from index "from" are orthonormalised,
   ! and further, those columns are only orthonormalised to first columns, up to
   ! the column with index "to".
   end

   reverse_schmidt_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric.
   end

   reverse_schmidt_orthogonalise ::: get_from(MAT{INTRINSIC}, CAST=>)
   ! Schmidt orthonormalise the column vectors in "self" using unit metric.
   end

   symmetrically_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Symmetrically orthonormalise the column vectors in "self" using
   ! "S" as the metric, which must be real and positive definite.
   end

   make_diagonally_dominant(permutation) ::: get_from(MAT{INTRINSIC})
   ! Rearrange the order of the columns of self so that the largest magnitude
   ! elements in each column occur along the diagonal. If "permutation" is
   ! present, it is the array which achieves this ordering, i.e. at the end of
   ! the routine, what is done is: self = self(:,permutation).
   end

!  ========================
!  Idempotency purification
!  ========================

   McWeeny_purify(S) ::: PURE
   ! Apply the McWeeny purification to obtain an idempotent density
   ! matrix, using "S" as the metric.
      self :: INOUT
      S :: MAT{REAL}, IN

      W,PS,PSPS :: MAT{REAL}*
      diff :: REAL
      n :: INT

      n = .dim1

      W.create(n,n)
      PS.create(n,n)
      PSPS.create(n,n)

      W    = self
      PS   = self
      PSPS = self

      do

         ! McWeeny term
         PS.to_product_of(self,S)
         W.to_scaled_product_of(PS,self,fac=THREE)
         PSPS.to_product_of(PS,PS)
         W.plus_scaled_product_of(PSPS,self,fac=-TWO)

         ! Same?
         diff = maxval(abs(self - W))
         self = W
         if (diff<REAL_EPSILON) exit


      end

      PSPS.destroy
      PS.destroy
      W.destroy


   end

   Holas_5th_order_purify(S) ::: PURE
   ! Apply the Holas's 5th order purification to obtain an idempotent
   ! density matrix, using "S" as the metric. This was shown by
   ! J. Kim and Y. Jung (2011) CPL 511 p. 159-60.
      self :: INOUT
      S :: MAT{REAL}, IN

      W,PS,PS2,PS3 :: MAT{REAL}*
      diff :: REAL
      n :: INT

      n = .dim1
      W.create(n,n)
      PS.create(n,n)
      PS2.create(n,n)
      PS3.create(n,n)

      W   = self
      PS  = self
      PS2 = self
      PS3 = self

      do

         ! Holas term
         PS.to_product_of(self,S)
         PS2.to_product_of(PS,PS)
         W.to_scaled_product_of(PS2,self,fac=TEN)

         PS3.to_product_of(PS2,PS)
         W.plus_scaled_product_of(PS3,self,fac=-FIFTEEN)

         PS2.to_product_of(PS3,PS)
         W.plus_scaled_product_of(PS2,self,fac=SIX)

         ! Same?
         diff = maxval(abs(self - W))
         self = W
         if (diff<REAL_EPSILON) exit

      end

      PS3.destroy
      PS2.destroy
      PS.destroy
      W.destroy


   end

!  =====================
!  Eigenproblem routines
!  =====================

!   diagonalize_by_jacobi_2(eigenvalues, failure, iter, u, eps, max_iter)
!   ! Diogonalises self using the Jacobi rotations method. Returns the
!   ! eigenvalues and rotation matrix. Input the accuracy if desired.
!     eigenvalues :: VEC{REAL}
!     failure :: BIN
!     iter :: INT
!     u :: MAT{REAL}
!     eps :: REAL, optional
!     max_iter :: INT, optional
!  ENSURE(.is_square, "the matrix is not square")
!  ENSURE(.is_symmetric, "the matrix is not symmetrix")
!  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
!     i,k, max_iter_default  :: INT
!   ! i,k, iter, max_iter_default  :: INT
!     a,b,c,d, u_pp, u_pq, accuracy :: REAL
!     no_rotation :: BIN
!     m :: MAT{REAL}*
!     r_p, r_q :: VEC{REAL}*
!     m.create_copy(self)
!     r_p.create(.dim1)
!     r_q.create(.dim1)
!     accuracy = TOL(12)
!     if (present(eps)) accuracy=eps
!     max_iter_default=1000
!     if (present(max_iter)) max_iter_default=max_iter
!     no_rotation=FALSE
!     iter=-1
!        do i=1,.dim1
!           do k=1,.dim1
!           if (k==i) then
!           u(k,i)=1
!           else
!           u(k,i)=0
!           end if
!           end do
!           end do
!
!     do
!        failure = iter>max_iter_default
!        if (failure) exit
!        if (no_rotation) exit
!        no_rotation=TRUE
!        do i=1,.dim1
!        do k=1,(i-1)
!           c = m(i,k)
!           if (abs(c)<accuracy) cycle
!           a = m(i,i)
!           b = m(k,k)
!           no_rotation=FALSE
!           d = (2*c)/(a-b+sqrt((a-b)==2+4*c==2))
!           u_pp = 1/(sqrt(1+d==2))
!           u_pq = d*u_pp
!          m.rotate_by_jacobi(i, k, u_pp, u_pq)
!      r_p  = u_pp*u(i,:) + u_pq*u(k,:)
!      r_q  = - u_pq*u(i,:) + u_pp*u(k,:)
!      u(i,:) = r_p
!      u(k,:) = r_q
!        end do
!        end do
!        iter=iter+1
!     end do
!     r_p.destroy; r_q.destroy
!     m.put_diagonal_to(eigenvalues)
!     m.destroy
!   end

!   diagonalize_by_jacobi(eigenvalues,eigenvectors,eps,max_iterations)
!   ! Diagonalises "self" using the Jacobi rotations method. Returns the
!   ! "eigenvalues" and "eigenvectors". Input the accuracy "eps" or the
!   ! maximum number of iterations "max_iter", if desired.
!     eigenvalues :: VEC{REAL}
!     eigenvectors :: MAT{REAL}
!     eps :: REAL, optional
!     max_iterations :: INT, optional
!  ENSURE(.is_square, "the matrix is not square")
!  ENSURE(.is_symmetric, "the matrix is not symmetrix")
!  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
!     i,j,iter,max_iter  :: INT
!     c,d,u_ii,u_ij,accuracy,del :: REAL
!     done :: BIN
!     W :: MAT{REAL}*
!     r_i,r_j :: VEC{REAL}*
!     accuracy = TOL(12)
!     if (present(eps)) accuracy = eps
!     max_iter=1000
!     if (present(max_iterations)) max_iter = max_iterations
!     W.create_copy(self)
!     r_i.create(.dim1)
!     r_j.create(.dim1)
!     eigenvectors.to_unit_matrix
!     iter=-1
!     done = FALSE
!     do
!      ! DIE_IF(iter>max_iter,"too many iterations")
!        if (iter>max_iter) exit
!        if (done) exit
!        write(*,*) "iter =",iter
!        write(*,"(a)") "W:"
!        write(*,"(3f12.8)") W
!        done = TRUE
!        do i = 1,.dim1
!        do j = 1,i-1
!           c = W(i,j)
!           if (abs(c)<accuracy) cycle
!           del = W(i,i) - W(j,j)
!           done = FALSE
!           d = TWO*c/(del+sqrt(del*del+FOUR*c*c))
!           u_ii = ONE/(sqrt(ONE+d*d))
!           u_ij = d*u_ii
!           W.rotate_by_jacobi(i,j,u_ii,u_ij)
!        write(*,"(a,2i3)") "W, ij = ",i,j
!        write(*,"(3f12.8)") W
!           r_i =  u_ii*eigenvectors(i,:) + u_ij*eigenvectors(j,:)
!           r_j = -u_ij*eigenvectors(i,:) + u_ii*eigenvectors(j,:)
!           eigenvectors(i,:) = r_i
!           eigenvectors(j,:) = r_j
!        end
!        end
!        iter = iter + 1
!     end
!     r_i.destroy; r_j.destroy
!     W.put_diagonal_to(eigenvalues)
!     W.destroy
!   end

   diagonalize_by_jacobi(eigenvalues,eps,max_iterations)
   ! Diagonalises "self" using the Jacobi rotations method. Returns
   ! the "eigenvalues". Input the accuracy "eps" or the maximum number
   ! of iterations "max_iter", if desired.
      eigenvalues :: VEC{REAL}
      eps :: REAL, optional
      max_iterations :: INT, optional

  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")

      i,j,iter,max_iter  :: INT
      accuracy,tol :: REAL
      done :: BIN
      W :: MAT{REAL}*

      accuracy = TOL(12)
      if (present(eps)) accuracy = eps

      max_iter = 30
      if (present(max_iterations)) max_iter = max_iterations

      W.create_copy(self)

      iter = 0

      do

        iter = iter + 1
        if (iter>max_iter) exit

        tol = accuracy
        if (iter<=3) tol = TOL(1)*(MAT{REAL}:sum_elements(abs(W)) - W.trace)

        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j)
        end
        end

        done = done AND iter>3

        if (done) exit

      end

      DIE_IF(iter>max_iter,"too many iterations")

      W.put_diagonal_to(eigenvalues)

      W.destroy

   end

   diagonalize_by_jacobi(eigenvalues,eigenvectors,eps,max_iterations)
   ! Diagonalises "self" using the Jacobi rotations method. Returns the
   ! "eigenvalues". Input the accuracy "eps" or the maximum number of iterations
   ! "max_iter", if desired.
      eigenvalues :: VEC{REAL}
      eigenvectors :: MAT{REAL}
      eps :: REAL, optional
      max_iterations :: INT, optional
  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
  ENSURE(eigenvectors.is_square, "eigenvectors are not square")
  ENSURE(eigenvalues.dim1>=.dim1,"wrong size, eigenvectors")
      i,j,iter,max_iter  :: INT
      accuracy,tol :: REAL
      done :: BIN
      W :: MAT{REAL}*
      accuracy = TOL(8)
      if (present(eps)) accuracy = eps
      max_iter = 500
      if (present(max_iterations)) max_iter = max_iterations
      W.create_copy(self)
      eigenvectors.to_unit_matrix
      iter = 0
      do
        iter = iter + 1
        DIE_IF(iter>max_iter,"too many iterations")
        if (iter>max_iter) exit
        tol = accuracy
        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j,eigenvectors)
        end
        end
        done = done AND iter>3
        if (done) exit
      end
      W.put_diagonal_to(eigenvalues)
      W.destroy
   end

!   solve_general_eigenproblem(eigenvalues,left,right,normalize)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "left" and "right" eigenvectors. If "normalize" is present
!   ! and FALSE, the left and right eigenvectors are not automatically
!   ! renormalized so that (left)^T (right) = 1
!      eigenvalues :: VEC{CPX}
!      left,right :: MAT{CPX}
!      normalize :: BIN, optional
!      er,ei,W :: VEC{REAL}*
!      A,le,re :: MAT{REAL}*
!      i,dim,dimW, info :: INT
!      normalise :: BIN
!      dot :: REAL
!      ENSURE(.is_square,"non-square matrix")
!      ENSURE(size(eigenvalues)>=.dim1,"eigenvalue array too small")
!      ENSURE(size(left)>=size(self),"left eigenvector matrix too small")
!      ENSURE(size(right)>=size(self),"right eigenvector matrix too small")
!      dim = .dim1
!      normalise = TRUE
!      if (present(normalize)) normalise = normalize
!      if (self.is_symmetric) then
!         A.create(dim,dim)
!         er.create(dim)
!         .solve_symmetric_eigenproblem(er,A)
!         eigenvalues = er
!         right = A
!         left  = A
!         er.destroy
!         A.destroy
!      else
!         A.create(dim,dim)
!         er.create(dim); ei.create(dim)
!         le.create(dim,dim); re.create(dim,dim)
!         dimW = 8*dim
!         W.create(dimW)
!         A = self
!         ! Solve the eigenvalueproblem
!         call dgeev('V','V',dim,A,dim,er,ei,le,dim,re,dim,W,dimW,info)
!         ENSURE(info==0,"error, info="// trim(info.to_str))
!         ! Search for the complex eigenvalues/vectors
!         i = 1
!         do
!            if (NOT ei(i).is_zero(TOL(20))) then
!               eigenvalues(i)   = cmplx(er(i)  ,ei(i),  kind=CPX_KIND)
!               eigenvalues(i+1) = cmplx(er(i+1),ei(i+1),kind=CPX_KIND)
!               left(:,i)    = cmplx(le(:,i), le(:,i+1),kind=CPX_KIND)
!               left(:,i+1)  = cmplx(le(:,i),-le(:,i+1),kind=CPX_KIND)
!               right(:,i)   = cmplx(re(:,i), re(:,i+1),kind=CPX_KIND)
!               right(:,i+1) = cmplx(re(:,i),-re(:,i+1),kind=CPX_KIND)
!               i = i + 2
!            else
!               eigenvalues(i)   = cmplx(er(i)  , ZERO,  kind=CPX_KIND)
!               left(:,i)    = cmplx(le(:,i),ZERO,kind=CPX_KIND)
!               right(:,i)   = cmplx(re(:,i),ZERO,kind=CPX_KIND)
!               i = i + 1
!            end
!            if (i>dim) exit
!         end
!         W.destroy
!         re.destroy; le.destroy
!         ei.destroy; er.destroy
!         A.destroy
!      end
!      if (normalise) then
!         do i = 1,dim
!            dot = dot_product(left(:,i),right(:,i))
!            dot = ONE/sqrt(dot)
!            left(:,i)  = dot*left(:,i)
!            right(:,i) = dot*right(:,i)
!         end
!      end
!   end

   solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors"
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT

#ifdef ESSL
      .solve_symm_eigenproblem_ESSL(eigenvalues,eigenvectors)
#else
      .solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors)
#endif

   end

   solve_symm_eigenproblem_ESSL(eigenvalues,eigenvectors) ::: private
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors". ESSL version.
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(eigenvalues.dim >=.dim1,"eigenvalue array too small")
   ENSURE(eigenvectors.dim>=.dim, "eigenvector matrix too small")

      ap,W :: VEC{REAL}*
      dim :: INT

      eigenvalues  = eigenvalues
      eigenvectors = eigenvectors

      dim = .dim1
      ap.create(dim*(dim+1)/2)
      self.zip_lower_triangle_to(ap)
      W.create(2*dim)

#ifdef ESSL
      call dspev(21,ap,eigenvalues,eigenvectors,dim,dim,W,2*dim)
#endif

      W.destroy
      ap.destroy

   end

   solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors) ::: private
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors". LAPACK version.
      self :: IN
      eigenvalues :: VEC{REAL}, OUT
      eigenvectors :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
   ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")

      W :: VEC{REAL}*
      dim,fail,lwork :: INT

      dim = .dim1
      lwork = max(dim*dim,3*dim-1)
      W.create(lwork)
      eigenvectors = self
      fail = 0
#ifndef ESSL
      call dsyev("V","L",dim,eigenvectors,dim,eigenvalues,W,lwork,fail)
#endif
      W.destroy

   ENSURE(fail==0,"no solution, error found")

   end

   internal_vectors(eigenvectors2,iv_tol) ::: leaky
   ! Extract the internal vectors of a matrix i.e. vectors in the
   ! orthocomplement of the kernel of the matrix.
   !leaky because the number of outputed internal vectors is not known
   !beforehand
     eigenvectors2 :: MAT{REAL}*
     iv_tol :: REAL, optional
     ENSURE(.dim1==.dim2,"matrix not square")
     eigenvalues :: VEC{REAL}*
     eigenvectors :: MAT{REAL}*
     tol :: REAL
     i,h,dim :: INT

     tol = INTERNAL_GEMINAL_TOL
     if (present(iv_tol)) tol = iv_tol

     dim = .dim1
     eigenvalues.create(dim)
     eigenvectors.create(dim,dim)
     .solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
     h = count(mask= eigenvalues >tol)
     DIE_IF(count(mask= eigenvalues <  -TOL(10))/=0,"matrix not positive")
     DIE_IF(h==0,"no internal vector")

     eigenvectors2.create(h,dim)
     h=0
     do i=1,dim
       if (NOT eigenvalues(i).is_zero(tol)) then
         h=h+1
         eigenvectors2(h,:)=eigenvectors(:,i)
       end
     end

     eigenvalues.destroy
     eigenvectors.destroy

   end

!  Unused ESSL routines

!   solve_general_eigenproblem(eigenvalues,eigenvectors)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "eigenvectors"
!      eigenvalues :: VEC{CPX}
!      eigenvectors :: MAT{CPX}
!       W :: VEC{REAL}*
!      dim1,dim2,dime,dimv :: INT
!      select :: BIN
!      dim1 = .dim1
!      dim2 = .dim2
!      dime = size(eigenvalues)
!      dimv = size(eigenvectors)
!      ENSURE(dim1==dim2,"non-square matrix")
!      ENSURE(dime>=dim1,"eigenvalue array too small")
!      ENSURE(dimv>=dim1*dim1,"eigenvector matrix too small")
!      W.create(2*dim1)
!      call dgeev(1,self,dim1,eigenvalues,eigenvectors,dim1,select,dim1,W,2*dim1)
!      W.destroy
!   end
!
!   solve_general_eigenproblem(eigenvalues,left,right,normalize)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "left" and "right" eigenvectors. If "normalize" is present
!   ! and FALSE, the left and right eigenvectors are not automatically
!   ! renormalized so that (left)^T (right) = 1.
!   ! NOTE : this routine fails if there are complex eigenvalues. Use the complex
!   ! routine in this case.
!      eigenvalues :: VEC{REAL}, target
!      left,right :: MAT{REAL}, target
!      normalize :: BIN, optional
!      er,ei,W :: VEC{REAL}*
!      A,le,re :: MAT{REAL}*
!      i,dim,dimW, info :: INT
!      normalise :: BIN
!      dot :: REAL
!      ENSURE(.is_square,"non-square matrix")
!      ENSURE(size(eigenvalues)>=.dim1,"eigenvalues array too small")
!      ENSURE(size(left)>=size(self),"left eigenvector matrix too small")
!      ENSURE(size(right)>=size(self),"right eigenvector matrix too small")
!      dim = .dim1
!      normalise = TRUE
!      if (present(normalize)) normalise = normalize
!      if (.is_symmetric) then
!         .solve_symmetric_eigenproblem(eigenvalues,right)
!         left = right
!      else
!         A.create(dim,dim)
!         ei.create(dim)
!         er => eigenvalues
!         le => left
!         re => right
!         dimW = 8*dim
!         W.create(dimW)
!         A = self
!         ! Solve the eigenvalueproblem
!         call dgeev('V','V',dim,A,dim,er,ei,le,dim,re,dim,W,dimW,info)
!         ENSURE(info==0,"error, info="// trim(info.to_str))
!         ! Search for the complex eigenvalues/vectors
!         do i = 1,dim
!            if (NOT ei(i).is_zero(TOL(20))) then
!               DIE("There are complex eigenvalues, use the complex routine")
!            end
!         end
!         W.destroy
!         ei.destroy
!         A.destroy
!      end
!      if (normalise) then
!         do i = 1,dim
!            dot = dot_product(left(:,i),right(:,i))
!            dot = ONE/sqrt(dot)
!            left(:,i)  = dot*left(:,i)
!            right(:,i) = dot*right(:,i)
!         end
!      end
!   end

!  ========================
!  Linear equation routines
!  ========================

   solve_linear_equation(rhs,solution,fail)
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yeilding vector "solution" as the answer
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      fail :: BIN, OUT, optional
#ifdef ESSL
      .solve_linear_equation_ESSL(rhs,solution)
#else
      .solve_linear_equation_LAPACK(rhs,solution,fail)
#endif
   end

   solve_linear_equation_ESSL(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yeilding vector "solution" as the answer. ESSL version
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim :: INT
      dim = rhs.dim
      LU.create(dim,dim)
      pivot.create(dim)
      LU = self
      solution = rhs
#ifdef ESSL
      call dgef(LU,dim,dim,pivot)
      call dges(LU,dim,dim,pivot,solution,0)
#endif
      pivot.destroy
      LU.destroy
   end

   solve_linear_equation_LAPACK(rhs,solution,fail) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yielding vector "solution" as the answer. LAPACK version.
      self :: INOUT
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      fail :: BIN, OUT, optional

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")

      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim,nrhs,err :: INT

      dim = rhs.dim
      nrhs = 1
      nullify(LU); LU.create(dim,dim)
      nullify(pivot); pivot.create(dim)

      LU = self
      solution = rhs
#ifndef ESSL
      call dgesv(dim,nrhs,LU,dim,pivot,solution,dim,err)
#endif
      if (present(fail)) then
         fail = FALSE
         if (err/=0) fail = TRUE
      else
         ENSURE(err==0,"no solution, error found")
      end

      pivot.destroy
      LU.destroy

   end

   solve_linear_equations(rhs,solution)
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
      rhs :: MAT{REAL}, IN
      solution :: MAT{REAL}, OUT
#ifdef ESSL
      .solve_linear_equations_ESSL(rhs,solution)
#else
      .solve_linear_equations_LAPACK(rhs,solution)
#endif
   end

   solve_linear_equations_ESSL(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
   ! ESSL version.
      rhs :: MAT{REAL}, IN
      solution :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim1==.dim2,"rhs incompatible with coefficient matrix")
   ENSURE(rhs.dim2 >0,"no rhs vectors")

      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim1,nrhs :: INT

      dim1 = rhs.dim1
      nrhs = rhs.dim2
      nrhs = nrhs
      LU.create(dim1,dim1)
      pivot.create(dim1)
      LU = self
      solution = rhs
#ifdef ESSL
      call dgef(LU,dim1,dim1,pivot)
      call dgesm("N",LU,dim1,dim1,pivot,solution,dim1,nrhs)
#endif

      pivot.destroy
      LU.destroy

   end

   solve_linear_equations_LAPACK(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
   ! LAPACK version
      self :: INOUT
      rhs :: MAT{REAL}, IN
      solution :: MAT{REAL}, OUT

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim1==.dim2,"rhs incompatible with coefficient matrix")
   ENSURE(nrhs>0,"no rhs vectors")

      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim1,nrhs,err :: INT
      dim1 = rhs.dim1
      nrhs = rhs.dim2
      LU.create(dim1,dim1)
      pivot.create(dim1)
      LU = self
      solution = rhs
#ifndef ESSL
      call dgesv(dim1,nrhs,LU,dim1,pivot,solution,dim1,err)
#endif

      pivot.destroy
      LU.destroy

      ENSURE(err==0,"no solution, error found")

   end

   solve_convex_linear_equation(rhs,solution,plist,keep0,keep1,fail)
   ! This routine solves the quadratic minimisation problem:
   !    f(X) = rhs . X  -  HALF * X^T . self . X  |  X>=0
   ! over all the elements in "plist", subject to the constraint that the
   ! "solution" X is positive for all elements in "plist". Any elements of the
   ! "solution" not in "plist" are not constrained to be positive nor do they
   ! participate in the evaluation of the quadratic function f -- they are
   ! usually lagrange multipliers. This routine involves solving reduced linear
   ! equations with "self" as the LHS and "rhs" as the RHS, over all partitions
   ! of the elements in "plist".  If "keep0" is present, then the indices in
   ! this sublist of "plist" must be kept when considering all partitions. If
   ! "keep1" is present, then the indices in this sublist of "plist" must be
   ! kept plus at most one extra index for each index in "keep1", and further,
   ! the positivity constraint is relaxed on these indices. It is an error if
   ! "keep0" and "keep1" are both present. If present, "fail" is set TRUE if no
   ! solutions are found, otherwise the routine terminates with an error.
   ! WARNING: if the dimension of the matrix is too large, this routine will
   ! take a long time.
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      plist :: VEC{INT}, IN
      keep0,keep1 :: VEC{INT}, IN, optional
      fail :: BIN, OUT, optional

   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
   ENSURE(plist.dim<=.dim1,"plist to large")
   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
   ENSURE(NOT (present(keep0) AND present(keep1)),"specify only keep0 or keep1")

      pdim,rdim,kdim,k,n,n_combinations :: INT
      ulist,list :: VEC{INT}*
      combination :: MAT{INT}*
      sol,sol0,rhs0 :: VEC{REAL}*
      e,e0 :: REAL
      found_one,even :: BIN

!      if (.dim1==6) then
!      list.create(4)
!      sol.create(.dim1)
!      sol = ZERO
!      sol(1) = 0.3
!      sol(2) = 0.7
!      sol(4) = 0.4
!      sol(5) = 0.6
!      list = [1,2,4,5]
!            e0 = dot_product(rhs(list),sol(list)) &
!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!      print *, "===in MAT, average energy =",e0
!      sol.destroy
!      list.destroy
!      end
!!      if (.dim1==3) then
!!      list.create(2)
!!      sol.create(.dim1)
!!      sol = ZERO
!!      sol(1) = 0.3
!!      sol(2) = 0.7
!!      list = [1,2]
!!            e0 = dot_product(rhs(list),sol(list)) &
!!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!!      print *, "===in MAT, average energy =",e0
!!      sol.destroy
!!      list.destroy
!!      end
      even = FALSE
      if (present(keep0)) then
         ENSURE(keep0.has_all_elements_common_with(plist),"keep0 not in plist")
         kdim = keep0.dim
         even = kdim.is_even
      end
      if (present(keep1)) then
         ENSURE(keep1.has_all_elements_common_with(plist),"keep1 not in plist")
         kdim = keep1.dim
         even = kdim.is_even
      end
      pdim = plist.dim
      WARN_IF(pdim>=20,"LHS dimension may be too large")
      found_one = FALSE
      e = huge(ONE)
      sol.create(.dim1)
      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
      ulist.prune(plist)                          ! ulist = all - plist = unconstrained
    ! print *, "-----------start------------"
    ! print *, "even =",even
    ! print *, "plist:"
    ! print *, plist
    ! print *, "ulist:"
    ! print *, ulist
      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
    ! print *, "---> combinations of length k =", k
         if (present(keep1)) then
            if (k>2*kdim) cycle
         end
         n_combinations = int(pdim.choose(k))
         combination.create(k,n_combinations)
         plist.make_combinations_of_length(k,combination)
         rdim = k + .dim1 - pdim
         rhs0.create(rdim)
         sol0.create(rdim)
         list.create(rdim)                        ! list = comb(plist) + ulist
         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
    ! print *, "combination:"
    ! print *, combination(:,n)
            if (present(keep1)) then               ! if present, keep only these elements
               if (NOT keep1.has_all_elements_common_with(combination(:,n))) cycle
            end
            if (present(keep0)) then               ! if present, keep only these elements
    ! print *, "keep0:"
    ! print *, keep0
             ! if (NOT keep0.has_all_elements_common_with(combination(:,n))) cycle
               if (NOT keep0.has_elements_common_with(combination(:,n))) cycle
               if (even AND all(combination(:,n)> .dim1/2)) cycle
               if (even AND all(combination(:,n)<=.dim1/2)) cycle
            end
            list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
            list(k+1:) = ulist                    ! Always add the list of unconstrained elements
    ! print *, "list:"
    ! print *, list
    ! print *, "rhs:"
    ! print *, rhs
            rhs0 = rhs(list)
    ! print *, "rhs0:"
    ! print *, rhs0
    ! print *, "lhs0:"
    ! print *, self(list,list)
            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
            sol(list) = sol0
    ! print *, "sol0:"
    ! print *, sol0
    ! print *, "sol:"
    ! print *, sol
            if (NOT present(keep1) AND any(sol(list(1:k))<ZERO)) cycle  ! Unacceptable ..............
            e0 = dot_product(rhs(list),sol(list)) &
               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
    ! print *, "e0 = ",e0
            if (e0>=e) cycle                      ! Found a better solution before
            solution = ZERO                       ! Zero non-"list" solution elements
            solution(list) = sol(list)            ! Keep this solutions
    ! print *, "new solution found:"
    ! print *, solution
            e = e0                                ! Keep this E value
            found_one = TRUE
         end
         list.destroy
         sol0.destroy; rhs0.destroy
         combination.destroy
      end
      ulist.destroy
      sol.destroy
      if (present(fail)) then
         if (NOT found_one) then; fail = TRUE
         else;                    fail = FALSE
         end
      else
         DIE_IF(NOT found_one,"acceptable solution was not found")
      end
   end

!   solve_convex_linear_equation(rhs,solution,plist,keep0,keep1,even,fail)
!   ! This routine solves the quadratic minimisation problem:
!   !    f(X) = rhs . X  -  HALF * X^T . self . X  |  X>=0
!   ! over all the elements in "plist", subject to the constraint that the
!   ! "solution" X is positive for all elements in "plist". Any elements of the
!   ! "solution" not in "plist" are not constrained to be positive nor do they
!   ! participate in the evaluation of the quadratic function f -- they are
!   ! usually lagrange multipliers. This routine involves solving reduced linear
!   ! equations with "self" as the LHS and "rhs" as the RHS, over all partitions
!   ! of the elements in "plist".  If "keep0" is present, then the indices in
!   ! this sublist of "plist" must be kept when considering all partitions. If
!   ! "keep1" is present, then the indices in this sublist of "plist" must be
!   ! kept plus one extra index, when considering the partitions, and further,
!   ! the positivity constraint is relaxed on these indices. It is an error if
!   ! "keep0" and "keep1" are both present. If "even" is present and TRUE then
!   ! "self" must be even dimensioned and the linear equations are considered to
!   ! be a (alpha,beta) direct product -- "plist" refers only to the first half of
!   ! the indices: the remaining indices are obtained from the first half by
!   ! adding .dim/2. The same applies to the indices in "keep0" and "keep1" --
!   ! the remaining indices must be generated. If present, "fail" is set TRUE if
!   ! no solutions are found, otherwise the routine terminates with an error.
!   ! WARNING: if the dimension of the matrix is too large, this routine will
!   ! take a long time.
!      rhs,solution :: VEC{REAL}
!      plist :: VEC{INT}
!      keep0,keep1 :: VEC{INT}, optional
!      even,fail :: BIN, optional
!   ENSURE(.is_square,"non-square matrix")
!   ENSURE(rhs.dim==.dim1,"incompatible rhs")
!   ENSURE(solution.dim==.dim1,"incompatible solution vector")
!   ENSURE(plist.dim<=.dim1,"plist to large")
!   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(NOT (present(keep0) AND present(keep1)),"specify only keep0 or keep1, not both")
!      pdim,pfac,rdim,kdim,k,n,n_combinations :: INT
!      ulist,list :: VEC{INT}*
!      combination :: MAT{INT}*
!      sol,sol0,rhs0 :: VEC{REAL}*
!      e,e0 :: REAL
!      found_one,is_even :: BIN
!      is_even = FALSE
!      if (present(even)) is_even = even
!      pfac = 1
!      if (is_even) then
!         ENSURE(.dim1.is_even,"self not even dimensioned")
!         pfac = 2
!      end
!      if (present(keep0)) then
!         ENSURE(keep0.has_all_elements_common_with(plist),"keep0 not a sublist of plist")
!         kdim = keep0.dim
!      end
!      if (present(keep1)) then
!         ENSURE(keep1.has_all_elements_common_with(plist),"keep1 not a sublist of plist")
!         kdim = keep1.dim
!      end
!      pdim = plist.dim
!      WARN_IF(pdim>=20,"LHS dimension may be too large")
!      found_one = FALSE
!      e = huge(ONE)
!      sol.create(.dim1)
!      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
!      ulist.prune(plist)                          ! ulist = all - plist = unconstrained
!      print *, "-----------start------------"
!      print *, "plist:"
!      print *, plist
!      print *, "ulist:"
!      print *, ulist
!      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
!      print *, "combinations of length k =", k
!         if (present(keep1)) then
!            if (k/=kdim+1) cycle
!         end
!         n_combinations = int(pdim.choose(k))
!         combination.create(k,n_combinations)
!         plist.make_combinations_of_length(k,combination)
!         rdim = pfac*k + .dim1 - pfac*pdim
!         rhs0.create(rdim)
!         sol0.create(rdim)
!         list.create(rdim)                        ! list = comb(plist) + ulist
!         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
!      print *, "combination:"
!      print *, combination(:,n)
!            if (present(keep1)) then               ! if present, keep only these elements
!               if (NOT keep1.has_all_elements_common_with(combination(:,n))) cycle
!            end
!            if (present(keep0)) then               ! if present, keep only these elements
!               if (NOT keep0.has_all_elements_common_with(combination(:,n))) cycle
!            end
!            if (is_even) then
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(k+1:) = ulist                    ! Always add the list of unconstrained elements
!            else
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(k+1:) = ulist                    ! Always add the list of unconstrained elements
!            end
!      print *, "list:"
!      print *, list
!            rhs0 = rhs(list)
!            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
!            sol(list) = sol0
!            if (NOT present(keep1) AND any(sol(list(1:k))<ZERO)) cycle  ! Unacceptable ..............
!            e0 = dot_product(rhs(list),sol(list)) &
!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!            if (e0>=e) cycle                      ! Found a better solution before
!            solution = ZERO                       ! Zero non-"list" solution elements
!            solution(list) = sol(list)            ! Keep this solutions
!      print *, "new solution found:"
!      print *, solution
!            e = e0                                ! Keep this E value
!            found_one = TRUE
!         end
!         list.destroy
!         sol0.destroy; rhs0.destroy
!         combination.destroy
!      end
!      ulist.destroy
!      sol.destroy
!      if (present(fail)) then
!         if (NOT found_one) then; fail = TRUE
!         else;                    fail = FALSE
!         end
!      else
!         DIE_IF(NOT found_one,"acceptable solution was not found")
!      end
!   end

!   solve_convex_linear_equations(rhs,solution,plist,nlist)
!   ! This routine solves the constrained linear equations with "self" as the LHS
!   ! of the linear equations, "rhs" as the RHS vector, and where the "solution"
!   ! is constrained to have positive values for those elements in "plist", AND
!   ! also "solution" minimises the quadratic problem "rhs.X - HALF*X^T.self.X"
!   ! over the elements in "plist" AND "nlist" of "solution". i.e.
!   ! plist -- positive or constrained elements, for testing
!   ! nlist -- non-positive or non-constrained elements for testing
!   ! Any other elements are non-constrained and non-tested. WARNING: if the
!   ! dimension of the matrix is too large, this routine will take a long time.
!      self :: target
!      rhs,solution :: VEC{REAL}
!      plist,nlist :: VEC{INT}
!   ENSURE(.is_square,"non-square matrix")
!   ENSURE(rhs.dim==.dim1,"incompatible rhs")
!   ENSURE(solution.dim==.dim1,"incompatible solution vector")
!   ENSURE(plist.dim<=.dim1,"plist to large")
!   ENSURE(nlist.dim<=.dim1,"nlist to large")
!   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(nlist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(plist.has_no_elements_common_with(nlist),"plist and nlist not disjoint")
!      pdim,rdim,k,n,n_combinations :: INT
!      ulist,tlist,list :: VEC{INT}*
!      combination :: MAT{INT}*
!      sol,sol0,rhs0 :: VEC{REAL}*
!      e,e0 :: REAL
!      found_one :: BIN
!      found_one = FALSE
!      e = huge(ONE)
!      pdim = plist.dim
!      sol.create(.dim1)
!      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
!      ulist.prune(plist)                          ! ulist = all - plist
!      print *, "-----------start------------"
!      print *, "ulist:"
!      print *, ulist
!      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
!      print *, "combinations of length k =", k
!         n_combinations = int(pdim.choose(k))
!         combination.create(k,n_combinations)
!         plist.make_combinations_of_length(k,combination)
!         rdim = k + .dim1 - pdim
!         rhs0.create(rdim)
!         sol0.create(rdim)
!         list.create(rdim)                        ! list = comb(plist) + ulist
!         tlist.create(k+nlist.dim)
!         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
!            list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!            list(k+1:) = ulist                    ! Add the list of unconstrained elements
!            tlist(1:k) = combination(:,n)
!            tlist(k+1:)= nlist                    ! test tlist = comb(plist) + nlist
!      print *, "list:"
!      print *, list
!      print *, "tlist:"
!      print *, tlist
!            rhs0 = rhs(list)
!            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
!      print *, "rhs0:"
!      print *, rhs0
!      print *, "sol0:"
!      print *, sol0
!      sol(list) = sol0
!      print *, "sol:"
!      print *, sol(list)
!            if (any(sol(list(1:k))<ZERO)) cycle        ! Unacceptable ..............
!      print *, "passed +ve test"
!            e0 = dot_product(rhs(tlist),sol(tlist)) &
!               - HALF*dot_product(sol(tlist),matmul(self(tlist,tlist),sol(tlist)))
!      print *, "e0=",e0
!            if (e0>=e) cycle                      ! Found a better solution before
!      print *, "passed e0 test"
!            solution = ZERO                       ! Zero non-"list" solution elements
!            solution(list) = sol(list)            ! Keep this solutions
!            e = e0                                ! Keep this E value
!            found_one = TRUE
!         end
!         tlist.destroy; list.destroy
!         sol0.destroy; rhs0.destroy
!         combination.destroy
!      end
!      print *, "-----------finish------------"
!      ulist.destroy
!      sol.destroy
!    ! if (NOT present(keep)) indices.destroy
!      DIE_IF(NOT found_one,"acceptable solution was not found")
!   end

   solve_ill_linear_equations(rhs,solution,tol_0,n_0,tol_near_0,n_near_0,eval_near_0,evec_near_0,inverse,CM) ::: leaky
   ! Solve a set of ill-conditioned linear equations. Eigenvalues of
   ! "self" less than "tol_near_0" are ignored.
      rhs :: VEC{REAL}, IN
      solution :: VEC{REAL}, OUT
      tol_0,tol_near_0 :: REAL, IN, optional
      n_0,n_near_0 :: INT, OUT, optional
      eval_near_0 :: VEC{REAL}*, optional
      evec_near_0 :: MAT{REAL}*, optional
      inverse,CM :: MAT{REAL}, OUT, optional

   ENSURE(.is_square,"not square")
   ENSURE(present(tol_0)       EQV present(n_0),        "tol/n_0 not both present")
   ENSURE(present(tol_near_0)  EQV present(n_near_0),   "tol/n_near_0 not both present")
   ENSURE(present(eval_near_0) EQV present(evec_near_0),"eval/evec_near_0 not both there")

      inv,evec :: MAT{REAL}*
      eval :: VEC{REAL}*
      d,i,j,k :: INT
      temp :: REAL

      ! Temporaries
      d = .dim1
      eval.create(d)
      evec.create(d,d)
      inv.create(d,d)

      ! Solve the eigenvalue problem
      .solve_symmetric_eigenproblem(eval,evec)

      ! Count eigenvalues which are zero
      if (present(n_0) AND present(tol_0)) &
         n_0 = count(eval<=ZERO OR abs(eval)<=tol_0)

      ! Count eigenvalues which are nearly zero (leaky)
      if (present(n_near_0) AND present(tol_near_0)) then

         n_near_0 = count(eval<=ZERO OR abs(eval)<=tol_near_0)

         eval_near_0.destroy
         eval_near_0.create(n_near_0)
         evec_near_0.destroy
         evec_near_0.create(d,n_near_0)

         j = 0
         do i = 1,d
            if (eval(i)>ZERO AND abs(eval(i))>tol_near_0) then
               eval(i) = ONE/eval(i)
            else
               j = j + 1
               eval_near_0(j)   = eval(i)
               evec_near_0(:,j) = evec(:,i)
               eval(i) = ZERO
            end
         end
      end

      ! Make the inverse
      evec = transpose(evec)

      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(k,i)*eval(k)*evec(k,j)
         end
         inv(i,j) = temp
      end
      end

      evec.destroy
      eval.destroy

      ! Get the solution
      solution.to_product_of(inv,rhs)

      ! Get uncertainties
      if (present(inverse)) then
         inverse = inv
      end

      ! Get correlation matrix
      if (present(CM)) then

         if (present(tol_near_0)) then
            do i = 1,d
            do j = 1,d
               if (inv(i,i).equals(ZERO,TOL(9)) OR inv(j,j).equals(ZERO,TOL(9))) then
                  CM(i,j) = ZERO
               else
                  CM(i,j) = inv(i,j)/sqrt(inv(i,i)*inv(j,j))
               end
            end
            end
         else
            do i = 1,d
            do j = 1,d
               CM(i,j) = inv(i,j)/sqrt(inv(i,i)*inv(j,j))
            end
            end
         end

      end

      inv.destroy

   end

!  ==========================================================
!  Matrix functions: square roots, inverses, and exponentials
!  ==========================================================

   to_inverse_of(R)
   ! self = (R)^(-1); can have R=self
      self :: INOUT
      R :: MAT{REAL}, IN

#ifdef ESSL
      .to_inverse_of_ESSL(R)
#else
      .to_inverse_of_LAPACK(R)
#endif

   end

   to_inverse_of_ESSL(R) ::: private
   ! self = (R)^(-1); can have R=self. ESSL version.
   ! This ESSL version is untested.
      self :: INOUT
      R :: MAT{REAL}, IN

   ENSURE(.is_square,"not square")
   ENSURE(.is_same_shape_as(R),"not same shape as R")

#ifdef ESSL
      W :: MAT{REAL}*
      ipiv :: VEC{INT}*
      d,d2 :: INT
      rcond :: REAL
      det :: VEC{REAL}(2)

      d  = size(R,1)
      d2 = d*d
      self = R
      ipiv.create(d)

      W.create(d,d)
      call dgef(d,d,self,ipiv)
      W(:,1) = ipiv
      call dgeicd(self, d, d, 4, rcond, det, W, d2)

      W.destroy
      ipiv.destroy
#else
      DIE("wtf?")
      if (FALSE) self = R
#endif

   end

   to_inverse_of_LAPACK(R) ::: private
   ! self = (R)^(-1); can have R=self. LAPACK version.
      self :: INOUT
      R :: MAT{REAL}, IN

   ENSURE(.is_square,"not square")
   ENSURE(.is_same_shape_as(R),"not same shape as R")

      W :: MAT{REAL}*
      ipiv :: VEC{INT}*
      d,d2,fail :: INT

      d  = size(R,1)
      d2 = d*d
      self = R
      ipiv.create(d)
      W.create(d,d)
      fail = 0
#ifndef ESSL
      call dgetrf(d,d,self,d,ipiv,fail)
      ENSURE(fail==0,"failed LU factorisation, fail = "//trim(fail.to_str))
      call dgetri(d,self,d,ipiv,W,d2,fail)
      ENSURE(fail==0,"failed back substitution, fail = "//trim(fail.to_str))
#endif

      ipiv.destroy
      W.destroy

   end

   to_pseudo_inverse_of(R,tol_0)
   ! self = (R)^(-1); can have R=self
      self :: INOUT
      R :: MAT{REAL}, IN
      tol_0 :: REAL, IN, optional

   ENSURE(.is_square,"self must be a square matrix")
   ENSURE(.is_same_shape_as(R),"self and R incomptabile")

      evec :: MAT{REAL}*
      eval :: VEC{REAL}*
      d,i,j,k :: INT
      tol,temp :: REAL

      ! Get tolerance for zero eigenvalue
      tol = REAL_EPSILON
      if (present(tol_0)) tol = tol_0

      ! Temporaries
      d = .dim1
      eval.create(d)
      evec.create(d,d)

      ! Solve the eigenvalue problem
      R.solve_symmetric_eigenproblem(eval,evec)

      ! Invert large eigenvalues
      j = 0
      do i = 1,d
         if (abs(eval(i))>tol) then; eval(i) = ONE/eval(i)
         else;                       eval(i) = ZERO
         end
      end

      ! Make the pseudo-inverse
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      ! Clean
      evec.destroy
      eval.destroy

   end

   to_inverse_of(R_eval,R_evec,tol,n_small)
   ! self = R^(-1), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on zero eigenvalues.  If "n_small" return the number of
   ! small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, target, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT

      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k,n :: INT
      val :: STR
      eps,temp :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Get inverse inverse eigenvalues
      d = R_eval.dim

      eval.create(d)

      n = 0
      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            val = temp.to_str("e15.8")
            DIE("non-positive eigenvalue, "// trim(val))
         else if (temp<=eps) then
            val = temp.to_str("e15.8")
            WARN("small eigenvalue, "// trim(val))
            n = n + 1
         end

         if (temp<=eps) then; eval(i) = ZERO
         else;                eval(i) = ONE/temp
         end

      end

      if (present(n_small)) n_small = n

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_sqrt_of(R)
   ! self = sqrt(R), cannot have R=self
      self :: OUT
      R :: MAT{REAL}, IN

 ! Looks like compiler problem for gfortran on 3/3/09
 ! ENSURE(.is_symmetric,"not symmetric")

      evec :: MAT{REAL}* DEFAULT_NULL
      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k :: INT
      temp :: REAL

      d = R.dim1

      eval.create(d)
      evec.create(d,d)

      R.solve_symmetric_eigenproblem(eval,evec)

      do i = 1,d
         temp = eval(i)
         if (temp <= ZERO) then
            WARN("non-positive eigenvalue, " // trim(temp.to_str("e15.8")))
            temp = abs(temp)
         end
         eval(i) = sqrt(temp)
      end

      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      evec.destroy
      eval.destroy

   end

   to_sqrt_of(R_eval,R_evec,tol)
   ! self = sqrt(R), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec".
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, target, IN
      tol :: REAL, optional, IN

      eval :: VEC{REAL}* DEFAULT_NULL
      d,i,j,k :: INT
      val :: STR
      eps,temp :: REAL

      eps = TOL(20)
      if (present(tol)) eps = tol

      d = R_eval.dim

      eval.create(d)

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            val = temp.to_str("e15.8")
            DIE("non-positive eigenvalue, "// trim(val))
         else if (temp<=eps) then
            val = temp.to_str("e15.8")
            WARN("small eigenvalue, "// trim(val))
            temp = abs(temp)
         end

         if (temp<=eps) then; eval(i) = ZERO
         else;                eval(i) = sqrt(temp)
         end

      end

      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_inverse_sqrt_of(R,tol,n_small,n_negative,shift)
   ! Set self = sqrt(R)^(-1). Cannot have R = self.
   ! If "tol" is present use that to decide on zero eigenvalues.
   ! If "n_small" return the number of small eigenvalues.
   ! If "shift" then use this value instead of small eigenvalues.
      self :: OUT
      R :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT
      shift :: REAL, optional, IN

 ! Looks like compiler problem for gfortran on 3/3/09
 ! ENSURE(.is_symmetric,"not symmetric")

      evec :: MAT{REAL}*
      eval :: VEC{REAL}*
      d,i,j,k,n_n,n_s :: INT
      eps,sh,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Shift for zeo eigenvalues
      sh = ZERO
      if (present(shift)) sh = shift

      ! Solve eigenproblem
      d = R.dim1

      eval.create(d)
      evec.create(d,d)

      R.solve_symmetric_eigenproblem(eval,evec)

      ! Inverse sqrt eigenvalues
      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = eval(i)

         if (temp<-eps) then
            ! Negative eigenvalues
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            ! Small eigenvalues
            eval(i) = sh   
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            ! Normal eigenvalues
            eval(i) = ONE/sqrt(temp)
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + evec(i,k)*eval(k)*evec(j,k)
         end
         self(i,j) = temp
      end
      end

      evec.destroy
      eval.destroy

   end

   to_inverse_sqrt_of(R_eval,R_evec,tol,n_small,n_negative,shift) ::: PURE
   ! self = sqrt(R)^(-1), but supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on zero eigenvalues.  If "n_small" return the number of
   ! small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT
      shift :: REAL, optional, IN

      eval :: VEC{REAL}*
      d,i,j,k,n_n,n_s :: INT
      eps,sh,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Shift for zeo eigenvalues
      sh = ZERO
      if (present(shift)) sh = shift

      ! Get inverse sqrt eigenvalues
      d = R_eval.dim

      eval.create(d)

      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            ! Negative eigenvalues
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            ! Small eigenvalues
            eval(i) = sh   
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            ! Normal eigenvalues
            eval(i) = ONE/sqrt(temp)
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp 
      end
      end

      eval.destroy

   end


   to_eigenfilter_of(R_eval,R_evec,tol,n_small,n_negative) ::: PURE
   ! self = filter(self), where small eigenvalues less than "tol" are
   ! removed from its spectrum. Supplied are the R eigenvalues "R_eval"
   ! and the R eigenvectors "R_evec". If "tol" is present use that to
   ! decide on small or negative eigenvalues.  If "n_small" return the
   ! number of small eigenvalues.
      self :: OUT
      R_eval :: VEC{REAL}, IN
      R_evec :: MAT{REAL}, IN
      tol :: REAL, optional, IN
      n_small :: INT, optional, OUT
      n_negative :: INT, optional, OUT

      eval :: VEC{REAL}*
      d,i,j,k, n_n,n_s :: INT
      eps,temp,val_n,val_s :: REAL

      ! Get tolerance for smallness
      eps = TOL(20)
      if (present(tol)) eps = tol

      ! Get inverse sqrt eigenvalues
      d = R_eval.dim

      eval.create(d)

      n_n   = 0
      n_s   = 0
      val_n = ZERO
      val_s = ZERO

      do i = 1,d

         temp = R_eval(i)

         if (temp<-eps) then
            eval(i) = ZERO
            n_n     = n_n + 1
            val_n   = min(temp,val_n)
         else if (temp<=eps) then
            eval(i) = ZERO
            n_s     = n_s + 1
            val_s   = min(temp,val_s)
         else
            eval(i) = temp
         end

      end

      if (present(n_small))    n_small    = n_s
      if (present(n_negative)) n_negative = n_n

   !  if (n_s>0) then
   !     WARN("There were "//trim(n_s.to_str)//"small eigenvalues")
   !  end

   !  if (n_n>0) then
   !     WARN("There were "//trim(n_n.to_str)//"negative eigenvalues")
   !  end

      ! Back transform
      do i = 1,d
      do j = 1,d
         temp = ZERO
         do k = 1,d
            temp = temp + R_evec(i,k)*eval(k)*R_evec(j,k)
         end
         self(i,j) = temp
      end
      end

      eval.destroy

   end


   to_power_series_inverse_of(S,tol,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the power series inverse square root of "S".
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
   end

   to_power_series_inv_sqrt_of(S,tol,prefactor,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the inverse square root of "S", a matrix which is required to
   ! have a unit diagonal. The method uses a binomial power series expansion.
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
   end

   to_power_product_inverse_of(S,tol,prefactor,max_it)
   ! Set self to the inverse of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed by the approximate square root until the result in the unit
   ! matrix, within tolerance "tol" (if present). Finally, to form the inverse,
   ! the inverse square root is squared.
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional
   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")
      n :: INT
      W :: MAT{REAL}*
      .to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
      n = S.dim1
      W.create(n,n); W = self
      .to_product_of(W,W)
      W.destroy
   end

   to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
   ! Set self to the inverse square root of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed into a new basis using the approximate square root, until the
   ! result is the unit matrix within tolerance "tol" (if present).
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional

   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")

      D,X :: MAT{REAL}*
      max_iter,n,k :: INT
      eps,prefac :: REAL

      eps = TOL(9)
      if (present(tol)) eps = tol
      max_iter = 100
      if (present(max_it)) max_iter = max_it
      prefac = ONE/FOUR
      if (present(prefactor)) prefac = prefactor

      n = S.dim1
      X.create(n,n)
      D.create(n,n)
      X = prefac*S

      self.to_unit_matrix

      k = 0
      do
         k = k + 1
         D = self
         self = (THREE/TWO)*D
         .plus_scaled_product_of(X,D,fac=-HALF)
         S.change_basis_to(X,self)
         X = prefac*X
         if (X.has_unit_diagonal(eps)) exit
         DIE_IF(k>max_iter,"power series too long")
      end
      self = sqrt(prefac)*self

      D.destroy
      X.destroy

   end


   to_exponential_of(X,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix "X" using a power series expansion, self = exp(X),
   end

   exponentiate_to(U,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix self using a power series expansion, U = exp(self),
   ! so that the maximum deviation from the exact answer is less than "tol"
   ! if present.
   end

   antisymmetric_exponential_to(U,eval,evec) ::: get_from(MAT{INTRINSIC}, EIGEN?=>solve_symmetric_eigenproblem)
   ! Make unitary matrix U = exp(self) where "self" must be antisymmetric.
   ! Uses the formula:  exp A = V (cos P) V^t + V (sin P)/P V^t A
   !                        P = sqrt diag(eig(A^t A))
   ! (c) dylan jayatilaka, university of western australia, 1993
   ! WARNING: Untested in TONTO and looks wrong.
   end

   to_matching_rotation(reference,actual,L,fail)
   ! Returns the rotation matrix which matches coordinates "reference"
   ! to "actual" in a least squares sense.  actual = U x reference.
   ! Return the mean fitting error "L" or else "fail"  for failure.
      reference :: MAT{REAL}, target, IN
      actual :: MAT{REAL}, IN
      L :: REAL
      fail :: BIN
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==actual.dim1,"self incompatible with actual")
   ENSURE(reference.dim2==actual.dim2,"reference incompatible with actual")

      U,X,Rd :: MAT{REAL}*
      X0,Xv :: VEC{REAL}*
      d,iteration :: INT
      big :: REAL

      ! Set dimension, number of points to fit
      d = .dim1

      ! Set minimum L value
      L = ZERO

      ! Start with U being unit matrix
      .to_unit_matrix

      ! Create antisymmetric matrix X, temporary rotation U
      X.create(d,d)
      X0.create(d*(d+1)/2)
      Xv.create(d*(d+1)/2)
      U.create(d,d)
      Rd.create(reference.dim1,reference.dim2)

      ! Repeatedly update U until converged
      iteration = 0
      fail = FALSE
      do

         iteration = iteration + 1

         ! Rotate actual positions
         Rd.to_product_of(self,actual,transpose_A=TRUE)

         ! Determine the gradient Xv at X=0
         saved_reference => reference
         saved_actual => Rd
         X0 = ZERO
         MAT{REAL}::match_vectors(X0,L,Xv)

         ! Exit if gradient converged or too many iterations
         big = maxval(abs(Xv))
         if (big<TOL(6)) exit
         fail = iteration==1000
         if (fail) exit


         ! Do a line minimisation along gradient Xv from X=0
         saved_reference => reference
         saved_actual => Rd
         VEC{REAL}:line_minimize_from_v2(MAT{REAL}::match_vectors,X0,Xv,L,TOL(6))

         ! Exponentiate X and update U
         X.antisymmetric_unzip_triangle(X0)
         U.to_exponential_of(X)
         X.to_product_of(self,U)
         self = X

      end

      ! Clean up
      Rd.destroy; U.destroy; Xv.destroy; X0.destroy; X.destroy

   end

   match_vectors(Xv,L,dL) ::: selfless, public
   ! Take Xv, exponentiate it, and determine "L", the overlap between
   ! "saved_actual" and "saved_reference". Also determine "dL" the
   ! derivative at Xv=0. NOTE: "dL" is wrong unless Xv=0.
      Xv :: VEC{REAL}, IN
      L :: REAL, OUT
      dL :: VEC{REAL}, optional, OUT
      X,U,Rd :: MAT{REAL}*
      d,n,p,q,pq,i :: INT
      val :: REAL

      ! Dimensions
      d = saved_actual.dim1
      n = saved_actual.dim2

      ! Temporaries
      X.create(d,d)
      U.create(d,d)
      Rd.create(d,n)

      ! Exponentiate Xv and get L
      X.antisymmetric_unzip_triangle(Xv)
      U.to_exponential_of(X)
      Rd.to_product_of(U,saved_actual,transpose_a=TRUE)
      Rd = Rd - saved_reference
      L = Rd.trace_product_with(Rd,transpose_a=TRUE)

      ! Gradient of L
      if (present(dL)) then
         Rd = Rd + saved_reference
         pq = 0
         do p = 1,d
            do q = 1,p
               pq = pq + 1
               val = ZERO
               do i = 1,n
                  val = val + Rd(p,i)*saved_reference(q,i) - Rd(q,i)*saved_reference(p,i)
               end
               dL(pq) = -TWO*val
            end
         end
      end

      ! Clean up
      Rd.destroy; U.destroy; X.destroy
   end

!  =============
!  String widths
!  =============

   str_lengths(dp,spaces) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns the minimal string lengths, with optional extra "spaces"
   end

   get_max_str_length(msl,max_dp,spaces) ::: get_from(MAT{INTRINSIC}), pure
   ! Return "msl" the maximum of the string lengths, keeping "max_dp"
   ! decimal places and including extra "spaces"
   end

!  =======================
!  Spin-orbital operations
!  =======================

!  Block returning routines

   alpha_alpha result (res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-alpha sector of the matrix
   end

   beta_alpha result (res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-alpha sector of the matrix
   end

   alpha_beta result (res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-beta sector of the matrix
   end

   beta_beta result (res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-beta sector of the matrix
   end

!  Set_to routines

   alpha_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Set the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Set the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Set the alpha-beta sector of the matrix to "X"
   end

   beta_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Set the beta-beta sector of the matrix to "X"
   end

   alpha_alpha_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Set the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Set the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Set the alpha-beta sector of the matrix to "X"
   end

   beta_beta_set_to(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Set the beta-beta sector of the matrix to "X"
   end

!  Put_to routines

   alpha_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>)
   ! Put the alpha-alpha sector of the matrix to "X"
   end

   beta_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>)
   ! Put the beta-alpha sector of the matrix to "X"
   end

   alpha_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>)
   ! Put the alpha-beta sector of the matrix to "X"
   end

   beta_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, CAST=>)
   ! Put the beta-beta sector of the matrix to "X"
   end

!  plus routines

   alpha_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Add "X" to the alpha-alpha sector of the matrix
   end

   beta_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Add "X" to the beta-alpha sector of the matrix
   end

   alpha_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Add "X" to the alpha-beta sector of the matrix
   end

   beta_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Add "X" to the beta-beta sector of the matrix
   end

   alpha_alpha_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Add "X" to the alpha-alpha sector of the matrix
   end

   beta_alpha_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Add "X" to the beta-alpha sector of the matrix
   end

   alpha_beta_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Add "X" to the alpha-beta sector of the matrix
   end

   beta_beta_plus(X,fac) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL}, FAC?=>REAL)
   ! Add "X" to the beta-beta sector of the matrix
   end

!  general block setting

   put_blocks_to(X,block_dim,block_list) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Put from "self" the blocks listed in "block_list" into "X".
   ! Each block is square and has dimension "block_dim".
   end

   put_sub_blocks_to(X,block_dim,X_block_dim,block_list,X_block_offset) ::: get_from(MAT{INTRINSIC}, X?=>MAT{REAL})
   ! Put from "self" into "X" the blocks listed in "block_list" BUT
   ! only the square sub blocks of size "X_block_dim" which start from
   ! "X_block_offset"+1 past a block boundary are copied into blocks
   ! of "X" i.e. a zero offset (default) assumes the first
   ! "X_block_dim" elements are copied from blocks of "self" into "X".
   end

!  =====================
!  Conversion to strings
!  =====================

   to_str(style,width,precision,left_justify) result (res) ::: get_from(MAT{INTRINSIC}), pure
   ! Change self to a string with specified "style", "width" and
   ! "precision" as defined in the fortran standard
      self :: IN
      style :: STR, IN
      width,precision :: INT, IN
      left_justify :: BIN, IN, optional
      res :: MAT{STR}(.dim1,.dim2)
   end

!  ===============
!  Unit conversion
!  ===============

   convert_to(units)
   ! Convert the number "self" in atomic units or generic units to a
   ! new number in "units".
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = units.conversion_factor
      self   = self*factor
   end

   convert_from(units)
   ! Convert the number "self" from "units" system to a new number
   ! in atomic units or generic units.  Returns "err" whether it was successful.
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = ONE/(units.conversion_factor)
      self   = self*factor
   end

!  ==================================================
!  Gaussian function rotation representation matrices
!  =================================================

   gaussian_d_xyz_matrix result (dtr)
   ! Return the representation matrix for a d-type xyz product found in gaussian
   ! shells, induced by an xyz rotation matrix "self". The matrix representation
   ! induced is: d = d' * dtr, when the coordinates r of the gaussian shell
   ! functions are written in terms of new coordinates r' as: r = self^T * r'.
      dtr :: MAT{REAL}(6,6)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2 :: INT
      d1 :: VEC{INT}(6)  = (/1,2,3,1,1,2/)
      d2 :: VEC{INT}(6)  = (/1,2,3,2,3,3/)

      do i = 1,6 ! loop on old coordinates
         i1 = d1(i)
         i2 = d2(i)
         dtr(1,i)  = self(1,i1)*self(1,i2)
         dtr(2,i)  = self(2,i1)*self(2,i2)
         dtr(3,i)  = self(3,i1)*self(3,i2)
         dtr(4,i)  = self(1,i1)*self(2,i2) &
                   + self(2,i1)*self(1,i2)
         dtr(5,i)  = self(1,i1)*self(3,i2) &
                   + self(3,i1)*self(1,i2)
         dtr(6,i)  = self(2,i1)*self(3,i2) &
                   + self(3,i1)*self(2,i2)
      end

   end

   gaussian_f_xyz_matrix result (ftr)
   ! Return the representation matrix for an f xyz product found in gaussian
   ! shells from a p-type xyz matrix
      ftr :: MAT{REAL}(10,10)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2,i3 :: INT
      f1 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,1/)
      f2 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,2/)
      f3 :: VEC{INT}(10) = (/1,2,3,2,3,1,3,1,2,3/)

      do i = 1,10
         i1 = f1(i)
         i2 = f2(i)
         i3 = f3(i)
         ftr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)
         ftr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)
         ftr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)
         ftr(4,i)  = self(1,i1)*self(1,i2)*self(2,i3) &
                   + self(1,i1)*self(2,i2)*self(1,i3) &
                   + self(2,i1)*self(1,i2)*self(1,i3)
         ftr(5,i)  = self(1,i1)*self(1,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(1,i3)
         ftr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(1,i3)
         ftr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(3,i3)
         ftr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(1,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(1,i3)
         ftr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(2,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(2,i3)
         ftr(10,i) = self(1,i1)*self(2,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(3,i3) &
                   + self(2,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(2,i3) &
                   + self(3,i1)*self(2,i2)*self(1,i3)
      end

   end

   gaussian_g_xyz_matrix result (gtr)
   ! Return the representation matrix for a g xyz product found in gaussian
   ! shells from a p-type xyz matrix
      gtr :: MAT{REAL}(15,15)

   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")

      i,i1,i2,i3,i4 :: INT
      g1 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g2 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g3 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,2,3,3,2,1,1/)
      g4 :: VEC{INT}(15) = (/1,2,3,2,3,1,3,1,2,2,3,3,3,3,2/)

      do i = 1,15
         i1 = g1(i)
         i2 = g2(i)
         i3 = g3(i)
         i4 = g4(i)
         gtr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)*self(2,i4)
         gtr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)*self(3,i4)
         gtr(4,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(5,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(1,i4)
         gtr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(3,i4)
         gtr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(1,i4)
         gtr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(2,i4)
         gtr(10,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(11,i) = self(1,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(1,i4)
         gtr(12,i) = self(2,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(2,i4)
         gtr(13,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(14,i) = self(2,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(2,i4)
         gtr(15,i) = self(3,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(3,i4)
      end

   end

! ======================
! Binning and histograms
! ======================

   to_histogram_from_data(data,X,Y,X_min,X_max,X_bin,Y_min,Y_max,Y_bin) ::: leaky
   ! Set "self" to a histogram matrix whose ij-th element contains the
   ! *sum* of the values in array "data" whose elements correspond to
   ! the ij-th bin in "X" and "Y", where a 2D bin is a range of
   ! values in "X" (and "Y) of side length "X_bin" (and "Y_bin")
   ! beginning at "X_min" (and "Y_min") and ending at "X_max" (and
   ! "Y_max"). The dimension of self is calculated here.
   ! NOTE: Don't use binned data to calculate properties unless you
   ! really need to coarse grain.
      self :: PTR
      data,X,Y :: VEC{REAL}, IN
      X_min,X_max,X_bin :: REAL, IN
      Y_min,Y_max,Y_bin :: REAL, IN

   ENSURE(data.dim==X.dim,"incompatible data and X descriptor")
   ENSURE(data.dim==Y.dim,"incompatible data and Y descriptor")
   ENSURE(X_max>X_min,"X_max is smaller than X_min!")
   ENSURE(Y_max>Y_min,"Y_max is smaller than Y_min!")
   ENSURE(X_bin<(X_max-X_min),"X_bin size is larger than [X_min,X_max]")
   ENSURE(Y_bin<(Y_max-Y_min),"X_bin size is larger than [X_min,X_max]")

      n_X,n_Y, i,j,k :: INT
      X_ran,Y_ran :: REAL

      ! The range of value ...
      X_ran = X_max - X_min
      Y_ran = Y_max - Y_min

      ! The number of bins ...
      n_X = ceiling(X_ran/X_bin)
      n_Y = ceiling(Y_ran/Y_bin)

      ! Create the histogram (leaky)
      self.create(n_X,n_Y)
      self = ZERO

      ! Now do the binning ...
      do k = 1,data.dim

         ! Get the bins
         i = ceiling(min(X(k)-X_min,X_ran)/X_bin)
         j = ceiling(min(Y(k)-Y_min,Y_ran)/Y_bin)

         ! Accumulate
         self(i,j) = self(i,j) + data(k)

      end

   end

!  ==========
!  Misc stuff
!  ==========

   make_enclosing_sphere(pos,radius)
   ! Determine the position and radius of a sphere that encloses all points in
   ! the grid.
      self :: IN
      radius :: REAL, OUT
      pos :: VEC{REAL}(3), OUT
   ENSURE(.dim2==3,"Second dimension of matrix is not 3.")
      diff :: VEC{REAL}(3)
      dist :: REAL
      n,n_pts :: INT
      n_pts = .dim2
      ! Get the center of the sphere.  Should use a better algorithm than just the
      ! average.
      pos = ZERO
      do n = 1,n_pts
       pos = pos + self(n,:)
      end
      pos = pos / n_pts
      ! The radius is the distance to the furthest point.
      radius = 0
      do n = 1,n_pts
       diff = self(n,:) - pos
       dist = dot_product(diff,diff)
       if (dist > radius) radius = dist
      end
      radius = sqrt(radius)
   end

   make_corresponding_orbitals(left,right,theta,p)
   ! This algorithm from Camp and King, J. Chem Phys. Vol 75(1), pp 268-274.
   ! p is the dimenstion of the first block of the partitioned matrices.
   ! Works best if "left" and "right" matrices are nonzero.
      self :: target
      left,right :: MAT{REAL}, target
      theta :: VEC{REAL}, OUT
      p :: INT, IN

   ENSURE(.is_square,"non-square matrix")
   ENSURE(.is_same_shape_as(right),"right is incompatible")
   ENSURE(.is_same_shape_as(left),"left is incompatible")
   ENSURE(size(theta)==min(.dim1,.dim1-p),"theta has wrong size")

      Vp,Vq,Wp,Wq,M,MWq,Hq,Up,Uq :: MAT{REAL}*
      lambda :: VEC{REAL}*
      minpq,q,n :: INT

      n = .dim1
      q = n - p
      minpq = min(p,q)

      ! I've only tested this for q>p.  Suspect p>q does not work.
      Vp => left(:p,:p)
      Vq => left(p+1:,p+1:)
      Wp => right(:p,:p)
      Wq => right(p+1:,p+1:)
      M  => self(:p,p+1:)
      Up => self(:p,:p)
      Uq => self(p+1:,p+1:)
      right(:p,p+1:)=ZERO
      right(p+1:,:p)=ZERO
      left(:p,p+1:)=ZERO
      left(p+1:,:p)=ZERO
      .zero_small_values(TOL(10))

      lambda.create(q)                       ! get eigenvalues and Wq.
      Hq.create(q,q)
      Hq.to_product_of(M,M,transpose_a=TRUE)
      Hq.solve_symmetric_eigenproblem(lambda,Wq)
      Hq.destroy

      lambda.reverse_order                   ! get rotation angles, largest first.
      theta = lambda(:minpq)
      lambda.destroy
      theta.zero_small_values(TOL(10))

   ENSURE(minval(theta)>=ZERO,"eigenvalues less than zero!")
   ENSURE(maxval(theta)<=ONE,"eigenvalues more than one!")
      theta = min(theta,ONE)
      theta = max(theta,ZERO)

      Wq.zero_small_values(TOL(10))          ! get Vp
      Wq.reverse_column_order
      MWq.create(p,q)
      MWq.to_product_of(M,Wq)
      Vp = MWq(:p,:p)
      MWq.destroy
      Vp.schmidt_orthonormalise(theta)

      Vq.to_product_of(Uq,Wq)                   ! get Vq
      Vq.reverse_schmidt_orthogonalise

      Wp.to_product_of(Up,Vp,transpose_a=TRUE)  ! get Wp
      Wp.reverse_schmidt_orthogonalise

      theta = sqrt(theta)
      theta = asin(theta)

   end

   to_multipole_W_translation_mx(R,l_max)
   ! Make the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, due to mistake (?) in Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Set self to zero, mainly for upper triangle
      self = ZERO
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   add_multipole_W_translation_mx(R,l_max)
   ! Add the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, when comparing to Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)==j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   to_multipole_T_interaction_mx(R,l_max,j_max)
   ! Make the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   add_multipole_T_interaction_mx(R,l_max,j_max)
   ! Add the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)==j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   to_R_mu_multipole_mx(points,l_max)
   ! Make the R_mu multipole matrix, self(i,j), which is the scaled regular
   ! mu-type solid harmonic evaluated at point P_i = "points(:,i)" for moment
   ! (L,M), where index j is L*L + M + L + 1, and where L is less than "l_max".
   ! This matrix is used to multiply the interaction matrix to evaluate the
   ! potential at the given points P_i from multipoles at Q,
   !     potential(i) = self * T(Q-P_i) * multipoles(Q).
   ! Reference: the book by Helgaker, Simons and Olsen, p. 407.
      points :: MAT{REAL}, IN
      l_max :: INT
   ENSURE(points.dim2==3,"wrong 2nd dimension, points arrays")
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==points.dim1,"wrong 1st dimension, self")
   ENSURE(.dim2==(l_max+1)*(l_max+1),"wrong 2nd dimension, self")
      Rm :: VEC{VEC_{VEC_{REAL}}}*
      L,M,lm :: INT
      VEC{REAL}:make_R_mu_harmonics(Rm,points,l_max)
      lm = 0
      do L = 0,l_max
         do M = -L,L ! note the canonoical order here
            lm = lm + 1
            self(:,lm) = Rm(L)[M][:]
         end
      end
      do L = l_max,0,-1
         do M = L,-L,-1
            deallocate(Rm(L)[M].element)
         end
         deallocate(Rm(L).element)
      end
      deallocate(Rm)
   end

!  solve_symm_eigenproblem_SCALAPACK(eigenvalues,eigenvectors) ::: private
!  ! Solve the symmetric eigenproblem for "self", yeilding a vector of
!  ! "eigenvalues" and a matrix of "eigenvectors". SCALAPACK version.
!     eigenvalues :: VEC{REAL}
!     eigenvectors :: MAT{REAL}
!     ENSURE(.is_square,"non-square matrix")
!     ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
!     ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")
!
!!     W :: VEC{REAL}*
!     lmat :: VEC{REAL}* ! local matrix
!
!     nb, myrow, mycol, nprow, npcol, nlrow, nlcol :: INT
!     desca :: VEC{INT}(50) ! Vector (or matrix side) descriptor array for BLACS
!     i,j,dim,info :: INT
!
!     dim = .dim1
!
!!      lwork :: INT
!!      lwork = max(dim*dim,3*dim-1)
!!      W.create(lwork)
!!      eigenvectors = self
!!      fail = 0
!!#ifndef ESSL
!!      call dsyev("V","L",dim,eigenvectors,dim,eigenvalues,W,lwork,fail)
!!#endif
!!      W.destroy
!
!
!!  n, nb, myrow, mycol, n_local_rows, n_local_cols :: INT
!!  clustersize, np0, mq0, anb,sqnpc,nps,nsygst_lwopt,nsytrd_lwopt,lwork :: INT
!!  localmat :: MAT{REAL}*
!!  desca :: VEC{REAL}(8)
!!  work,gap :: VEC{REAL}*
!!  ifail,iwork,iclustr :: VEC{INT}*
!!  junki :: INT
!!  junkr,abstol,orfac :: REAL
!
!!  call descinit(desca,dim,dim,tp.proc_grid_bs,tp.proc_grid_bs,0,0,tp.blacs_2d_context,nb,info)
!!
!!  ! This is for pdsygvx
!!  liwork = 3 + 5*n
!!  clustersize = 20
!!  nn = max(n,nb,2)
!!  np0 = numroc(nn,nb,0,0,nprow)
!!  mq0 = numroc(nn,nb,0,0,npcol)
!!  anb = pjlaenv(.blacs_2d_context,3,'PDSYTTRD','L',0,0,0,0)
!!  sqnpc = int(sqrt(real(nprow * npcol,kind=REAL_KIND)))
!!  nps = max(numroc(n,1,0,0,sqnpc), 2*anb)
!!  nsygst_lwopt = nb*(2*np0 + nq0 + nb)
!!  nsytrd_lwopt = n + 2*( anb+1 )*( 4*nps+2 ) + ( nps + 3 ) *  nps
!!  lrwork = 5*n + max(5*nn,np0*mq0+2*nb*nb) + iceil(neigvec,nprow*npcol)*nn + (clustersize-1)*n
!!  lrwork >=  max(lrwork, 5*n + nsytrd_lwopt, nsygst_lwopt )
!
!    ! Save typing.
!    nb = tonto_parallel.proc_grid_bs
!    myrow = tonto_parallel.proc_grid_myrow
!    mycol = tonto_parallel.proc_grid_mycol
!    nprow = tonto_parallel.proc_grid_nrow
!    npcol = tonto_parallel.proc_grid_ncol
!    nlrow = tonto_parallel.n_this_row(n)
!    nlcol = tonto_parallel.n_this_col(n)
!
!    ! Allocate local matrix.
!    lmat.create(nlrow,nlcol)
!
!    ! Set local matrix from global matrix on this processor.
!    ! Probably not efficient.
!    do i = 1, dim
!      do j = 1, dim
!         call pdelset(lmat,i,j,desca,self(i,j))
!      end
!    end
!
!!  ifail.create(n))
!!  rwork.create(lrwork))
!!  iwork.create(liwork))
!!  iclustr.create(2*nprow*npcol))
!!  gap.create(nprow*npcol))
!!
!!  abstol = 2*pdlamch('S')
!!  orfac = -1.0d0 ! -ve means use defaults.
!!  call pdsyevx( 'V', 'A', 'L', n, a, 1, 1, desca, 'Z',
!!      'Z', 'Z', 'Z', abstol, neigok, neigvecok, eigvals, orfac, eigvec, 1,
!!                  1, desca, rwork, lrwork, iwork, liwork, ifail,
!!                  iclustr, gap, info )
!!
!!  gap.destroy
!!  iclustr.destroy
!!  iwork.destroy
!!  work.destroy
!!  ifail.destroy
!
!    !ENSURE(info==0,"no solution, error found")
!    ! Copy the local matrix to global matrix on all processors.
!    ! Probably not efficient.
!    do i = 1, dim
!      do j = 1, dim
!        call pdelset('A', ' ',self(i,j),lmat,i,j,desca)
!      end
!    end
!    lmat.destroy
!  end

end
